{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZWrvHYSWs3g"
      },
      "source": [
        "## Part 1: Downloading Dataset and Parameters\n",
        "Drop kaggle.json, project-50021-415714-5d993bed20f3.json, and data.yaml in /content directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsEcdJEKXEA0"
      },
      "source": [
        "## Part 1.1: Retrieve Dataset From Kaggle API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YxZEhEw5u4Gs"
      },
      "outputs": [],
      "source": [
        "# Install required libraries\n",
        "!pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jkBwPYdnLeKB"
      },
      "outputs": [],
      "source": [
        "# create .kaggle directory in root direcory\n",
        "!mkdir -p ~/.kaggle\n",
        "# copy kaggle.json to ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle\n",
        "# change file permission for kaggle.json\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9MDCMauxDxC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42cca0ea-d727-40ee-8741-6b9a095652ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading ocr-data.zip to /content\n",
            " 61% 6.16G/10.1G [05:12<03:19, 21.2MB/s]\n",
            "User cancelled operation\n"
          ]
        }
      ],
      "source": [
        "# download ocr dataset\n",
        "!kaggle datasets download -d aidapearson/ocr-data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DuN31eldGJWa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b75c8ab3-defb-4f28-cb95-76007082278f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  ocr-data.zip\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of ocr-data.zip or\n",
            "        ocr-data.zip.zip, and cannot find ocr-data.zip.ZIP, period.\n"
          ]
        }
      ],
      "source": [
        "# unzip the retrieved dataset into `raw_train_data`\n",
        "!unzip ocr-data.zip -d raw_train_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeQyG6OIYDTN"
      },
      "source": [
        "## Part 1.2 Retrive any model params from Google drive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7NUhnU9W2w1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b787659-92fc-4174-8621-90b65e091b46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.10/dist-packages (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.10/dist-packages (1.2.0)\n",
            "Requirement already satisfied: google-auth-httplib2 in /usr/local/lib/python3.10/dist-packages (0.1.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib) (1.3.1)\n",
            "Requirement already satisfied: httplib2>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-httplib2) (0.22.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2>=0.19.0->google-auth-httplib2) (3.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.2.2)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install google-auth google-auth-oauthlib google-auth-httplib2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDWpgFrXSBmp"
      },
      "outputs": [],
      "source": [
        "# # Authenticate with service account credentials\n",
        "from google.oauth2 import service_account\n",
        "from google.auth.transport.requests import Request\n",
        "# Access Google Drive using the authenticated credentials\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.http import MediaFileUpload,MediaIoBaseDownload\n",
        "import io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHjRpOUWSTuD"
      },
      "outputs": [],
      "source": [
        "credentials = service_account.Credentials.from_service_account_file(\n",
        "    '/content/project-50021-415714-5d993bed20f3.json',\n",
        "    scopes=['https://www.googleapis.com/auth/drive']\n",
        ")\n",
        "# Authenticate the credentials\n",
        "credentials.refresh(Request())\n",
        "# Build a Drive service object\n",
        "drive_service = build('drive', 'v3', credentials=credentials)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGFFQxOFs5-5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c41a6621-b88c-4b8d-dd51-9bcf8136ca8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "yolo_params_batch_1234567_epochs_6.pt (1Z12nGT_dmFPAfSL82qsRvIlcJ8a9tB_B)\n",
            "yolo_params_batch_1234567_epochs_5.pt (1rBGQjbwns6odzth1xy-Vopnl0lukYmyQ)\n",
            "yolo_params_batch_1234567_epochs_4.pt (1I9wBPy2v8ysuFhPzeJ8LKtpZvZTFjN6Z)\n",
            "lstm_1_layer_512_with_attention_params_batch_1_7_epoch_4 (1OzjeQDvOSZw7ay-e8dGuFPiojAo3lVoN)\n",
            "lstm_1_layer_512_with_attention_params_batch_1_7_epoch_3 (1jR_Utq6VHPzlgr8LHh-ioc5TuZnF23gj)\n",
            "lstm_1_layer_512_with_attention_params_batch_1_7_epoch_2 (1Q7XIcYvSy5nGN8Pm2qETM4qdpy3pMsus)\n",
            "lstm_1_layer_512_with_attention_params_batch_1_7_epoch_1 (156drajFS6W5IBjTJA9UBvRG8GqR8wyKC)\n",
            "lstm_1_layer_512_with_attention_params_batch_1_7_epoch_0 (1ZQqZ6nprkghL4Ces72C5Cz4_c4_EgSFH)\n",
            "yolo_data_full.zip (1dDyvBGBWYPrUDO9asAiQX1XIB0B_pomS)\n",
            "yolo_params_batch_123_epochs_22.pt (1-IqgnHsaRL6lUzSQSg3Z6or184Ik_YkY)\n",
            "lstm_1_layer_512_with_attention_params_batch_2_epoch_2 (1jDF-mJ97GsvdDw-8FrvnY9GbMP1BYDvc)\n",
            "lstm_1_layer_512_with_attention_params_batch_2_epoch_1 (1UyWVR6JVYsctQPf9JJx3wvDizMafmZeJ)\n",
            "lstm_1_layer_512_with_attention_params_batch_2_epoch_0 (1XurHUbVdjNqSSitGjCzSY597XxqnYiK9)\n",
            "lstm_1_layer_512_with_attention_params_batch_2_epoch_15 (1NnWc5vu_HOVx7oaC7hiWQh-G0u_92qRP)\n",
            "object_detection_prediction_batch_1 (10TV4ewfqD7ZuhhRU_km17I9sAQljHsBv)\n",
            "object_detection_params_batch_2 (1hJa3vOG-p_q-YEwXzJQ_-bcUkt1texms)\n",
            "lstm_1_layer_512_with_attention_params_batch_2_epoch_4 (1ODCbTfVjyInA_yaLgX-Jp0wt3uE7U_9S)\n",
            "lstm_params_batch_2_layers_3_epoch_1 (1rp-iEZLiB4k6vk7bhlXCX2FFl0b-Wiy2)\n",
            "lstm_params_batch_2_layers_3_epoch_0 (1mSWSIHqkXjtlf_S1BtoSAMrJ5GVHNdjH)\n",
            "object_detection_params_batch_2 (1GBrsx0DcEQ9LNZeBbnOa9_fmgZeZ1vRc)\n",
            "files to retrieve\n",
            "[{'kind': 'drive#file', 'mimeType': 'application/zip', 'id': '1Z12nGT_dmFPAfSL82qsRvIlcJ8a9tB_B', 'name': 'yolo_params_batch_1234567_epochs_6.pt'}, {'kind': 'drive#file', 'mimeType': 'application/zip', 'id': '1OzjeQDvOSZw7ay-e8dGuFPiojAo3lVoN', 'name': 'lstm_1_layer_512_with_attention_params_batch_1_7_epoch_4'}, {'kind': 'drive#file', 'mimeType': 'application/zip', 'id': '1dDyvBGBWYPrUDO9asAiQX1XIB0B_pomS', 'name': 'yolo_data_full.zip'}]\n",
            "files to delete\n",
            "[]\n"
          ]
        }
      ],
      "source": [
        "# Example: List files in Drive\n",
        "results = drive_service.files().list(pageSize=30).execute()\n",
        "items = results.get('files', [])\n",
        "files_to_retrieve = []\n",
        "files_to_delete = []\n",
        "if not items:\n",
        "    print('No files found.')\n",
        "else:\n",
        "    # print('Files:')\n",
        "    for item in items:\n",
        "        print(f\"{item['name']} ({item['id']})\")\n",
        "        # if item['name'].startswith(\"lstm_1_layer_512_with_attention_params_batch_123_epoch_9\"):\n",
        "        #   files_to_retrieve.append(item)\n",
        "        # if not item[\"name\"].startswith(\"yolo_params_batch_123_epochs_22\"):\n",
        "        #   files_to_delete.append(item)\n",
        "        # if not item[\"name\"].startswith(\"lstm_1_layer_512_with_attention_params_batch_123_epoch_1\"):\n",
        "        #   files_to_delete.append(item)\n",
        "        if item[\"name\"].startswith(\"lstm_1_layer_512_with_attention_params_batch_1_7_epoch_4\"):\n",
        "          files_to_retrieve.append(item)\n",
        "        if item[\"name\"].startswith(\"yolo_params_batch_1234567_epochs_6\"):\n",
        "          files_to_retrieve.append(item)\n",
        "        if item['name'].startswith(\"yolo_data_full\"):\n",
        "          files_to_retrieve.append(item)\n",
        "        # if item['name'].startswith(\"ocr-data\"):\n",
        "        #   files_to_delete.append(item)\n",
        "print(\"files to retrieve\")\n",
        "print(files_to_retrieve)\n",
        "print(\"files to delete\")\n",
        "print(files_to_delete)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def upload_file_to_drive(file_path, file_name = None):\n",
        "  if not file_name:\n",
        "    file_name = os.path.basename(file_path)\n",
        "  file_metadata = {\"name\": file_name}\n",
        "  chunksize = 4000\n",
        "  media = MediaFileUpload(file_path, mimetype=\"application/zip\", resumable=True)\n",
        "  uploaded_file = drive_service.files().create(body=file_metadata, media_body=media, fields='id').execute()\n",
        "def save_state_dict(model, file_name):\n",
        "  torch.save(model.state_dict(), file_name)"
      ],
      "metadata": {
        "id": "O7KHWdRVjzU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72KR37IrAXox"
      },
      "outputs": [],
      "source": [
        "def retrieve_files_from_drive(files_to_retrieve):\n",
        "  for file_obj in files_to_retrieve:\n",
        "    # pylint: disable=maybe-no-member\n",
        "    request = drive_service.files().get_media(fileId=file_obj[\"id\"])\n",
        "    fh = io.FileIO(f'{file_obj[\"name\"]}', mode='wb')\n",
        "    downloader = MediaIoBaseDownload(fh, request)\n",
        "    done = False\n",
        "    while done is False:\n",
        "      status, done = downloader.next_chunk()\n",
        "      print(f\"Download {int(status.progress() * 100)}.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def delete_files_from_drive(files_to_delete):\n",
        "  for file_obj in files_to_delete:\n",
        "    drive_service.files().delete(fileId=file_obj[\"id\"]).execute()"
      ],
      "metadata": {
        "id": "-hvjMEle54Vt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retrieve_files_from_drive(files_to_retrieve)"
      ],
      "metadata": {
        "id": "Y_GiKAXbK1rA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "delete_files_from_drive(files_to_delete)"
      ],
      "metadata": {
        "id": "IxKJxyzY6bgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip yolo_data_full.zip -d yolo_data"
      ],
      "metadata": {
        "id": "h3WDWPA5fKMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clVU1p2OavXJ"
      },
      "source": [
        "## Part 1.3 Create Char encoding for visible and full char set.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from PIL import Image\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import io\n",
        "import json\n",
        "import os\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection import FasterRCNN"
      ],
      "metadata": {
        "id": "LBHuecMZBg7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0qCDGzKf0Y1"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "def convert_image_to_binary(image, thresh):\n",
        "    \"\"\"Convert image to black and white, which will be referred to as a binary image\"\"\"\n",
        "    fn = lambda x : 1 if x <= thresh else 0\n",
        "    binary_image = image.convert('L').point(fn, mode='1')\n",
        "    return binary_image\n",
        "\n",
        "def create_bounding_box_labels(input_json_file):\n",
        "    \"\"\"\n",
        "    for each image, create a file listing the coordinates of bounding boxes of latex chars of the image\n",
        "    \"\"\"\n",
        "    data = []\n",
        "    with open(f\"{input_json_file}\", 'r') as f:\n",
        "        data = json.load(f)\n",
        "    data = list(data)\n",
        "    data.sort(key = lambda x: x[\"uuid\"])\n",
        "    bounding_box_dict = {}\n",
        "    for d in data:\n",
        "        # get output file name\n",
        "        file_name = f\"{d['uuid']}.jpg\"\n",
        "        # extract coordinates from each item in json array\n",
        "        xmins = d[\"image_data\"][\"xmins\"]\n",
        "        ymins = d[\"image_data\"][\"ymins\"]\n",
        "        xmaxs = d[\"image_data\"][\"xmaxs\"]\n",
        "        ymaxs = d[\"image_data\"][\"ymaxs\"]\n",
        "        # make list of bounding box coordinates for each LaTeX character\n",
        "        bounding_box_dict[file_name] = [[xmin,ymin,xmax,ymax]\n",
        "                             for xmin,ymin,xmax,ymax in zip(xmins, ymins, xmaxs, ymaxs)]\n",
        "    return bounding_box_dict\n",
        "\n",
        "def set_default(obj):\n",
        "    if isinstance(obj, set):\n",
        "        return list(obj)\n",
        "    raise TypeError\n",
        "\n",
        "def get_visible_chars_in_image(image_data):\n",
        "    \"\"\"\n",
        "    Returns\n",
        "    ---\n",
        "    char_set set[str]: set of latex chars for the image corresponding to image_data\n",
        "    \"\"\"\n",
        "    char_set = set(image_data.get(\"visible_latex_chars\"))\n",
        "    return char_set\n",
        "\n",
        "def get_full_chars_in_image(image_data):\n",
        "    \"\"\"\n",
        "    Returns\n",
        "    ---\n",
        "    char_set set[str]: set of latex chars for the image corresponding to image_data\n",
        "    \"\"\"\n",
        "    char_set = set(image_data.get(\"full_latex_chars\"))\n",
        "    return char_set\n",
        "\n",
        "def create_visible_char_labels(input_json_file, subset_start = None, subset_end = None):\n",
        "    \"\"\"\n",
        "    input_json_file list[str]: file path of json ground truth for a batch\n",
        "    file_subset list[str] | None: list of files that need to be checked\n",
        "    Returns\n",
        "    ---\n",
        "    char_set set[str]: set of latex chars that occur in the files that were checked\n",
        "    char_dict dict[str,dict[str]]: for each file in the files checked, a dict of visible latex chars for that file is returned\n",
        "    \"\"\"\n",
        "    data = []\n",
        "    with open(f\"{input_json_file}\", 'r') as f:\n",
        "        data = json.load(f)\n",
        "    data = list(data)\n",
        "    data.sort(key = lambda x: x[\"uuid\"])\n",
        "    char_set = set()\n",
        "    char_dict = {}\n",
        "    if subset_start is not None and subset_end is not None:\n",
        "        data = [\n",
        "            d\n",
        "            for i,d in enumerate(data)\n",
        "            if i >= subset_start\n",
        "            and i < subset_end\n",
        "        ]\n",
        "    print('create_char_labels',len(data))\n",
        "    for i,d in enumerate(tqdm(data)):\n",
        "        # get output file name\n",
        "        file_name = f\"{d['uuid']}.jpg\"\n",
        "        chars_in_image = get_visible_chars_in_image(d[\"image_data\"])\n",
        "        char_set = char_set.union(chars_in_image)\n",
        "        char_dict[file_name] = d[\"image_data\"][\"visible_latex_chars\"]\n",
        "    return char_set, char_dict\n",
        "\n",
        "def create_full_char_labels(input_json_file, subset_start = None, subset_end = None):\n",
        "    \"\"\"\n",
        "    input_json_file list[str]: file path of json ground truth for a batch\n",
        "    file_subset list[str] | None: list of files that need to be checked\n",
        "    Returns\n",
        "    ---\n",
        "    char_set set[str]: set of latex chars that occur in the files that were checked\n",
        "    char_dict dict[str,dict[str]]: for each file in the files checked, a dict of visible latex chars for that file is returned\n",
        "    \"\"\"\n",
        "    data = []\n",
        "    with open(f\"{input_json_file}\", 'r') as f:\n",
        "        data = json.load(f)\n",
        "    data = list(data)\n",
        "    data.sort(key = lambda x: x[\"uuid\"])\n",
        "    char_set = set()\n",
        "    char_dict = {}\n",
        "    if subset_start is not None and subset_end is not None:\n",
        "        data = [\n",
        "            d\n",
        "            for i,d in enumerate(data)\n",
        "            if i >= subset_start\n",
        "            and i < subset_end\n",
        "        ]\n",
        "    print('create_char_labels',len(data))\n",
        "    for i,d in enumerate(tqdm(data)):\n",
        "        # get output file name\n",
        "        file_name = f\"{d['uuid']}.jpg\"\n",
        "        chars_in_image = get_full_chars_in_image(d[\"image_data\"])\n",
        "        char_set = char_set.union(chars_in_image)\n",
        "        char_dict[file_name] = d[\"image_data\"][\"full_latex_chars\"]\n",
        "    return char_set, char_dict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_complete_visible_char_set():\n",
        "  batch_char_set = []\n",
        "  batch_char_set.append([])\n",
        "  complete_char_set = set()\n",
        "  for i in range(1,11):\n",
        "    input_json_file_name = f\"raw_train_data/batch_{i}/JSON/kaggle_data_{i}.json\"\n",
        "    batch_dir = \"\"\n",
        "    cur_batch_char_set, cur_batch_char_dict = create_visible_char_labels(input_json_file_name,subset_start = 0, subset_end = 5000)\n",
        "    cur_batch_char_list = list(cur_batch_char_set)\n",
        "    cur_batch_char_list.sort()\n",
        "    batch_char_set.append(cur_batch_char_set)\n",
        "    print(f\"batch {i}\")\n",
        "    print(f\"number of unique LaTeX chars in batch {i}:{len(cur_batch_char_list)}\")\n",
        "    print(f\"unique LaTeX chars\",cur_batch_char_list)\n",
        "\n",
        "  for c in batch_char_set:\n",
        "    complete_char_set = complete_char_set.union(c)\n",
        "  complete_char_set = list(complete_char_set)\n",
        "  complete_char_set.sort()\n",
        "  print(\"number of unique LaTeX chars in dataset:\",len(complete_char_set))\n",
        "  print(\"unique LaTeX chars:\",complete_char_set)\n",
        "  return complete_char_set\n",
        "def get_complete_full_char_set():\n",
        "  batch_char_set = []\n",
        "  batch_char_set.append([])\n",
        "  complete_char_set = set()\n",
        "  for i in range(1,11):\n",
        "    input_json_file_name = f\"raw_train_data/batch_{i}/JSON/kaggle_data_{i}.json\"\n",
        "    batch_dir = \"\"\n",
        "    cur_batch_char_set, cur_batch_char_dict = create_full_char_labels(input_json_file_name,subset_start = 0, subset_end = 5000)\n",
        "    cur_batch_char_list = list(cur_batch_char_set)\n",
        "    cur_batch_char_list.sort()\n",
        "    batch_char_set.append(cur_batch_char_set)\n",
        "    print(f\"batch {i}\")\n",
        "    print(f\"number of unique LaTeX chars in batch {i}:{len(cur_batch_char_list)}\")\n",
        "    print(f\"unique LaTeX chars\",cur_batch_char_list)\n",
        "\n",
        "  for c in batch_char_set:\n",
        "    complete_char_set = complete_char_set.union(c)\n",
        "  complete_char_set = list(complete_char_set)\n",
        "  complete_char_set.sort()\n",
        "  print(\"number of unique LaTeX chars in dataset:\",len(complete_char_set))\n",
        "  print(\"unique LaTeX chars:\",complete_char_set)\n",
        "  return complete_char_set\n",
        "def get_char_encoding(complete_char_set):\n",
        "  char_encoding = {}\n",
        "  for i, char in enumerate(complete_char_set):\n",
        "    char_encoding[char] = i\n",
        "  return char_encoding\n",
        "def get_reverse_char_encoding(char_encoding):\n",
        "  reverse_char_encoding = {}\n",
        "  for key,val in char_encoding.items():\n",
        "    reverse_char_encoding[val] = key\n",
        "  return reverse_char_encoding\n",
        "def encode_char_list(char_list,char_encoding):\n",
        "  encoded_char_list = []\n",
        "  for char in char_list:\n",
        "    encoded_char_list.append(char_encoding[char])\n",
        "  return encoded_char_list\n",
        "def decode_char_list(char_list,reverse_char_encoding):\n",
        "  decoded_char_list = []\n",
        "  for char in char_list:\n",
        "    decoded_char_list.append(reverse_char_encoding[char])\n",
        "  return decoded_char_list\n",
        "def convert_full_to_visible_encoding(full_char_encoding,visible_char_encoding):\n",
        "  full_to_visible_encoding = {}\n",
        "  visible_to_full_encoding = {}\n",
        "  for key,val in full_char_encoding.items():\n",
        "    if key in visible_char_encoding.keys():\n",
        "      full_to_visible_encoding[val + 3] = visible_char_encoding[key] + 3\n",
        "  full_to_visible_encoding[0] = 0\n",
        "  full_to_visible_encoding[1] = 1\n",
        "  full_to_visible_encoding[2] = 2\n",
        "  for key,val in visible_char_encoding.items():\n",
        "    if key in full_char_encoding.keys():\n",
        "      visible_to_full_encoding[val + 3] = full_char_encoding[key] + 3\n",
        "  visible_to_full_encoding[0] = 0\n",
        "  visible_to_full_encoding[1] = 1\n",
        "  visible_to_full_encoding[2] = 2\n",
        "  return full_to_visible_encoding, visible_to_full_encoding\n"
      ],
      "metadata": {
        "id": "_vjIaAFRv_oG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "complete_visible_char_set = get_complete_visible_char_set()\n",
        "visible_char_encoding = get_char_encoding(complete_visible_char_set)\n",
        "reverse_visible_char_encoding = get_reverse_char_encoding(visible_char_encoding)\n",
        "\n",
        "complete_full_char_set = get_complete_full_char_set()\n",
        "full_char_encoding = get_char_encoding(complete_full_char_set)\n",
        "reverse_full_char_encoding = get_reverse_char_encoding(full_char_encoding)\n"
      ],
      "metadata": {
        "id": "HN6aWVS6iGQK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "1d0a9fe3-a89a-4ea5-d167-362d4bffed34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'raw_train_data/batch_1/JSON/kaggle_data_1.json'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-f8852817f0f9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcomplete_visible_char_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_complete_visible_char_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvisible_char_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_char_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomplete_visible_char_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mreverse_visible_char_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_reverse_char_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvisible_char_encoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcomplete_full_char_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_complete_full_char_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-ff735b1000d0>\u001b[0m in \u001b[0;36mget_complete_visible_char_set\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0minput_json_file_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"raw_train_data/batch_{i}/JSON/kaggle_data_{i}.json\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mbatch_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mcur_batch_char_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_batch_char_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_visible_char_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_json_file_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msubset_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mcur_batch_char_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_batch_char_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mcur_batch_char_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-2318fb2b1d52>\u001b[0m in \u001b[0;36mcreate_visible_char_labels\u001b[0;34m(input_json_file, subset_start, subset_end)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \"\"\"\n\u001b[1;32m     63\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{input_json_file}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'raw_train_data/batch_1/JSON/kaggle_data_1.json'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_to_visible_encoding, visible_to_full_encoding = convert_full_to_visible_encoding(full_char_encoding, visible_char_encoding)"
      ],
      "metadata": {
        "id": "tOPXyjzXeaX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(complete_visible_char_set)\n",
        "print(reverse_visible_char_encoding)\n",
        "print(reverse_full_char_encoding)\n",
        "print(full_to_visible_encoding)\n",
        "print(visible_to_full_encoding)"
      ],
      "metadata": {
        "id": "oGp3xPGC1O_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1.4 Create yolo_data directory for yolo training/test data"
      ],
      "metadata": {
        "id": "kqjOFbLMJCG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DatasetTypes = [\n",
        "    \"train\",\n",
        "    \"validation\",\n",
        "    \"test\"\n",
        "]"
      ],
      "metadata": {
        "id": "Pl22ZSQC7AiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import shutil\n",
        "def create_yolo_data(input_json_file_list, image_subset_list, image_dir_list, dataset_type = \"train\"):\n",
        "    \"\"\"\n",
        "    Converts JSON annotations to YOLO format label files.\n",
        "    \"\"\"\n",
        "    print(input_json_file_list,image_subset_list,image_dir_list)\n",
        "    for input_json_file, image_subset, image_dir in zip(input_json_file_list, image_subset_list, image_dir_list):\n",
        "      print(f\"image_dir: {image_dir}\")\n",
        "      print(f\"image_subset: {image_subset}\")\n",
        "      with open(input_json_file, 'r') as f:\n",
        "          data = json.load(f)\n",
        "      data.sort(key=lambda d: d[\"uuid\"])\n",
        "\n",
        "      yolo_label_folder_path = f\"yolo_data_full/{dataset_type}/labels/\"\n",
        "      yolo_image_folder_path = f\"yolo_data_full/{dataset_type}/images/\"\n",
        "\n",
        "      for i,item in enumerate(data):\n",
        "          # only add images with indices within the subset range\n",
        "          if i < image_subset[0] or i >= image_subset[1]:\n",
        "            continue\n",
        "          image_file_name = item['uuid'] + '.jpg'  # Adjust if your image names differ\n",
        "          original_image_path = os.path.join(image_dir, image_file_name)\n",
        "          if not os.path.exists(original_image_path):\n",
        "              continue  # Skip if image does not exist\n",
        "          yolo_label_file_name = os.path.splitext(image_file_name)[0] + '.txt'\n",
        "          # path of label file for yolo\n",
        "          yolo_label_file_path = yolo_label_folder_path + yolo_label_file_name\n",
        "          # path of training image for yolo\n",
        "          yolo_image_file_path = yolo_image_folder_path + image_file_name\n",
        "\n",
        "          if not os.path.exists(yolo_label_folder_path):\n",
        "            os.makedirs(yolo_label_folder_path)\n",
        "          if not os.path.exists(yolo_image_folder_path):\n",
        "            os.makedirs(yolo_image_folder_path)\n",
        "\n",
        "          with open(yolo_label_file_path, 'w+') as label_file:\n",
        "              for char, xmin, ymin, xmax, ymax in zip(item['image_data']['visible_latex_chars'],item['image_data']['xmins'], item['image_data']['ymins'], item['image_data']['xmaxs'], item['image_data']['ymaxs']):\n",
        "                  # Convert to YOLO format and write to file\n",
        "                  # Note: This requires image dimensions to normalize coordinates\n",
        "                  x_center, y_center, width, height = convert_to_yolo_format(xmin, ymin, xmax, ymax)\n",
        "                  class_id = visible_char_encoding[char]\n",
        "                  label_file.write(f\"{class_id} {x_center} {y_center} {width} {height}\\n\")\n",
        "          # copy image file to image_file_path\n",
        "          shutil.copy2(original_image_path, yolo_image_file_path)\n",
        "def convert_to_yolo_format(xmin, ymin, xmax, ymax):\n",
        "    \"\"\"\n",
        "    Converts bounding box coordinates to YOLO format.\n",
        "    \"\"\"\n",
        "    x_center = (xmin + xmax) / 2\n",
        "    y_center = (ymin + ymax) / 2\n",
        "    width = xmax - xmin\n",
        "    height = ymax - ymin\n",
        "    return x_center, y_center, width, height\n"
      ],
      "metadata": {
        "id": "19ywbwJO69hr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "def get_annotation_file_path(batch_number):\n",
        "    return f\"/content/raw_train_data/batch_{batch_number}/JSON/kaggle_data_{batch_number}.json\"\n",
        "def get_image_path(batch_number):\n",
        "    return f\"/content/raw_train_data/batch_{batch_number}/background_images\"\n",
        "def write_yolo_data():\n",
        "  batch_numbers = {\n",
        "      \"train\":[1,2,3,4,5,6,7],\n",
        "      \"validation\":[8,9],\n",
        "      \"test\":[9,10]\n",
        "  }\n",
        "  # Define the directory where your images are located\n",
        "  image_dirs = {\n",
        "      \"train\":[get_image_path(batch_number) for batch_number in batch_numbers[\"train\"]],\n",
        "      \"validation\":[get_image_path(batch_number) for batch_number in batch_numbers[\"validation\"]],\n",
        "      \"test\":[get_image_path(batch_number) for batch_number in batch_numbers[\"test\"]]\n",
        "  }\n",
        "  # Assuming create_bounding_box_labels function is defined as in your provided code\n",
        "  annotation_files = {\n",
        "      \"train\":[get_annotation_file_path(batch_number) for batch_number in batch_numbers[\"train\"]],\n",
        "      \"validation\":[get_annotation_file_path(batch_number) for batch_number in batch_numbers[\"validation\"]],\n",
        "      \"test\":[get_annotation_file_path(batch_number) for batch_number in batch_numbers[\"test\"]]\n",
        "  }\n",
        "  image_subsets = {\n",
        "      \"train\":[(0,10000),(0,10000),(0,10000),(0,10000),(0,10000),(0,10000),(0,10000)], # 70%\n",
        "      \"validation\":[(0,10000),(0,5000)], # 15%\n",
        "      \"test\":[(5000,10000),(0,10000)] # 15%\n",
        "  }\n",
        "  # Corrected function call with all required arguments\n",
        "  for dataset_type in DatasetTypes:\n",
        "    print(dataset_type)\n",
        "    create_yolo_data(annotation_files[dataset_type], image_subsets[dataset_type], image_dirs[dataset_type], dataset_type)"
      ],
      "metadata": {
        "id": "yXkE99986-kw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "write_yolo_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrJM8Wjh7HlX",
        "outputId": "4aece726-6a6c-43c7-b3c7-54e9a0b0c286"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train\n",
            "['/content/raw_train_data/batch_1/JSON/kaggle_data_1.json', '/content/raw_train_data/batch_2/JSON/kaggle_data_2.json', '/content/raw_train_data/batch_3/JSON/kaggle_data_3.json', '/content/raw_train_data/batch_4/JSON/kaggle_data_4.json', '/content/raw_train_data/batch_5/JSON/kaggle_data_5.json', '/content/raw_train_data/batch_6/JSON/kaggle_data_6.json', '/content/raw_train_data/batch_7/JSON/kaggle_data_7.json'] [(0, 10000), (0, 10000), (0, 10000), (0, 10000), (0, 10000), (0, 10000), (0, 10000)] ['/content/raw_train_data/batch_1/background_images', '/content/raw_train_data/batch_2/background_images', '/content/raw_train_data/batch_3/background_images', '/content/raw_train_data/batch_4/background_images', '/content/raw_train_data/batch_5/background_images', '/content/raw_train_data/batch_6/background_images', '/content/raw_train_data/batch_7/background_images']\n",
            "image_dir: /content/raw_train_data/batch_1/background_images\n",
            "image_subset: (0, 10000)\n",
            "image_dir: /content/raw_train_data/batch_2/background_images\n",
            "image_subset: (0, 10000)\n",
            "image_dir: /content/raw_train_data/batch_3/background_images\n",
            "image_subset: (0, 10000)\n",
            "image_dir: /content/raw_train_data/batch_4/background_images\n",
            "image_subset: (0, 10000)\n",
            "image_dir: /content/raw_train_data/batch_5/background_images\n",
            "image_subset: (0, 10000)\n",
            "image_dir: /content/raw_train_data/batch_6/background_images\n",
            "image_subset: (0, 10000)\n",
            "image_dir: /content/raw_train_data/batch_7/background_images\n",
            "image_subset: (0, 10000)\n",
            "validation\n",
            "['/content/raw_train_data/batch_8/JSON/kaggle_data_8.json', '/content/raw_train_data/batch_9/JSON/kaggle_data_9.json'] [(0, 10000), (0, 5000)] ['/content/raw_train_data/batch_8/background_images', '/content/raw_train_data/batch_9/background_images']\n",
            "image_dir: /content/raw_train_data/batch_8/background_images\n",
            "image_subset: (0, 10000)\n",
            "image_dir: /content/raw_train_data/batch_9/background_images\n",
            "image_subset: (0, 5000)\n",
            "test\n",
            "['/content/raw_train_data/batch_9/JSON/kaggle_data_9.json', '/content/raw_train_data/batch_10/JSON/kaggle_data_10.json'] [(5000, 10000), (0, 10000)] ['/content/raw_train_data/batch_9/background_images', '/content/raw_train_data/batch_10/background_images']\n",
            "image_dir: /content/raw_train_data/batch_9/background_images\n",
            "image_subset: (5000, 10000)\n",
            "image_dir: /content/raw_train_data/batch_10/background_images\n",
            "image_subset: (0, 10000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "shutil.make_archive(\"yolo_data_full\", 'zip', \"yolo_data_full\")\n",
        "upload_file_to_drive(\"yolo_data_full.zip\")"
      ],
      "metadata": {
        "id": "w2POgKWk-w5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_names = sorted([filename.strip(\"jpg\") for dirname, _, filenames in os.walk(\"yolo_data/train/images\")\n",
        "                      for i,filename in enumerate(filenames)])\n",
        "label_names = sorted([filename.strip(\"txt\") for dirname, _, filenames in os.walk(\"yolo_data/train/labels\")\n",
        "                      for i,filename in enumerate(filenames)])\n",
        "print(len(image_names),len(label_names))\n",
        "for image_name, label_name in zip(image_names,label_names):\n",
        "  assert(image_name == label_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7kmGaayAGC0",
        "outputId": "6545422a-3983-43e4-8683-fd017940a665"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30000 30000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import locale\n",
        "# def getpreferredencoding(do_setlocale = True):\n",
        "#     return \"UTF-8\"\n",
        "# locale.getpreferredencoding = getpreferredencoding\n",
        "# !rm -d -r yolo_data"
      ],
      "metadata": {
        "id": "Lv7PTYV27j95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcn-4UWTZjcl"
      },
      "source": [
        "## Part 2: Object Detection Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part 2.1. YOLO"
      ],
      "metadata": {
        "id": "s_G6uIRxDgvB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yolov8"
      ],
      "metadata": {
        "id": "r2KM1gHqDsWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "from PIL import Image\n",
        "import cv2"
      ],
      "metadata": {
        "id": "vB3vxAfrDtU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the function takes the original prediction and the iou threshold.\n",
        "def apply_nms(orig_prediction, iou_thresh=0.05):\n",
        "\n",
        "    # torchvision returns the indices of the bboxes to keep\n",
        "    keep = torchvision.ops.nms(orig_prediction['boxes'], orig_prediction['scores'], iou_thresh)\n",
        "    # print('keep',keep)\n",
        "    final_prediction = orig_prediction\n",
        "    final_prediction['boxes'] = final_prediction['boxes'][keep]\n",
        "    final_prediction['scores'] = final_prediction['scores'][keep]\n",
        "    final_prediction['labels'] = final_prediction['labels'][keep]\n",
        "\n",
        "    return final_prediction\n"
      ],
      "metadata": {
        "id": "KfqeNDwkG197"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def yolo_predict(model, dl):\n",
        "  dataloader_predictions = []\n",
        "  for data in dl:\n",
        "    imgs = []\n",
        "    targets = []\n",
        "    filenames = []\n",
        "    filepaths = []\n",
        "    for filename, filepath, src, trg in data:\n",
        "      imgs.append(src)\n",
        "      targets.append(trg)\n",
        "      filenames.append(filename)\n",
        "      filepaths.append(filepath)\n",
        "      prediction = model(filepath)\n",
        "      prediction = {\n",
        "            \"filename\":filename,\n",
        "            \"boxes\":prediction[0].boxes.xyxyn,\n",
        "            \"labels\":prediction[0].boxes.cls,\n",
        "            \"scores\":prediction[0].boxes.conf\n",
        "      }\n",
        "      final_prediction = apply_nms(prediction)\n",
        "      dataloader_predictions.append(final_prediction)\n",
        "  return dataloader_predictions"
      ],
      "metadata": {
        "id": "snp2KvyzEC7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_names = sorted([filename.strip(\"jpg\") for dirname, _, filenames in os.walk(\"yolo_data_full/train/images\")\n",
        "                                  for i,filename in enumerate(filenames)])\n",
        "label_names = sorted([filename.strip(\"txt\") for dirname, _, filenames in os.walk(\"yolo_data_full/train/labels\")\n",
        "                                  for i,filename in enumerate(filenames)])\n",
        "assert([image_name == label_name for image_name,label_name in zip(image_names,label_names)])"
      ],
      "metadata": {
        "id": "w6_iz2bO9PHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "def save_and_upload_params(file_path, batch_numbers = [], epochs = 5):\n",
        "    \"\"\"\n",
        "    batch_numbers: list of batch numbers the model was trained on\n",
        "    \"\"\"\n",
        "    batch_number_str = \"\"\n",
        "    for n in batch_numbers:\n",
        "        batch_number_str+=str(n)\n",
        "    # zip yolo params\n",
        "    # shutil.make_archive(f\"yolo_params_batch_{batch_number_str}_epochs_{epochs}\", 'zip', \"runs/detect/train/weights\")\n",
        "    # uncomment to upload params to drive\n",
        "    upload_file_to_drive(file_path = file_path,file_name = f\"yolo_params_batch_{batch_number_str}_epochs_{epochs}.pt\")"
      ],
      "metadata": {
        "id": "3wwuxHSOgNOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_yolo_model(pretrained = False, weight_location = \"\"):\n",
        "  if pretrained:\n",
        "    print(\"pretrained\")\n",
        "    return YOLO(weight_location)\n",
        "  print('not pretrained')\n",
        "  return YOLO('yolov8n.yaml').load('yolov8n.pt')"
      ],
      "metadata": {
        "id": "lAaOIvv9gBqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def train_and_save_periodically(yolo_model, pretrained = True, starting_epoch = 0, num_epochs= 10, period = 1, batch_numbers = [1,2,3]):\n",
        "#   data_yaml_path = 'data.yaml'\n",
        "#   resume = pretrained\n",
        "#   train_num = 1\n",
        "#   for epoch in range(starting_epoch, starting_epoch + num_epochs, period):\n",
        "#     if epoch > starting_epoch:\n",
        "#       resume = True\n",
        "#     weight_location = f\"runs/detect/train/weights/last.pt\"\n",
        "#     if train_num > 1:\n",
        "#       weight_location = f\"runs/detect/train{train_num}/weights/last.pt\"\n",
        "#     yolo_model.train(data=data_yaml_path, epochs=period, imgsz=416, batch=16, lr0=0.0001, dropout=0.15, pretrained = pretrained)\n",
        "#     save_and_upload_params(weight_location, batch_numbers = [1,2,3,4,5,6,7], epochs = epoch)\n",
        "#     yolo_model = get_yolo_model(pretrained = True, weight_location = weight_location)\n",
        "#     train_num+=1"
      ],
      "metadata": {
        "id": "AVYhNjjkG8AZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# specify location of last pretrained weights here\n",
        "weight_location = \"runs/detect/train3/weights/epoch11.pt\"\n",
        "yolo_model = get_yolo_model(pretrained = True, weight_location = weight_location)"
      ],
      "metadata": {
        "id": "avVdsMqakP7-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b03e9d26-26f2-4841-f73f-417c2d1184ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pretrained\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_yaml_path = 'data.yaml'\n",
        "yolo_model.train(data=data_yaml_path, epochs=100, imgsz=416, batch=32, lr0=0.0001, dropout=0.15,resume=True,save_period=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0CtXzVtfYDp",
        "outputId": "3d02a1d8-c951-493e-d653-2c0642515ce4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.1.43  Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=runs/detect/train3/weights/epoch11.pt, data=data.yaml, epochs=100, time=None, patience=100, batch=32, imgsz=416, save=True, save_period=1, cache=False, device=None, workers=8, project=None, name=train3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=runs/detect/train3/weights/epoch11.pt, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.15, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.0001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.0, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train3\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train3', view at http://localhost:6006/\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    761842  ultralytics.nn.modules.head.Detect           [54, [64, 128, 256]]          \n",
            "YOLOv8n summary: 225 layers, 3021378 parameters, 3021362 gradients, 8.3 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolo_data/train/labels.cache... 70000 images, 0 backgrounds, 0 corrupt: 100%|| 70000/70000 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolo_data/validation/labels.cache... 15000 images, 0 backgrounds, 0 corrupt: 100%|| 15000/15000 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/train3/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.0001' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Resuming training runs/detect/train3/weights/epoch11.pt from epoch 13 to 100 total epochs\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train3\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     13/100      3.33G      0.577     0.4377     0.8178       1244        416:  62%|   | 1358/2188 [14:10<06:26,  2.15it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_and_upload_params(\"runs/detect/train3/weights/epoch11.pt\", batch_numbers = [1,2,3,4,5,6,7], epochs = 12)"
      ],
      "metadata": {
        "id": "0pD-MPan2Zym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "O5Xx7PdoDG80"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import locale\n",
        "# def getpreferredencoding(do_setlocale = True):\n",
        "#     return \"UTF-8\"\n",
        "# locale.getpreferredencoding = getpreferredencoding\n",
        "# !rm -r -d ocr-data.zip"
      ],
      "metadata": {
        "id": "L1Fc5ntnIMLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3: Seq2Seq Model"
      ],
      "metadata": {
        "id": "2qJfqyA2N54K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from PIL import Image\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import io\n",
        "import json\n",
        "import os"
      ],
      "metadata": {
        "id": "coZ0Gguhzefu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part 3.1 Datasets"
      ],
      "metadata": {
        "id": "_UQGjfuYsRVs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def upload_state_dict_to_drive(file_name):\n",
        "  file_metadata = {\"name\": file_name}\n",
        "  chunksize = 4000\n",
        "  media = MediaFileUpload(file_name, mimetype=\"application/zip\", resumable=True)\n",
        "  uploaded_file = drive_service.files().create(body=file_metadata, media_body=media, fields='id').execute()\n",
        "def save_state_dict(model, file_name):\n",
        "  torch.save(model.state_dict(), file_name)"
      ],
      "metadata": {
        "id": "nuYWMm__ZJak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sequence_inputs(input_json_file):\n",
        "    \"\"\"\n",
        "    for each image, create a file listing the coordinates of bounding boxes of latex chars of the image\n",
        "    \"\"\"\n",
        "    data = []\n",
        "    with open(f\"{input_json_file}\", 'r') as f:\n",
        "        data = json.load(f)\n",
        "    data = list(data)\n",
        "    data.sort(key = lambda x: x[\"uuid\"])\n",
        "    sequence_input_dict = {}\n",
        "    for d in data:\n",
        "        # get output file name\n",
        "        file_name = f\"{d['uuid']}.jpg\"\n",
        "        # extract coordinates from each item in json array\n",
        "        xmins = d[\"image_data\"][\"xmins\"]\n",
        "        ymins = d[\"image_data\"][\"ymins\"]\n",
        "        xmaxs = d[\"image_data\"][\"xmaxs\"]\n",
        "        ymaxs = d[\"image_data\"][\"ymaxs\"]\n",
        "        latex_char_labels = encode_char_list(d[\"image_data\"][\"visible_latex_chars\"],visible_char_encoding)\n",
        "        # make list of bounding box coordinates for each LaTeX character\n",
        "        sequence_input_dict[file_name] = [[latex_char,xmin,ymin,xmax,ymax]\n",
        "                             for latex_char,xmin,ymin,xmax,ymax in zip(latex_char_labels,xmins, ymins, xmaxs, ymaxs)]\n",
        "    return sequence_input_dict\n",
        "def create_sequence_outputs(input_json_file):\n",
        "    \"\"\"\n",
        "    for each image, create a file listing the coordinates of bounding boxes of latex chars of the image\n",
        "    \"\"\"\n",
        "    data = []\n",
        "    with open(f\"{input_json_file}\", 'r') as f:\n",
        "        data = json.load(f)\n",
        "    data = list(data)\n",
        "    data.sort(key = lambda x: x[\"uuid\"])\n",
        "    sequence_label_dict = {}\n",
        "    for d in data:\n",
        "        # get output file name\n",
        "        file_name = f\"{d['uuid']}.jpg\"\n",
        "        # extract coordinates from each item in json array\n",
        "        latex_char_labels = encode_char_list(d[\"image_data\"][\"full_latex_chars\"],full_char_encoding)\n",
        "        # make list of bounding box coordinates for each LaTeX character\n",
        "        sequence_label_dict[file_name] = latex_char_labels\n",
        "    return sequence_label_dict\n",
        "def get_yolo_prediction(file_path,model):\n",
        "\n",
        "  prediction = model(file_path,verbose=False)\n",
        "  prediction = {\n",
        "      \"boxes\":prediction[0].boxes.xyxyn,\n",
        "      \"labels\":prediction[0].boxes.cls,\n",
        "      \"scores\":prediction[0].boxes.conf\n",
        "  }\n",
        "  final_prediction = apply_nms(prediction, iou_thresh = 0.45)\n",
        "  return final_prediction\n",
        "def get_fast_rcnn_prediction(file_path, model):\n",
        "  pass\n",
        "def create_sequence_input(yolo_prediction):\n",
        "  labels = [int(label) for label in yolo_prediction[\"labels\"].tolist()]\n",
        "  boxes = yolo_prediction[\"boxes\"].tolist()\n",
        "  sequence_input = [[label, box[0], box[1], box[2], box[3]]\n",
        "                    for label, box in zip(labels, boxes)]\n",
        "  return sequence_input\n",
        "def sort_inputs_by_position(encoded_inputs):\n",
        "  encoded_inputs.sort(key = lambda x: (x[56],x[57],x[58],x[59]))\n",
        "def add_start_end_tokens(seq,sos_token,eos_token):\n",
        "  # append one hot encoded sos and eos tokens to start and end of seq\n",
        "  seq.insert(0,sos_token)\n",
        "  seq.append(eos_token)\n",
        "  return seq"
      ],
      "metadata": {
        "id": "Qwq7H2v4AnOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Part 3.1.1 Dataset Using Output of YOLO Model For Input Sequence"
      ],
      "metadata": {
        "id": "LCsTMrEAsbqK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# class SequenceDataset(Dataset):\n",
        "#     \"\"\"\n",
        "#     Dataset object for a single batch in the dataset\n",
        "#     \"\"\"\n",
        "#     def __init__(self, batch_number, input_seq_dim = 60, output_seq_dim = 63, starting_index = 0, length = 800):\n",
        "#         # directory of the background images\n",
        "#         self.batch_dir = f\"raw_train_data/batch_{str(batch_number)}/background_images\"\n",
        "#         self.file_names = sorted([filename\n",
        "#                                   for dirname, _, filenames in os.walk(self.batch_dir)\n",
        "#                                   for i,filename in enumerate(filenames)\n",
        "#                                   if i - starting_index < length\n",
        "#                                   and i >= starting_index])\n",
        "#         self.file_paths = [os.path.join(self.batch_dir, file_name) for file_name in self.file_names]\n",
        "#         # number of files in the dataset\n",
        "#         self.no_of_files = len(self.file_names)\n",
        "#         # dimension of one input sequence element\n",
        "#         self.input_seq_dim = input_seq_dim\n",
        "#         # dimension of one output sequence element\n",
        "#         self.output_seq_dim = output_seq_dim\n",
        "#         # dict of filename to object detection output\n",
        "#         self.object_detection_predictions = {}\n",
        "#         # JSON file name for training labels\n",
        "#         training_label_file_name = f\"raw_train_data/batch_{str(batch_number)}/JSON/kaggle_data_{str(batch_number)}.json\"\n",
        "#         # create input sequence from training label file\n",
        "#         self.sequence_input_dict = create_sequence_inputs(training_label_file_name)\n",
        "#         # create output sequence from training label file\n",
        "#         self.sequence_label_dict = create_sequence_outputs(training_label_file_name)\n",
        "#         self.char_set,self.char_dict = create_full_char_labels(training_label_file_name)\n",
        "#     def __getitem__(self, idx):\n",
        "#         \"\"\"\n",
        "#         each item is a tuple of (image: Tensor, target:dict:{boxes:list[list[int]],labels:list[int]} )\n",
        "#         \"\"\"\n",
        "#         file_name = self.file_names[idx]\n",
        "#         file_path = self.file_paths[idx]\n",
        "#         encoded_labels = []\n",
        "#         encoded_inputs = []\n",
        "#         #create one hot encoding for each label in the output sequence\n",
        "#         for label in self.sequence_label_dict[file_name]:\n",
        "#           # one hot encode each label, starting from i = 3, so we can use i = 0 as pad token and i = 1 as sos token and i = 2 as pad token\n",
        "#           one_hot_encoding = [ 1\n",
        "#                               if label + 3 == i and i >= 3\n",
        "#                               else 0\n",
        "#                               for i in range(63)]\n",
        "#           encoded_labels.append(one_hot_encoding)\n",
        "#         # create target object for training\n",
        "#         target = encoded_labels\n",
        "#         yolo_prediction = get_yolo_prediction(file_path, yolo_model)\n",
        "#         yolo_prediction = create_sequence_input(yolo_prediction)\n",
        "#         encoded_inputs = []\n",
        "#         for input in yolo_prediction:\n",
        "#           label = input[0]\n",
        "#           # one hot encode each label, starting from i = 2, so we can use i = 0 as sos token and i = 1 as eos token\n",
        "#           one_hot_encoding = [ 1\n",
        "#                               if label + 3 == i and i >= 3\n",
        "#                               else 0\n",
        "#                               for i in range(57)]\n",
        "#           # append bounding box coordinates to the end of the one_hot_encoding to produce input vector of 60 elements\n",
        "#           one_hot_encoding = one_hot_encoding + input[1:5]\n",
        "#           encoded_inputs.append(one_hot_encoding)\n",
        "#         sort_inputs_by_position(encoded_inputs)\n",
        "#         source = encoded_inputs\n",
        "#         item = {\n",
        "#             \"target\": target,\n",
        "#             \"source\": source\n",
        "#         }\n",
        "#         return item\n",
        "#     def __len__(self):\n",
        "#         return self.no_of_files\n",
        "#     def add_object_detection_prediction(self,filename,object_detection_output):\n",
        "#       self.object_detection_predictions[filename] = object_detection_output"
      ],
      "metadata": {
        "id": "fDoT7OZPQtmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Part 3.1.2 Dataset Using Ground Truth Objects as Input Sequence"
      ],
      "metadata": {
        "id": "p-B05M5SsjHY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SequenceDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset object for a single batch in the dataset\n",
        "    \"\"\"\n",
        "    def __init__(self, batch_number, input_seq_dim = 60, output_seq_dim = 62, starting_index = 0, length = 800):\n",
        "        # directory of the background images\n",
        "        self.batch_dir = f\"raw_train_data/batch_{str(batch_number)}/background_images\"\n",
        "        self.file_names = sorted([filename\n",
        "                                  for dirname, _, filenames in os.walk(self.batch_dir)\n",
        "                                  for i,filename in enumerate(filenames)\n",
        "                                  if i - starting_index < length\n",
        "                                  and i >= starting_index])\n",
        "        self.file_paths = [os.path.join(self.batch_dir, file_name) for file_name in self.file_names]\n",
        "        # number of files in the dataset\n",
        "        self.no_of_files = len(self.file_names)\n",
        "        # dimension of one input sequence element\n",
        "        self.input_seq_dim = input_seq_dim\n",
        "        # dimension of one output sequence element\n",
        "        self.output_seq_dim = output_seq_dim\n",
        "        # dict of filename to object detection output\n",
        "        self.object_detection_predictions = {}\n",
        "        # JSON file name for training labels\n",
        "        training_label_file_name = f\"raw_train_data/batch_{str(batch_number)}/JSON/kaggle_data_{str(batch_number)}.json\"\n",
        "        # create input sequence from training label file\n",
        "        self.sequence_input_dict = create_sequence_inputs(training_label_file_name)\n",
        "        # create output sequence from training label file\n",
        "        self.sequence_label_dict = create_sequence_outputs(training_label_file_name)\n",
        "        self.char_set,self.char_dict = create_full_char_labels(training_label_file_name)\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        each item is a tuple of (image: Tensor, target:dict:{boxes:list[list[int]],labels:list[int]} )\n",
        "        \"\"\"\n",
        "        file_name = self.file_names[idx]\n",
        "        encoded_labels = []\n",
        "        encoded_inputs = []\n",
        "        #create one hot encoding for each label in the output sequence\n",
        "        for label in self.sequence_label_dict[file_name]:\n",
        "          # one hot encode each label, starting from i = 2, so we can use i = 0 as sos token and i = 1 as eos token\n",
        "          one_hot_encoding = [ 1\n",
        "                              if label + 3 == i and i >= 3\n",
        "                              else 0\n",
        "                              for i in range(63)]\n",
        "          encoded_labels.append(one_hot_encoding)\n",
        "        # create target object for training\n",
        "        target = encoded_labels\n",
        "        for input in self.sequence_input_dict[file_name]:\n",
        "          label = input[0]\n",
        "          # one hot encode each label, starting from i = 2, so we can use i = 0 as sos token and i = 1 as eos token\n",
        "          one_hot_encoding = [ 1\n",
        "                              if label + 3 == i and i >= 3\n",
        "                              else 0\n",
        "                              for i in range(57)]\n",
        "          # append bounding box coordinates to the end of the one_hot_encoding to produce input vector of 60 elements\n",
        "          one_hot_encoding = one_hot_encoding + input[1:5]\n",
        "          encoded_inputs.append(one_hot_encoding)\n",
        "        sort_inputs_by_position(encoded_inputs)\n",
        "        source = encoded_inputs\n",
        "        item = {\n",
        "            \"target\": target,\n",
        "            \"source\": source\n",
        "        }\n",
        "        # return encoded_inputs,encoded_labels\n",
        "        return item\n",
        "    def __len__(self):\n",
        "        return self.no_of_files\n",
        "    def add_object_detection_prediction(self,filename,object_detection_output):\n",
        "      self.object_detection_predictions[filename] = object_detection_output"
      ],
      "metadata": {
        "id": "JaVvKji3bOvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part 3.2 Initialising Datasets and Dataloaders"
      ],
      "metadata": {
        "id": "TkDb_bx9swlF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq_train_datasets = [SequenceDataset(batch_number = n, starting_index = 0, length = 10000)\n",
        "                      for n in range(1,8)]\n",
        "seq_valid_dataset_1 = SequenceDataset(batch_number = 8, starting_index = 0, length = 10000)\n",
        "seq_valid_dataset_2 = SequenceDataset(batch_number = 9, starting_index = 0, length = 5000)\n",
        "seq_test_dataset_1 = SequenceDataset(batch_number = 9, starting_index = 5000, length = 5000)\n",
        "seq_test_dataset_2 = SequenceDataset(batch_number = 10, starting_index = 0, length = 10000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXqgwmn_-XRY",
        "outputId": "d9971995-dd1d-4f41-aeab-f7f03c9b4175"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "create_char_labels 10000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 10000/10000 [00:00<00:00, 119302.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "create_char_labels 10000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 10000/10000 [00:00<00:00, 173427.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "create_char_labels 10000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 10000/10000 [00:00<00:00, 158858.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "create_char_labels 10000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 10000/10000 [00:00<00:00, 188469.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "create_char_labels 10000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 10000/10000 [00:00<00:00, 186826.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "create_char_labels 10000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 10000/10000 [00:00<00:00, 163547.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "create_char_labels 10000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 10000/10000 [00:00<00:00, 183917.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "create_char_labels 10000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 10000/10000 [00:00<00:00, 121758.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "create_char_labels 10000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 10000/10000 [00:00<00:00, 156767.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "create_char_labels 10000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 10000/10000 [00:00<00:00, 174641.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "create_char_labels 10000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 10000/10000 [00:00<00:00, 169050.18it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_train_dataset = torch.utils.data.ConcatDataset(seq_train_datasets)\n",
        "seq_valid_dataset = torch.utils.data.ConcatDataset([seq_valid_dataset_1, seq_valid_dataset_2])\n",
        "seq_test_dataset = torch.utils.data.ConcatDataset([seq_test_dataset_1, seq_test_dataset_2])"
      ],
      "metadata": {
        "id": "ow70GWVaruBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_seq(batch_seq, max_seq_length, pad_token, sos_token,eos_token):\n",
        "  new_batch_seq = []\n",
        "  for seq in batch_seq:\n",
        "    new_seq = seq\n",
        "    while len(new_seq) < max_seq_length:\n",
        "      new_seq.append(pad_token)\n",
        "    new_seq = add_start_end_tokens(new_seq, sos_token,eos_token)\n",
        "    new_batch_seq.append(torch.tensor(new_seq))\n",
        "  return new_batch_seq\n",
        "\n",
        "def collate_fn(batch):\n",
        "  # define pad char\n",
        "  trg_pad_token = [1 if i == 0\n",
        "                   else 0\n",
        "                   for i in range(63)]\n",
        "  trg_sos_token = [1 if i == 1\n",
        "                   else 0\n",
        "                   for i in range(63)]\n",
        "  trg_eos_token = [1 if i == 2\n",
        "                   else 0\n",
        "                   for i in range(63)]\n",
        "  src_pad_token = [1 if i == 0\n",
        "                    else 0\n",
        "                    for i in range(61)]\n",
        "  src_sos_token = [1 if i == 1\n",
        "                    else 0\n",
        "                    for i in range(61)]\n",
        "  src_eos_token = [1 if i == 2\n",
        "                    else 0\n",
        "                    for i in range(61)]\n",
        "  # construct a two lists, one for the batch's source objects and one for the atarget objects\n",
        "  batch_trg = [item[\"target\"] for item in batch]\n",
        "  batch_src = [item[\"source\"] for item in batch]\n",
        "  # pad target objects in batch to be same length as longest rarget\n",
        "  max_trg_length = len(max(batch_trg, key = lambda t: len(t)))\n",
        "  max_src_length = len(max(batch_src, key = lambda t: len(t)))\n",
        "  batch_trg = pad_seq(batch_trg, max_trg_length, trg_pad_token, trg_sos_token, trg_eos_token)\n",
        "  batch_src = pad_seq(batch_src, max_src_length, src_pad_token, src_sos_token, src_eos_token)\n",
        "  # batch_src = [torch.tensor(item) for item in batch_src]\n",
        "  # convert batch_src to torch tensor by stacking\n",
        "  batch_src = torch.stack(batch_src,dim=0)\n",
        "  # convert batch_trg to torch tensor\n",
        "  batch_trg = torch.stack(batch_trg,dim=0)\n",
        "  return batch_src,batch_trg\n",
        "# def collate_fn(batch):\n",
        "#   return batch\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "torch.cuda.empty_cache()\n",
        "print(collate_fn)"
      ],
      "metadata": {
        "id": "z5CwQPZNdK3t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9469a527-3d5d-4990-893e-ab806c801038"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<function collate_fn at 0x79993111b910>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "seq_train_dl = torch.utils.data.DataLoader(\n",
        "    seq_train_dataset,\n",
        "    batch_size = 20,\n",
        "    shuffle = True,\n",
        "    collate_fn = collate_fn,\n",
        "    pin_memory = True if torch.cuda.is_available() else False\n",
        ")\n",
        "seq_valid_dl = torch.utils.data.DataLoader(\n",
        "    seq_valid_dataset,\n",
        "    batch_size = 20,\n",
        "    shuffle = True,\n",
        "    collate_fn = collate_fn,\n",
        "    pin_memory = True if torch.cuda.is_available() else False\n",
        ")\n",
        "seq_test_dl = torch.utils.data.DataLoader(\n",
        "    seq_test_dataset,\n",
        "    batch_size = 20,\n",
        "    shuffle = True,\n",
        "    collate_fn = collate_fn,\n",
        "    pin_memory = True if torch.cuda.is_available() else False\n",
        ")"
      ],
      "metadata": {
        "id": "ZZPKropZclUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def compare_trg_with_pred(trg,pred,print_output = False):\n",
        "\n",
        "  if print_output is False:\n",
        "    return\n",
        "  trg_copy = trg.transpose(0,1)\n",
        "  decoded_trg = []\n",
        "  trg_ls = trg_copy.tolist()\n",
        "  for ls in trg_ls[0]:\n",
        "    for i,l in enumerate(ls):\n",
        "      if l == 1.0:\n",
        "        decoded_trg.append(i)\n",
        "        break\n",
        "  decoded_trg = [i for i in decoded_trg if i != 0]\n",
        "  pred = [i for i in pred if i != 0]\n",
        "  print('trg',decoded_trg)\n",
        "  print('pred',pred)"
      ],
      "metadata": {
        "id": "bBXoqMd0gMKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part 3.3.1 LSTM with Attention Model"
      ],
      "metadata": {
        "id": "RYGJMwajs2R_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Attention, self).__init__()\n",
        "\n",
        "    def forward(self, encoder_outputs, decoder_hidden):\n",
        "        # encoder_outputs: (batch_size, seq_len, hidden_dim)\n",
        "        # decoder_hidden: (batch_size, hidden_dim)\n",
        "        encoder_outputs = encoder_outputs.transpose(0,1)\n",
        "        # Calculate the attention scores.\n",
        "        scores = torch.bmm(encoder_outputs, decoder_hidden.unsqueeze(2)).squeeze(2)  # (batch_size, seq_len)\n",
        "        attn_weights = F.softmax(scores, dim=1)  # (batch_size, seq_len)\n",
        "        context_vector = torch.bmm(attn_weights.unsqueeze(1), encoder_outputs).squeeze(1)  # (batch_size, hidden_dim)\n",
        "        return context_vector, attn_weights\n",
        "\n",
        "class LSTMEncoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.rnn = nn.LSTM(input_dim, hidden_dim, n_layers, dropout=dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src):\n",
        "        # src = [src length, batch size, input_dim]\n",
        "        self.dropout(src.float())\n",
        "        # print('src shape',src.shape)\n",
        "        outputs, (hidden, cell) = self.rnn(src)\n",
        "        # outputs = [src length, batch size, hidden dim * n directions]\n",
        "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
        "        # cell = [n layers * n directions, batch size, hidden dim]\n",
        "        # outputs are always from the top hidden layer\n",
        "        return outputs, hidden, cell\n",
        "\n",
        "class LSTMDecoder(nn.Module):\n",
        "    def __init__(self, output_dim, hidden_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        self.output_dim = output_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.attention = Attention()\n",
        "        self.n_layers = n_layers\n",
        "        self.rnn = nn.LSTM(output_dim + hidden_dim, hidden_dim, n_layers, dropout=dropout)\n",
        "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "    def forward(self, input, encoder_outputs, hidden, cell):\n",
        "        # input = [batch size, output_dim]\n",
        "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
        "        # cell = [n layers * n directions, batch size, hidden dim]\n",
        "        # n directions in the decoder will both always be 1, therefore:\n",
        "        # hidden = [n layers, batch size, hidden dim]\n",
        "        # context = [n layers, batch size, hidden dim]\n",
        "        # input = input.unsqueeze(0)\n",
        "        self.dropout(input.float())\n",
        "\n",
        "        # create attention context vector and get attention weights\n",
        "        context_vector, attn_weights = self.attention(encoder_outputs, hidden[-1])  # using the last layer's hidden state\n",
        "        rnn_input = torch.cat([input.transpose(0,1), context_vector.unsqueeze(1)], dim=2)  # (batch_size, 1, emb_dim + hidden_dim)\n",
        "        rnn_input = rnn_input.transpose(0,1)\n",
        "        output, (hidden, cell) = self.rnn(rnn_input.float(), (hidden, cell))\n",
        "        # seq length and n directions will always be 1 in this decoder, therefore:\n",
        "        # output = [1, batch size, hidden dim]\n",
        "        # hidden = [n layers, batch size, hidden dim]\n",
        "        # cell = [n layers, batch size, hidden dim]\n",
        "        prediction = self.fc_out(output.squeeze(0))\n",
        "        # prediction = [batch size, output dim]\n",
        "        return prediction, hidden, cell\n",
        "\n",
        "class LSTMSeq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "        assert (\n",
        "            encoder.hidden_dim == decoder.hidden_dim\n",
        "        ), \"Hidden dimensions of encoder and decoder must be equal!\"\n",
        "        assert (\n",
        "            encoder.n_layers == decoder.n_layers\n",
        "        ), \"Encoder and decoder must have equal number of layers!\"\n",
        "\n",
        "    def forward(self, src, trg, print_output = False, teacher_forcing_ratio = 0):\n",
        "        # src = [src length, batch size]\n",
        "        # trg = [trg length, batch size]\n",
        "        # teacher_forcing_ratio is probability to use teacher forcing\n",
        "        # e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
        "        batch_size = trg.shape[1]\n",
        "        trg_length = trg.shape[0]\n",
        "        # tensor to store decoder outputs\n",
        "        outputs = torch.zeros(trg_length, batch_size, self.decoder.output_dim).to(self.device)\n",
        "        # last hidden state of the encoder is used as the initial hidden state of the decoder\n",
        "        encoder_outputs, hidden, cell = self.encoder(src)\n",
        "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
        "        # cell = [n layers * n directions, batch size, hidden dim]\n",
        "\n",
        "        # first input to the decoder is the <sos> tokens\n",
        "        input = trg[0,:]\n",
        "        input = input[None,:]\n",
        "        # input = [batch size]\n",
        "        pred = [[1 for i in range(20)]]\n",
        "        for t in range(1, trg_length):\n",
        "            # insert input token embedding, previous hidden and previous cell states\n",
        "            # receive output tensor (predictions) and new hidden and cell states\n",
        "            output, hidden, cell = self.decoder(input, encoder_outputs, hidden, cell)\n",
        "            # output = [batch size, output dim]\n",
        "            # hidden = [n layers, batch size, hidden dim]\n",
        "            # cell = [n layers, batch size, hidden dim]\n",
        "            # place predictions in a tensor holding predictions for each token\n",
        "            outputs[t] = output\n",
        "            # decide if we are going to use teacher forcing or not\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            # get the highest predicted token from our predictions\n",
        "            top1 = output.argmax(1)\n",
        "            top1_vals = top1.tolist()\n",
        "            one_hot_encoded_top1 = torch.tensor([\n",
        "                [\n",
        "                  1 if i == val\n",
        "                  else 0\n",
        "                  for i in range(self.decoder.output_dim)\n",
        "              ] for val in top1_vals]\n",
        "            )\n",
        "            # if teacher forcing, use actual next token as next input\n",
        "            # if not, use predicted token\n",
        "            pred.append(top1_vals)\n",
        "            input = trg[t] if teacher_force else one_hot_encoded_top1\n",
        "            encoded_input = []\n",
        "            input = torch.tensor(input).float().to(device)\n",
        "            input = input[None,:]\n",
        "            # input = [batch size, output dim]\n",
        "        # print('pred',pred)\n",
        "        pred_0 = []\n",
        "        for i in range(len(pred)):\n",
        "          pred_0.append(pred[i][0])\n",
        "        compare_trg_with_pred(trg,pred_0,print_output)\n",
        "        return outputs\n"
      ],
      "metadata": {
        "id": "hXBwg-01gFEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part 3.3.2 Training LSTM with Attention Model"
      ],
      "metadata": {
        "id": "_wzRxPSSs-aD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# num of visible labels = 54, num of coordinates = 4, 1 sos token and 1 eos token, 1 pad token = 61\n",
        "input_dim = 61\n",
        "# 60 full labels + 1 sos token + 1 eos token + 1 pad token = 62\n",
        "output_dim = 63\n",
        "# size of hidden state vector\n",
        "hidden_dim = 512\n",
        "# number of LSTM layers to produce hidden feature state\n",
        "n_layers = 1\n",
        "# dropout for regularization\n",
        "encoder_dropout = 0.2\n",
        "decoder_dropout = 0.2\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "lstm_encoder = LSTMEncoder(\n",
        "    input_dim,\n",
        "    hidden_dim,\n",
        "    n_layers,\n",
        "    encoder_dropout,\n",
        ")\n",
        "\n",
        "lstm_decoder = LSTMDecoder(\n",
        "    output_dim,\n",
        "    hidden_dim,\n",
        "    n_layers,\n",
        "    decoder_dropout,\n",
        ")\n",
        "\n",
        "lstm_model = LSTMSeq2Seq(lstm_encoder, lstm_decoder, device).to(device)\n",
        "state_dict = torch.load('lstm_1_layer_512_with_attention_params_batch_123_epoch_5')\n",
        "lstm_model.load_state_dict(state_dict)"
      ],
      "metadata": {
        "id": "uZIxZY2qo-v1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a79ed4cc-117a-4b97-b97a-800fdb556c5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialise Weights"
      ],
      "metadata": {
        "id": "WreY9di3tUMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def init_weights(m):\n",
        "#     for name, param in m.named_parameters():\n",
        "#         nn.init.uniform_(param.data, -0.08, 0.08)\n",
        "# lstm_model.apply(init_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4r2eNLKzC3y3",
        "outputId": "ce1275e0-8a54-4b24-e6fb-4d1a977da675"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMSeq2Seq(\n",
              "  (encoder): LSTMEncoder(\n",
              "    (rnn): LSTM(61, 512, dropout=0.2)\n",
              "    (dropout): Dropout(p=0.2, inplace=False)\n",
              "  )\n",
              "  (decoder): LSTMDecoder(\n",
              "    (attention): Attention()\n",
              "    (rnn): LSTM(575, 512, dropout=0.2)\n",
              "    (fc_out): Linear(in_features=512, out_features=63, bias=True)\n",
              "    (dropout): Dropout(p=0.2, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(lstm_model.parameters())\n",
        "criterion = torch.nn.CrossEntropyLoss()\n"
      ],
      "metadata": {
        "id": "OLCFN5TeC_M-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### Trying to add eos tokens ###\n",
        "def train_fn(\n",
        "    model, data_loader, optimizer, criterion, clip, teacher_forcing_ratio, device\n",
        "):\n",
        "  model.train()\n",
        "  model.to(device)\n",
        "  epoch_loss = 0\n",
        "  div = 50\n",
        "  current_loss = 0\n",
        "  for i, (src,trg) in enumerate(data_loader):\n",
        "    optimizer.zero_grad()\n",
        "    src,trg = src.transpose(0,1).to(device),trg.transpose(0,1).to(device)\n",
        "    # print(src.shape,trg.shape)\n",
        "    # src = [src length, batch size, input_dim]\n",
        "    # trg = [trg length, batch size, output_dim]\n",
        "    print_output = False\n",
        "    if i % div == 0 and i > 0:\n",
        "      print_output = True\n",
        "    output = model(src, trg, print_output, teacher_forcing_ratio)\n",
        "    # print('output shape, trg shape',output.shape,trg.shape)\n",
        "    # output = [trg length, batch size, output_dim]\n",
        "    output = output[1:]\n",
        "    # output = [(trg length - 1), batch size, output_dim]\n",
        "    trg = trg[1:]\n",
        "    trg, output = trg.transpose(1,2), output.transpose(1,2)\n",
        "\n",
        "    # print('output shape, trg shape after reshape',output.shape,trg.shape)\n",
        "    # trg = [(trg length - 1) * batch size]\n",
        "    loss = criterion(output.float(), trg.float())\n",
        "    current_loss += loss.item()\n",
        "    if print_output:\n",
        "      print('iter',i * 20)\n",
        "      print('loss',current_loss / div)\n",
        "      current_loss = 0\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "    optimizer.step()\n",
        "    epoch_loss += loss.item()\n",
        "  return epoch_loss / len(data_loader)"
      ],
      "metadata": {
        "id": "diYf-3S3mFhv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_fn(model, data_loader, criterion, teacher_forcing_ratio, device):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    div = 50\n",
        "    current_loss = 0\n",
        "    with torch.no_grad():\n",
        "      for i, (src,trg) in enumerate(data_loader):\n",
        "        src,trg = src.transpose(0,1).to(device),trg.transpose(0,1).to(device)\n",
        "        # src = [src length, batch size, input_dim]\n",
        "        # trg = [trg length, batch size, output_dim]\n",
        "        print_output = False\n",
        "        if i % div == 0 and i > 0:\n",
        "          print_output = True\n",
        "        output = model(src, trg, print_output, teacher_forcing_ratio)\n",
        "        # print('output shape, trg shape',output.shape,trg.shape)\n",
        "        # output = [trg length, batch size, output_dim]\n",
        "        output = output[1:]\n",
        "        # output = [(trg length - 1) * batch size, output_dim]\n",
        "        trg = trg[1:]\n",
        "        trg, output = trg.transpose(1,2), output.transpose(1,2)\n",
        "\n",
        "        # print('output shape, trg shape after reshape',output.shape,trg.shape)\n",
        "        # trg = [(trg length - 1) * batch size]\n",
        "        loss = criterion(output.float(), trg.float())\n",
        "        current_loss += loss.item()\n",
        "        if print_output:\n",
        "          print('iter',i * 20)\n",
        "          print('loss',current_loss / div)\n",
        "          current_loss = 0\n",
        "        epoch_loss += loss.item()\n",
        "      return epoch_loss / len(data_loader)"
      ],
      "metadata": {
        "id": "nHZ89SyyGRCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# save_state_dict(lstm_model,f\"lstm_1_layers_1024_with_attention_params_batch_2_layers_3_epoch_{9}\")\n",
        "# upload_state_dict_to_drive(f\"lstm_1_layers_1024_with_attention_params_batch_2_layers_3_epoch_{9}\")"
      ],
      "metadata": {
        "id": "60CJG2EGG5Qi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Loop"
      ],
      "metadata": {
        "id": "kkFGjacLtQdA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "n_epochs = 5\n",
        "start_epoch = 0\n",
        "clip = 1.0\n",
        "teacher_forcing_ratio = 0.2\n",
        "\n",
        "best_valid_loss = float(\"inf\")\n",
        "\n",
        "for epoch in tqdm(range(start_epoch,start_epoch+n_epochs)):\n",
        "    train_loss = train_fn(\n",
        "        lstm_model,\n",
        "        seq_train_dl,\n",
        "        optimizer,\n",
        "        criterion,\n",
        "        clip,\n",
        "        teacher_forcing_ratio,\n",
        "        device,\n",
        "    )\n",
        "\n",
        "    save_state_dict(lstm_model,f\"lstm_1_layer_512_with_attention_params_batch_1_7_epoch_{epoch}\")\n",
        "    upload_state_dict_to_drive(f\"lstm_1_layer_512_with_attention_params_batch_1_7_epoch_{epoch}\")\n",
        "    valid_loss = evaluate_fn(\n",
        "        lstm_model,\n",
        "        seq_test_dl,\n",
        "        criterion,\n",
        "        teacher_forcing_ratio,\n",
        "        device,\n",
        "    )\n",
        "    test_loss = evaluate_fn(\n",
        "        lstm_model,\n",
        "        seq_test_dl,\n",
        "        criterion,\n",
        "        0,\n",
        "        device,\n",
        "    )\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "    print('\\n')\n",
        "    print(f\"\\tTrain Loss: {train_loss:7.3f} | Train PPL: {np.exp(train_loss):7.3f}\")\n",
        "    print(f\"\\tValid Loss: {valid_loss:7.3f} | Valid PPL: {np.exp(valid_loss):7.3f}\")\n",
        "    print(f\"\\Test Loss: {test_loss:7.3f} | Valid PPL: {np.exp(test_loss):7.3f}\")"
      ],
      "metadata": {
        "id": "SPI8xRaKHWXQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81ac0bce-8cb7-469e-a4ad-3451c7c7aca4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/5 [00:00<?, ?it/s]<ipython-input-67-e0f4c5705112>:127: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  input = torch.tensor(input).float().to(device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trg [1, 27, 61, 50, 38, 23, 61, 30, 62, 61, 16, 62, 62, 23, 61, 36, 3, 4, 10, 22, 61, 50, 62, 62, 61, 50, 3, 4, 10, 23, 61, 30, 62, 61, 10, 62, 62, 2]\n",
            "pred [1, 27, 61, 61, 38, 38, 62, 62, 61, 61, 61, 61, 61, 61, 61, 61, 61, 62, 62, 62, 62, 62, 62, 62]\n",
            "iter 1000\n",
            "loss 2.265040135383606\n",
            "trg [1, 27, 61, 50, 38, 30, 6, 16, 62, 23, 61, 9, 20, 40, 61, 11, 62, 61, 50, 62, 3, 4, 15, 22, 40, 61, 11, 62, 61, 50, 62, 62, 61, 10, 62, 2]\n",
            "pred [1, 27, 61, 55, 38, 62, 62, 61, 61, 61, 61, 61, 61, 61, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62]\n",
            "iter 2000\n",
            "loss 1.8828905510902405\n",
            "trg [1, 27, 61, 59, 38, 24, 62, 23, 61, 29, 41, 61, 8, 8, 62, 61, 59, 62, 62, 61, 29, 41, 61, 11, 15, 62, 61, 14, 62, 62, 23, 61, 29, 41, 61, 9, 8, 62, 61, 9, 62, 62, 61, 29, 41, 61, 8, 7, 62, 61, 59, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 62, 61, 62, 62, 62, 62, 62, 62, 62, 62, 62]\n",
            "iter 3000\n",
            "loss 1.7820318961143493\n",
            "trg [1, 27, 61, 43, 38, 12, 40, 61, 3, 62, 62, 22, 61, 43, 62, 3, 4, 9, 23, 61, 15, 62, 61, 43, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 30, 62, 23, 61, 61, 61, 61, 62, 61, 62, 62, 62, 62, 62]\n",
            "iter 4000\n",
            "loss 1.8167565035820008\n",
            "trg [1, 27, 61, 57, 38, 23, 61, 30, 62, 61, 9, 62, 62, 23, 61, 10, 36, 61, 57, 62, 3, 4, 10, 20, 61, 57, 62, 62, 61, 12, 57, 3, 4, 12, 23, 61, 30, 62, 61, 16, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 30, 61, 61, 62, 61, 61, 61, 61, 61, 62, 61, 61, 62, 62, 62, 61, 62, 62, 61, 62, 62, 62, 61, 62, 62, 62, 62, 62, 62, 62, 61, 62, 62, 62, 62, 62, 62]\n",
            "iter 5000\n",
            "loss 1.6124433660507203\n",
            "trg [1, 27, 61, 43, 38, 16, 62, 23, 61, 43, 62, 61, 43, 40, 61, 9, 62, 3, 13, 40, 61, 15, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 23, 61, 61, 62, 61, 61, 62, 62, 61, 61, 62, 62, 61, 61, 62]\n",
            "iter 6000\n",
            "loss 1.604102418422699\n",
            "trg [1, 17, 27, 61, 59, 38, 11, 62, 16, 34, 61, 59, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 23, 62, 61, 61, 62, 62, 61]\n",
            "iter 7000\n",
            "loss 1.6053316020965576\n",
            "trg [1, 27, 61, 48, 38, 9, 62, 23, 61, 36, 61, 25, 10, 48, 31, 62, 62, 61, 48, 20, 61, 25, 13, 48, 31, 62, 62, 2]\n",
            "pred [1, 27, 61, 48, 38, 24, 62, 23, 61, 61, 61, 61, 61, 61, 61, 62, 61, 61, 62, 62, 61, 62, 62, 62, 62, 62]\n",
            "iter 8000\n",
            "loss 1.5299720549583435\n",
            "trg [1, 27, 61, 43, 38, 23, 61, 30, 62, 61, 12, 62, 62, 23, 61, 36, 61, 43, 62, 3, 4, 15, 36, 61, 43, 62, 62, 61, 43, 3, 4, 11, 23, 61, 30, 62, 61, 10, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 23, 61, 30, 62, 61, 61, 62, 62, 23, 61, 45, 62, 61, 61, 62, 62, 61, 61, 62, 62, 61, 61, 62, 62, 61, 61, 62, 62, 61, 61, 62, 61, 61, 62, 62, 61, 62, 62]\n",
            "iter 9000\n",
            "loss 1.4724466729164123\n",
            "trg [1, 28, 61, 57, 62, 17, 23, 61, 27, 61, 50, 38, 30, 6, 9, 40, 61, 4, 62, 62, 20, 61, 50, 62, 62, 61, 27, 61, 50, 38, 30, 6, 13, 40, 61, 4, 62, 62, 4, 14, 20, 40, 61, 14, 62, 61, 50, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 17, 23, 61, 27, 61, 61, 38, 23, 61, 30, 62, 61, 61, 62, 62, 61, 61, 62, 62, 61, 61, 62, 62, 61, 62, 62, 61, 61, 62, 61, 61, 62, 62, 61, 61, 62, 62, 61, 61, 62, 62, 61, 62, 62]\n",
            "iter 10000\n",
            "loss 1.400550615787506\n",
            "trg [1, 27, 61, 37, 38, 10, 62, 23, 61, 28, 61, 37, 62, 62, 61, 28, 61, 37, 62, 25, 28, 61, 37, 62, 3, 11, 31, 62, 2]\n",
            "pred [1, 27, 61, 57, 38, 9, 62, 23, 61, 61, 62, 62, 61, 61, 61, 61, 62, 62, 61, 61, 61, 61, 61, 62, 61, 62, 62]\n",
            "iter 11000\n",
            "loss 1.3885398077964783\n",
            "trg [1, 27, 61, 58, 38, 24, 62, 23, 61, 4, 9, 25, 20, 61, 23, 61, 9, 62, 61, 58, 62, 62, 3, 4, 12, 23, 61, 16, 62, 61, 58, 62, 20, 61, 23, 61, 10, 62, 61, 58, 62, 62, 31, 62, 61, 4, 9, 58, 40, 61, 4, 11, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 23, 61, 61, 61, 61, 61, 61, 61, 62, 62, 62, 62, 62, 62, 62, 62, 61, 61, 62, 62, 62, 61, 61, 62, 62, 62, 61, 61, 62, 62, 62, 62, 62, 62, 62, 62]\n",
            "iter 12000\n",
            "loss 1.3157440555095672\n",
            "trg [1, 27, 61, 59, 38, 9, 62, 59, 40, 61, 15, 62, 4, 11, 40, 61, 15, 6, 9, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 23, 61, 61, 61, 62, 61, 62, 62, 61, 62]\n",
            "iter 13000\n",
            "loss 1.2485072588920594\n",
            "trg [1, 28, 61, 53, 62, 17, 23, 61, 27, 61, 55, 38, 23, 61, 30, 62, 61, 11, 62, 40, 61, 4, 62, 62, 4, 14, 33, 40, 61, 9, 62, 61, 55, 62, 62, 61, 27, 61, 55, 38, 23, 61, 30, 62, 61, 9, 62, 40, 61, 4, 62, 62, 14, 22, 40, 61, 15, 62, 61, 55, 62, 36, 61, 55, 62, 62, 2]\n",
            "pred [1, 28, 61, 27, 62, 17, 23, 61, 27, 61, 58, 38, 23, 61, 30, 62, 61, 4, 62, 40, 61, 4, 62, 62, 23, 61, 62, 62, 61, 61, 62, 61, 27, 61, 27, 61, 27, 61, 30, 38, 30, 40, 30, 62, 61, 4, 62, 40, 61, 4, 62, 62, 61, 40, 40, 61, 9, 62, 61, 62, 62, 61, 62, 62]\n",
            "iter 14000\n",
            "loss 1.2768521869182587\n",
            "trg [1, 23, 61, 15, 62, 61, 10, 62, 27, 61, 59, 38, 23, 61, 30, 62, 61, 16, 62, 40, 61, 4, 62, 62, 23, 61, 11, 62, 61, 36, 40, 61, 9, 62, 61, 59, 62, 3, 16, 36, 40, 61, 11, 62, 61, 59, 62, 62, 2]\n",
            "pred [1, 17, 61, 61, 62, 17, 23, 61, 27, 61, 58, 38, 23, 61, 30, 62, 61, 9, 62, 40, 61, 4, 62, 62, 23, 61, 61, 62, 62, 61, 61, 61, 38, 62, 61, 30, 62, 61, 4, 62, 62, 61, 62, 62, 62]\n",
            "iter 15000\n",
            "loss 1.195475676059723\n",
            "trg [1, 27, 61, 59, 38, 4, 10, 62, 23, 61, 59, 40, 61, 8, 62, 3, 14, 62, 61, 59, 3, 8, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 62, 23, 61, 9, 62, 61, 61, 61, 62, 62, 61, 61, 62]\n",
            "iter 16000\n",
            "loss 1.17528555393219\n",
            "trg [1, 27, 61, 58, 38, 23, 61, 30, 62, 61, 9, 62, 62, 23, 61, 9, 21, 61, 58, 62, 3, 4, 12, 36, 61, 58, 62, 62, 61, 14, 58, 3, 4, 14, 23, 61, 30, 62, 61, 15, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 23, 61, 30, 62, 61, 10, 62, 62, 23, 61, 23, 61, 61, 61, 62, 62, 61, 62, 62, 61, 62, 62, 61, 61, 62, 61, 61, 62, 3, 4, 9, 30, 61, 61, 61, 61, 62, 62, 62, 62]\n",
            "iter 17000\n",
            "loss 1.133119444847107\n",
            "trg [1, 27, 61, 48, 38, 7, 40, 61, 4, 62, 62, 23, 61, 26, 48, 4, 11, 32, 62, 61, 48, 40, 61, 16, 62, 3, 4, 14, 48, 3, 8, 14, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 23, 61, 62, 62, 23, 61, 4, 61, 61, 61, 62, 61, 61, 62, 62, 61, 61, 62, 61, 61, 62, 62, 62, 62, 62]\n",
            "iter 18000\n",
            "loss 1.115352716445923\n",
            "trg [1, 27, 61, 56, 38, 9, 40, 61, 3, 62, 62, 23, 61, 56, 62, 61, 26, 56, 3, 11, 32, 62, 2]\n",
            "pred [1, 27, 61, 54, 38, 9, 40, 61, 3, 62, 62, 23, 61, 61, 62, 61, 61, 61, 61, 61, 61, 62, 62]\n",
            "iter 19000\n",
            "loss 1.0796058535575868\n",
            "trg [1, 27, 61, 55, 38, 12, 62, 4, 23, 61, 13, 55, 62, 61, 35, 61, 55, 3, 9, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 23, 23, 61, 61, 61, 61, 62, 61, 61, 4, 62, 62, 62]\n",
            "iter 20000\n",
            "loss 1.0132984972000123\n",
            "trg [1, 27, 61, 55, 38, 16, 40, 61, 3, 62, 62, 23, 61, 4, 11, 34, 61, 55, 62, 22, 40, 61, 8, 62, 61, 55, 62, 62, 61, 25, 9, 3, 9, 55, 36, 61, 55, 62, 31, 20, 40, 61, 11, 62, 61, 55, 62, 62, 2]\n",
            "pred [1, 27, 61, 59, 38, 8, 40, 61, 3, 62, 62, 23, 61, 4, 3, 3, 61, 56, 62, 62, 61, 61, 62, 62, 61, 61, 62, 3, 4, 3, 61, 3, 4, 62, 62, 61, 62, 62]\n",
            "iter 21000\n",
            "loss 0.9890863049030304\n",
            "trg [1, 27, 61, 55, 38, 30, 62, 23, 61, 20, 40, 61, 10, 62, 61, 55, 62, 3, 14, 34, 61, 55, 62, 3, 9, 62, 61, 20, 61, 55, 62, 3, 7, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 23, 61, 30, 62, 61, 9, 62, 62, 23, 61, 34, 61, 61, 62, 62, 61, 61, 62, 62, 25, 38, 30, 61, 30, 62, 61, 4, 62, 62, 61, 40, 61, 62]\n",
            "iter 22000\n",
            "loss 0.9584633719921112\n",
            "trg [1, 27, 61, 43, 38, 16, 40, 61, 4, 62, 62, 23, 61, 14, 62, 61, 36, 61, 43, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 9, 40, 61, 3, 62, 62, 23, 61, 34, 61, 61, 62, 61, 58, 62, 62]\n",
            "iter 23000\n",
            "loss 0.9844728493690491\n",
            "trg [1, 27, 61, 55, 38, 12, 40, 61, 3, 62, 62, 4, 9, 9, 22, 61, 55, 62, 2]\n",
            "pred [1, 27, 61, 54, 38, 9, 40, 61, 3, 62, 62, 4, 9, 34, 40, 61, 62, 62, 61, 62, 62]\n",
            "iter 24000\n",
            "loss 0.9495380663871765\n",
            "trg [1, 27, 61, 58, 38, 9, 40, 61, 3, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 58, 62, 25, 9, 3, 4, 14, 34, 40, 61, 16, 62, 61, 58, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 58, 62, 25, 34, 61, 58, 62, 3, 58, 34, 40, 61, 7, 62, 61, 58, 62, 31, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 9, 40, 61, 3, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 58, 62, 25, 9, 3, 4, 9, 36, 40, 61, 9, 62, 61, 58, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 58, 62, 25, 36, 61, 58, 62, 3, 58, 20, 40, 61, 9, 62, 61, 58, 62, 31, 62]\n",
            "iter 25000\n",
            "loss 0.9366139364242554\n",
            "trg [1, 27, 61, 48, 38, 4, 9, 62, 23, 61, 48, 40, 61, 10, 62, 3, 13, 48, 3, 9, 62, 61, 48, 3, 13, 62, 2]\n",
            "pred [1, 27, 61, 57, 38, 4, 9, 62, 23, 61, 61, 48, 40, 61, 61, 62, 3, 4, 48, 62, 61, 61, 62, 62, 4, 62, 62]\n",
            "iter 26000\n",
            "loss 0.8912944805622101\n",
            "trg [1, 28, 61, 57, 62, 17, 23, 61, 27, 61, 50, 38, 30, 6, 10, 40, 61, 4, 62, 62, 20, 61, 50, 62, 62, 61, 27, 61, 50, 38, 30, 6, 14, 40, 61, 4, 62, 62, 4, 10, 33, 40, 61, 12, 62, 61, 50, 62, 62, 2]\n",
            "pred [1, 28, 61, 55, 62, 17, 23, 61, 27, 61, 54, 38, 30, 6, 9, 40, 61, 4, 62, 62, 36, 61, 54, 62, 62, 61, 27, 61, 54, 38, 30, 6, 9, 40, 61, 4, 62, 62, 4, 9, 36, 40, 61, 9, 62, 61, 55, 62, 62]\n",
            "iter 27000\n",
            "loss 0.9381031727790833\n",
            "trg [1, 48, 17, 27, 61, 56, 38, 8, 40, 61, 3, 62, 62, 26, 28, 61, 56, 62, 32, 40, 61, 56, 62, 2]\n",
            "pred [1, 17, 27, 61, 61, 54, 38, 40, 40, 61, 3, 62, 62, 26, 28, 61, 40, 40, 61, 62, 61, 54, 62, 62]\n",
            "iter 28000\n",
            "loss 0.8415339195728302\n",
            "trg [1, 27, 61, 50, 38, 24, 62, 23, 61, 23, 61, 29, 41, 61, 11, 12, 62, 61, 50, 62, 62, 61, 29, 41, 61, 9, 9, 62, 61, 9, 62, 62, 62, 61, 23, 61, 29, 41, 61, 11, 14, 62, 61, 50, 62, 62, 61, 29, 41, 61, 14, 10, 62, 61, 14, 62, 62, 62, 2]\n",
            "pred [1, 27, 61, 54, 38, 24, 62, 23, 61, 23, 61, 29, 41, 61, 8, 8, 62, 61, 51, 62, 62, 61, 29, 41, 61, 8, 8, 62, 61, 10, 62, 62, 62, 61, 23, 61, 29, 41, 61, 8, 8, 62, 61, 58, 62, 62, 61, 29, 41, 61, 8, 8, 62, 61, 62, 62]\n",
            "iter 29000\n",
            "loss 0.8580176389217377\n",
            "trg [1, 27, 61, 57, 38, 30, 6, 12, 62, 23, 61, 9, 34, 40, 61, 14, 62, 61, 57, 62, 3, 10, 36, 40, 61, 10, 62, 61, 57, 62, 62, 61, 15, 62, 2]\n",
            "pred [1, 27, 61, 57, 38, 30, 6, 11, 62, 23, 61, 34, 34, 40, 61, 9, 62, 61, 57, 62, 3, 4, 34, 40, 61, 9, 62, 61, 57, 62, 62, 61, 9, 62]\n",
            "iter 30000\n",
            "loss 0.8625986170768738\n",
            "trg [1, 27, 61, 48, 38, 4, 24, 62, 23, 61, 10, 48, 40, 61, 8, 62, 62, 61, 9, 48, 40, 61, 10, 62, 3, 35, 61, 9, 8, 48, 40, 61, 11, 62, 3, 48, 40, 61, 9, 62, 62, 62, 2]\n",
            "pred [1, 27, 61, 48, 38, 4, 24, 62, 23, 61, 9, 48, 40, 61, 61, 62, 3, 3, 4, 62, 61, 61, 61, 3, 62, 3, 9, 48, 3, 62, 3, 9, 62, 62, 62, 62]\n",
            "iter 31000\n",
            "loss 0.8456134009361267\n",
            "trg [1, 27, 61, 50, 38, 30, 6, 12, 62, 23, 61, 23, 61, 45, 62, 61, 45, 50, 62, 25, 36, 3, 4, 15, 20, 61, 50, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 50, 62, 25, 50, 3, 4, 16, 30, 6, 9, 31, 62, 2]\n",
            "pred [1, 27, 61, 44, 38, 30, 6, 9, 62, 23, 61, 23, 61, 45, 62, 61, 45, 56, 62, 25, 36, 61, 44, 62, 3, 4, 9, 20, 61, 44, 62, 31, 61, 61, 62, 61, 45, 62, 61, 45, 61, 62, 25, 9, 30, 3, 4, 9, 30, 31, 62]\n",
            "iter 32000\n",
            "loss 0.7834341049194335\n",
            "trg [1, 27, 61, 55, 38, 16, 40, 61, 3, 62, 62, 23, 61, 4, 14, 33, 61, 55, 62, 20, 40, 61, 8, 62, 61, 55, 62, 62, 61, 36, 40, 61, 12, 62, 61, 55, 62, 3, 25, 12, 55, 34, 61, 55, 62, 3, 10, 31, 36, 40, 61, 16, 62, 61, 55, 62, 62, 2]\n",
            "pred [1, 27, 61, 55, 38, 9, 40, 61, 3, 62, 62, 23, 61, 4, 9, 36, 61, 55, 62, 36, 40, 61, 9, 62, 61, 55, 62, 62, 61, 34, 40, 61, 9, 62, 61, 55, 62, 3, 25, 9, 55, 36, 61, 55, 62, 3, 9, 31, 40, 40, 61, 10, 62, 61, 55, 62, 62]\n",
            "iter 33000\n",
            "loss 0.7637750399112702\n",
            "trg [1, 27, 61, 49, 38, 24, 62, 23, 61, 14, 49, 62, 61, 49, 3, 26, 49, 32, 62, 2]\n",
            "pred [1, 27, 61, 49, 38, 24, 62, 23, 61, 49, 3, 61, 61, 62, 62, 61, 49, 40, 62]\n",
            "iter 34000\n",
            "loss 0.759311796426773\n",
            "trg [1, 23, 61, 27, 61, 42, 38, 24, 62, 23, 61, 45, 62, 61, 45, 42, 62, 16, 7, 16, 42, 62, 61, 27, 61, 42, 38, 24, 62, 23, 61, 45, 62, 61, 45, 42, 62, 16, 7, 14, 42, 40, 61, 11, 62, 62, 2]\n",
            "pred [1, 28, 61, 27, 61, 50, 38, 24, 62, 23, 61, 45, 62, 61, 45, 45, 62, 25, 8, 7, 40, 40, 61, 61, 61, 61, 38, 24, 62, 23, 61, 61, 62, 61, 45, 45, 62, 62, 62, 62, 62, 61]\n",
            "iter 35000\n",
            "loss 0.752806487083435\n",
            "trg [1, 27, 61, 54, 38, 24, 62, 23, 61, 9, 62, 61, 12, 62, 2]\n",
            "pred [1, 27, 61, 54, 38, 24, 62, 23, 61, 9, 62, 61, 9, 62, 62]\n",
            "iter 36000\n",
            "loss 0.7055239218473435\n",
            "trg [1, 27, 61, 55, 38, 11, 62, 23, 61, 15, 34, 40, 61, 7, 62, 61, 25, 10, 55, 31, 62, 62, 61, 55, 40, 61, 16, 62, 62, 2]\n",
            "pred [1, 17, 27, 61, 55, 38, 9, 62, 23, 61, 9, 20, 61, 25, 9, 62, 61, 25, 55, 55, 62, 62, 61, 61, 61, 61, 62, 62, 62]\n",
            "iter 37000\n",
            "loss 0.7108391135931015\n",
            "trg [1, 27, 61, 56, 38, 11, 62, 23, 61, 46, 40, 61, 56, 40, 61, 9, 62, 62, 4, 12, 62, 61, 56, 3, 4, 34, 61, 56, 62, 62, 2]\n",
            "pred [1, 27, 61, 56, 38, 9, 62, 23, 61, 43, 40, 61, 61, 56, 61, 56, 62, 62, 61, 61, 61, 40, 61, 62, 62, 61, 56, 62, 62, 62, 62]\n",
            "iter 38000\n",
            "loss 0.7590552085638046\n",
            "trg [1, 27, 61, 53, 38, 9, 40, 61, 3, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 53, 62, 25, 10, 3, 4, 10, 20, 40, 61, 10, 62, 61, 53, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 53, 62, 25, 34, 61, 53, 62, 3, 53, 34, 40, 61, 10, 62, 61, 53, 62, 31, 62, 2]\n",
            "pred [1, 27, 61, 53, 38, 9, 40, 61, 3, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 53, 62, 25, 9, 3, 4, 9, 20, 40, 61, 8, 62, 61, 53, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 51, 62, 25, 36, 61, 53, 62, 3, 51, 36, 40, 61, 9, 62, 61, 49, 62, 31, 62]\n",
            "iter 39000\n",
            "loss 0.7078344535827636\n",
            "trg [1, 27, 61, 59, 38, 4, 24, 62, 23, 61, 7, 62, 61, 59, 40, 61, 10, 62, 62, 2]\n",
            "pred [1, 27, 61, 59, 38, 4, 24, 62, 23, 61, 59, 62, 61, 59, 40, 61, 62, 62, 62]\n",
            "iter 40000\n",
            "loss 0.6559996902942657\n",
            "trg [1, 27, 61, 58, 38, 15, 40, 61, 3, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 58, 62, 25, 15, 3, 4, 15, 36, 40, 61, 7, 62, 61, 58, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 58, 62, 25, 34, 61, 58, 62, 3, 58, 22, 40, 61, 13, 62, 61, 58, 62, 31, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 9, 40, 61, 3, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 58, 62, 25, 58, 3, 4, 9, 36, 40, 61, 62, 62, 61, 58, 31, 31, 62, 61, 23, 61, 45, 62, 61, 45, 58, 62, 25, 58, 58, 62, 62, 58, 62, 62, 62]\n",
            "iter 41000\n",
            "loss 0.6809299373626709\n",
            "trg [1, 27, 61, 48, 38, 15, 40, 61, 4, 62, 62, 23, 61, 13, 62, 61, 35, 61, 48, 25, 48, 4, 10, 31, 62, 62, 2]\n",
            "pred [1, 27, 61, 48, 38, 9, 40, 61, 4, 62, 62, 23, 61, 35, 61, 48, 62, 61, 62, 61, 48, 62, 61, 62, 62]\n",
            "iter 42000\n",
            "loss 0.6565752416849137\n",
            "trg [1, 27, 61, 50, 38, 12, 40, 61, 3, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 50, 62, 25, 16, 3, 4, 10, 34, 40, 61, 11, 62, 61, 50, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 50, 62, 25, 34, 3, 50, 33, 40, 61, 11, 62, 61, 50, 62, 31, 62, 2]\n",
            "pred [1, 27, 61, 50, 38, 9, 40, 61, 3, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 50, 62, 25, 9, 3, 4, 9, 40, 61, 61, 9, 62, 61, 50, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 50, 62, 25, 36, 61, 50, 62, 3, 50, 20, 40, 61, 9, 62, 61, 62]\n",
            "iter 43000\n",
            "loss 0.6810927605628967\n",
            "trg [1, 27, 61, 51, 38, 14, 62, 23, 61, 28, 61, 25, 13, 3, 51, 31, 62, 62, 61, 28, 61, 25, 7, 3, 4, 16, 51, 40, 61, 9, 62, 31, 62, 62, 2]\n",
            "pred [1, 27, 61, 51, 38, 10, 62, 23, 61, 28, 61, 25, 13, 3, 4, 62, 61, 61, 61, 61, 61, 61, 62, 61, 3, 4, 3, 31, 62, 62]\n",
            "iter 44000\n",
            "loss 0.64917101085186\n",
            "trg [1, 27, 61, 52, 38, 15, 40, 61, 4, 62, 62, 23, 61, 4, 9, 62, 61, 36, 61, 52, 62, 62, 2]\n",
            "pred [1, 27, 61, 52, 38, 9, 40, 61, 4, 62, 62, 23, 61, 52, 62, 61, 61, 52, 62, 62, 62]\n",
            "iter 45000\n",
            "loss 0.6526080298423768\n",
            "trg [1, 27, 61, 55, 38, 30, 6, 9, 62, 23, 61, 34, 61, 55, 62, 3, 4, 10, 36, 61, 55, 62, 62, 61, 55, 3, 4, 9, 30, 6, 10, 62, 2]\n",
            "pred [1, 27, 61, 55, 38, 30, 6, 9, 62, 23, 61, 34, 61, 55, 62, 3, 4, 9, 36, 61, 55, 62, 62, 61, 55, 3, 4, 9, 30, 6, 9, 62]\n",
            "iter 46000\n",
            "loss 0.654566217660904\n",
            "trg [1, 27, 61, 42, 38, 24, 62, 23, 61, 29, 41, 61, 15, 15, 62, 61, 42, 62, 62, 61, 29, 41, 61, 13, 16, 62, 61, 7, 62, 62, 23, 61, 29, 41, 61, 15, 13, 62, 61, 16, 62, 62, 61, 29, 41, 61, 8, 10, 62, 61, 42, 62, 62, 2]\n",
            "pred [1, 27, 61, 42, 38, 24, 62, 23, 61, 29, 41, 61, 14, 14, 62, 61, 42, 62, 62, 61, 29, 41, 61, 9, 61, 62, 61, 62, 62, 62, 23, 61, 29, 41, 61, 9, 9, 62, 61, 9, 62, 62, 61, 29, 41, 61, 8, 8, 62, 61, 42, 62, 62]\n",
            "iter 47000\n",
            "loss 0.5756416469812393\n",
            "trg [1, 27, 61, 59, 38, 23, 61, 30, 62, 61, 10, 62, 62, 23, 61, 20, 61, 59, 62, 62, 61, 34, 61, 59, 62, 62, 2]\n",
            "pred [1, 27, 61, 59, 38, 23, 61, 30, 62, 61, 9, 62, 62, 23, 61, 34, 61, 59, 62, 62, 61, 36, 61, 59, 62, 62]\n",
            "iter 48000\n",
            "loss 0.6023917323350907\n",
            "trg [1, 23, 61, 9, 62, 61, 14, 62, 27, 61, 59, 38, 24, 62, 23, 61, 36, 61, 23, 61, 10, 62, 61, 59, 62, 62, 3, 4, 9, 23, 61, 12, 62, 61, 59, 62, 34, 61, 23, 61, 9, 62, 61, 59, 62, 62, 62, 61, 59, 40, 61, 4, 14, 62, 62, 2]\n",
            "pred [1, 23, 61, 9, 62, 61, 9, 62, 27, 61, 59, 38, 24, 62, 23, 61, 23, 61, 36, 61, 61, 9, 62, 62, 62, 62, 61, 9, 23, 61, 9, 62, 61, 62, 61, 23, 61, 23, 61, 61, 62, 61, 61, 61, 62, 62, 61, 61, 62, 62, 62, 61, 59, 62, 62]\n",
            "iter 49000\n",
            "loss 0.5775521492958069\n",
            "trg [1, 27, 61, 54, 38, 7, 62, 23, 61, 36, 61, 7, 62, 54, 62, 61, 36, 61, 15, 62, 54, 62, 2]\n",
            "pred [1, 27, 61, 54, 38, 8, 62, 23, 61, 36, 61, 54, 62, 62, 61, 61, 40, 61, 62, 62, 61, 54, 62]\n",
            "iter 50000\n",
            "loss 0.6012104165554046\n",
            "trg [1, 27, 61, 51, 38, 30, 6, 15, 40, 61, 4, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 51, 62, 25, 33, 61, 51, 62, 4, 10, 31, 62, 61, 23, 61, 45, 62, 61, 45, 51, 62, 20, 61, 51, 62, 62, 2]\n",
            "pred [1, 27, 61, 51, 38, 30, 6, 10, 40, 61, 4, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 51, 62, 25, 34, 61, 51, 62, 4, 9, 62, 61, 61, 62, 61, 45, 62, 61, 45, 51, 62, 62]\n",
            "iter 51000\n",
            "loss 0.5821378862857819\n",
            "trg [1, 27, 61, 55, 38, 11, 40, 61, 4, 62, 62, 23, 61, 25, 55, 4, 12, 31, 25, 55, 4, 10, 31, 62, 61, 55, 3, 7, 62, 2]\n",
            "pred [1, 27, 61, 55, 38, 9, 62, 4, 4, 62, 62, 23, 61, 55, 4, 4, 31, 25, 55, 4, 8, 31, 62, 25, 55, 3, 4, 31, 62]\n",
            "iter 52000\n",
            "loss 0.6096380376815795\n",
            "trg [1, 27, 61, 58, 38, 30, 6, 15, 40, 61, 4, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 58, 62, 25, 34, 61, 58, 62, 4, 12, 31, 62, 61, 23, 61, 45, 62, 61, 45, 58, 62, 34, 61, 58, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 30, 6, 11, 40, 61, 4, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 58, 62, 25, 34, 61, 58, 62, 4, 9, 62, 61, 23, 61, 45, 62, 61, 45, 58, 62, 36, 61, 58, 62, 62]\n",
            "iter 53000\n",
            "loss 0.563987842798233\n",
            "trg [1, 27, 61, 58, 38, 7, 40, 61, 3, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 58, 62, 25, 16, 3, 4, 14, 20, 40, 61, 12, 62, 61, 58, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 58, 62, 25, 36, 61, 58, 62, 3, 58, 36, 40, 61, 8, 62, 61, 58, 62, 31, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 8, 40, 61, 3, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 58, 62, 25, 9, 3, 4, 9, 40, 40, 61, 9, 62, 61, 58, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 58, 62, 25, 34, 61, 58, 62, 3, 58, 20, 40, 61, 8, 62, 61, 58, 62, 31, 62, 2]\n",
            "iter 54000\n",
            "loss 0.5802803212404251\n",
            "trg [1, 28, 61, 42, 62, 17, 23, 61, 27, 61, 60, 38, 23, 61, 30, 62, 61, 16, 62, 40, 61, 4, 62, 62, 22, 61, 60, 62, 62, 61, 27, 61, 60, 38, 23, 61, 30, 62, 61, 10, 62, 40, 61, 4, 62, 62, 4, 13, 36, 40, 61, 14, 62, 61, 60, 62, 62, 2]\n",
            "pred [1, 28, 61, 58, 62, 17, 23, 61, 27, 61, 60, 38, 23, 61, 30, 62, 61, 10, 62, 40, 61, 4, 62, 62, 4, 61, 34, 62, 62, 61, 27, 61, 60, 38, 23, 61, 30, 62, 61, 9, 62, 40, 61, 4, 62, 62, 4, 9, 20, 40, 61, 9, 62, 61, 60, 62, 62]\n",
            "iter 55000\n",
            "loss 0.5476732176542282\n",
            "trg [1, 27, 61, 58, 38, 23, 61, 30, 62, 61, 9, 62, 62, 23, 61, 36, 40, 61, 16, 62, 61, 58, 62, 3, 20, 40, 61, 16, 62, 61, 58, 62, 62, 61, 10, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 23, 61, 30, 62, 61, 9, 62, 62, 23, 61, 36, 40, 61, 9, 62, 61, 58, 62, 3, 34, 40, 61, 9, 62, 61, 58, 62, 62, 61, 9, 62]\n",
            "iter 56000\n",
            "loss 0.5344318675994874\n",
            "trg [1, 23, 61, 27, 61, 47, 38, 9, 62, 11, 9, 25, 11, 36, 40, 61, 9, 62, 61, 25, 12, 47, 31, 62, 3, 36, 40, 61, 11, 62, 61, 25, 12, 47, 31, 62, 31, 62, 61, 14, 62, 2]\n",
            "pred [1, 23, 61, 27, 61, 47, 38, 9, 62, 9, 9, 25, 9, 36, 61, 61, 9, 62, 61, 25, 9, 47, 31, 62, 62, 61, 61, 61, 9, 62, 31, 62, 31, 62, 31, 62]\n",
            "iter 57000\n",
            "loss 0.5467999279499054\n",
            "trg [1, 27, 61, 53, 38, 24, 62, 23, 61, 13, 16, 62, 61, 16, 62, 2]\n",
            "pred [1, 27, 61, 53, 38, 24, 62, 23, 61, 12, 62, 61, 61, 40, 62]\n",
            "iter 58000\n",
            "loss 0.5494094622135163\n",
            "trg [1, 27, 61, 48, 38, 23, 61, 30, 62, 61, 10, 62, 62, 23, 61, 14, 34, 61, 48, 62, 3, 4, 13, 33, 61, 48, 62, 62, 61, 14, 48, 3, 4, 14, 23, 61, 30, 62, 61, 13, 62, 62, 2]\n",
            "pred [1, 27, 61, 48, 38, 23, 61, 30, 62, 61, 10, 62, 62, 23, 61, 10, 34, 61, 48, 62, 3, 4, 9, 34, 61, 48, 62, 62, 61, 10, 48, 3, 4, 10, 23, 61, 30, 62, 61, 10, 62, 62]\n",
            "iter 59000\n",
            "loss 0.5711789274215698\n",
            "trg [1, 27, 61, 55, 38, 10, 62, 23, 61, 46, 40, 61, 55, 62, 4, 9, 62, 61, 10, 55, 3, 7, 62, 2]\n",
            "pred [1, 27, 61, 55, 38, 10, 62, 23, 61, 46, 40, 61, 55, 62, 62, 10, 62, 61, 61, 62, 61, 55, 62]\n",
            "iter 60000\n",
            "loss 0.5434442722797393\n",
            "trg [1, 27, 61, 51, 38, 7, 40, 61, 3, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 51, 62, 25, 14, 3, 7, 21, 40, 61, 12, 62, 61, 51, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 51, 62, 25, 20, 61, 51, 62, 3, 51, 20, 40, 61, 7, 62, 61, 51, 62, 31, 62, 2]\n",
            "pred [1, 27, 61, 51, 38, 8, 40, 61, 3, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 51, 62, 25, 9, 3, 4, 9, 40, 61, 9, 62, 61, 51, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 51, 62, 25, 34, 61, 51, 62, 3, 51, 20, 40, 61, 8, 62, 61, 51, 62, 31, 62]\n",
            "iter 61000\n",
            "loss 0.5309916859865189\n",
            "trg [1, 27, 61, 57, 38, 24, 62, 23, 61, 9, 57, 4, 10, 62, 61, 9, 57, 3, 11, 9, 62, 2]\n",
            "pred [1, 27, 61, 57, 38, 24, 62, 23, 61, 9, 57, 40, 61, 62, 62, 61, 57, 62, 61, 61, 57, 3, 61, 62, 62]\n",
            "iter 62000\n",
            "loss 0.5261768102645874\n",
            "trg [1, 27, 61, 48, 38, 9, 40, 61, 3, 62, 62, 23, 61, 48, 62, 61, 48, 34, 61, 48, 62, 62, 3, 4, 16, 23, 61, 20, 61, 48, 62, 62, 61, 48, 36, 61, 48, 62, 62, 2]\n",
            "pred [1, 27, 61, 48, 38, 9, 40, 61, 3, 62, 62, 23, 61, 48, 3, 61, 48, 48, 61, 48, 62, 62, 61, 48, 62, 61, 61, 48, 62, 61, 62, 62, 61, 48, 62, 61, 48, 62, 62]\n",
            "iter 63000\n",
            "loss 0.5163376092910766\n",
            "trg [1, 27, 61, 58, 38, 11, 62, 23, 61, 58, 4, 13, 62, 61, 58, 40, 61, 8, 62, 3, 4, 13, 58, 40, 61, 14, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 11, 62, 23, 61, 58, 3, 4, 10, 62, 3, 4, 58, 58, 61, 62, 62, 4, 58, 62]\n",
            "iter 64000\n",
            "loss 0.5176223343610764\n",
            "trg [1, 27, 61, 47, 38, 13, 40, 61, 3, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 47, 62, 25, 15, 3, 4, 14, 36, 40, 61, 8, 62, 61, 47, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 47, 62, 25, 34, 61, 47, 62, 3, 47, 20, 40, 61, 12, 62, 61, 47, 62, 31, 62, 2]\n",
            "pred [1, 27, 61, 47, 38, 13, 40, 61, 3, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 47, 62, 25, 8, 3, 4, 9, 20, 40, 61, 9, 62, 61, 47, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 47, 62, 25, 36, 61, 47, 62, 3, 47, 20, 40, 61, 8, 62, 61, 47, 62, 31, 62, 2]\n",
            "iter 65000\n",
            "loss 0.5099807560443879\n",
            "trg [1, 27, 61, 44, 38, 9, 40, 61, 3, 62, 62, 23, 61, 23, 61, 12, 62, 61, 44, 62, 62, 61, 4, 10, 22, 61, 44, 62, 36, 61, 44, 62, 62, 2]\n",
            "pred [1, 27, 61, 44, 38, 9, 40, 61, 3, 62, 62, 23, 61, 23, 61, 16, 62, 61, 44, 62, 62, 61, 4, 10, 20, 61, 44, 62, 36, 61, 44, 62, 62]\n",
            "iter 66000\n",
            "loss 0.5613218295574188\n",
            "trg [1, 27, 61, 48, 38, 24, 62, 23, 61, 9, 48, 40, 61, 10, 62, 62, 61, 46, 40, 61, 48, 62, 62, 2]\n",
            "pred [1, 27, 61, 48, 38, 24, 62, 23, 61, 9, 62, 40, 61, 46, 40, 61, 48, 62, 62, 61, 48, 62, 62]\n",
            "iter 67000\n",
            "loss 0.4740997278690338\n",
            "trg [1, 27, 61, 42, 38, 24, 62, 23, 61, 35, 61, 42, 40, 61, 9, 62, 3, 42, 62, 62, 61, 35, 61, 10, 42, 40, 61, 11, 62, 4, 9, 62, 62, 2]\n",
            "pred [1, 27, 61, 42, 38, 24, 62, 23, 61, 35, 61, 42, 40, 61, 10, 62, 3, 9, 62, 61, 35, 61, 61, 35, 61, 61, 62, 3, 9, 62, 62, 62, 62]\n",
            "iter 68000\n",
            "loss 0.4845511531829834\n",
            "trg [1, 27, 61, 48, 38, 11, 16, 62, 23, 61, 48, 4, 15, 7, 62, 61, 35, 61, 58, 62, 4, 8, 62, 2]\n",
            "pred [1, 27, 61, 48, 38, 10, 62, 23, 61, 35, 61, 58, 62, 61, 35, 61, 35, 61, 4, 4, 62, 62, 62, 62]\n",
            "iter 69000\n",
            "loss 0.4886350178718567\n",
            "trg [1, 28, 61, 58, 62, 17, 23, 61, 27, 61, 60, 38, 30, 6, 9, 40, 61, 4, 62, 62, 4, 10, 34, 40, 61, 9, 62, 61, 60, 62, 62, 61, 27, 61, 60, 38, 30, 6, 10, 40, 61, 4, 62, 62, 16, 20, 40, 61, 16, 62, 61, 60, 62, 21, 61, 60, 62, 62, 2]\n",
            "pred [1, 28, 61, 58, 62, 17, 23, 61, 27, 61, 60, 38, 30, 6, 9, 40, 61, 4, 62, 62, 4, 9, 20, 40, 61, 9, 62, 61, 60, 62, 62, 61, 27, 61, 60, 38, 30, 6, 9, 40, 61, 4, 62, 62, 9, 36, 40, 61, 9, 62, 61, 60, 62, 20, 61, 60, 62, 62]\n",
            "iter 1000\n",
            "loss 0.4920034557580948\n",
            "trg [1, 27, 61, 44, 38, 23, 61, 30, 62, 61, 9, 62, 62, 23, 61, 20, 40, 61, 13, 62, 61, 44, 62, 3, 20, 40, 61, 10, 62, 61, 44, 62, 62, 61, 16, 62, 2]\n",
            "pred [1, 27, 61, 44, 38, 23, 61, 30, 62, 61, 9, 62, 62, 23, 61, 20, 40, 61, 13, 62, 61, 44, 62, 3, 20, 40, 61, 14, 62, 61, 44, 62, 62, 61, 10, 62]\n",
            "iter 2000\n",
            "loss 0.47356479287147524\n",
            "trg [1, 27, 61, 59, 38, 8, 40, 61, 4, 62, 62, 23, 61, 59, 4, 8, 62, 61, 59, 40, 61, 11, 62, 3, 4, 59, 62, 2]\n",
            "pred [1, 27, 61, 59, 38, 8, 40, 61, 4, 62, 62, 23, 61, 59, 3, 4, 62, 62, 59, 40, 61, 62, 62]\n",
            "iter 3000\n",
            "loss 0.47760067999362943\n",
            "trg [1, 27, 61, 43, 38, 23, 61, 30, 62, 61, 15, 62, 62, 23, 61, 9, 34, 61, 43, 62, 3, 4, 11, 20, 61, 43, 62, 62, 61, 9, 43, 3, 4, 10, 23, 61, 30, 62, 61, 9, 62, 62, 2]\n",
            "pred [1, 27, 61, 43, 38, 23, 61, 30, 62, 61, 9, 62, 62, 23, 61, 9, 34, 61, 43, 62, 3, 4, 9, 34, 61, 43, 62, 62, 61, 9, 43, 3, 4, 9, 23, 61, 30, 62, 61, 16, 62, 62]\n",
            "iter 4000\n",
            "loss 0.4595959758758545\n",
            "trg [1, 27, 61, 57, 38, 24, 62, 23, 61, 29, 41, 61, 13, 11, 62, 61, 57, 62, 29, 41, 61, 8, 14, 62, 61, 15, 62, 62, 61, 29, 41, 61, 14, 8, 62, 61, 8, 62, 29, 41, 61, 11, 10, 62, 61, 57, 62, 62, 2]\n",
            "pred [1, 27, 61, 57, 38, 24, 62, 23, 61, 29, 41, 61, 14, 8, 62, 61, 57, 62, 29, 41, 61, 13, 11, 62, 61, 12, 62, 62, 61, 29, 41, 61, 12, 62, 61, 61, 62, 62, 29, 41, 61, 8, 7, 62, 61, 57, 62, 62]\n",
            "iter 5000\n",
            "loss 0.4809662938117981\n",
            "trg [1, 27, 61, 57, 38, 9, 40, 61, 3, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 57, 62, 25, 10, 3, 4, 11, 34, 40, 61, 8, 62, 61, 57, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 57, 62, 25, 36, 61, 57, 62, 3, 57, 36, 40, 61, 7, 62, 61, 57, 62, 31, 62, 2]\n",
            "pred [1, 27, 61, 57, 38, 9, 40, 61, 3, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 57, 62, 25, 12, 3, 4, 36, 40, 40, 61, 9, 62, 61, 57, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 57, 62, 25, 36, 61, 57, 62, 3, 57, 20, 40, 61, 9, 62, 61, 57, 62, 31, 62, 2]\n",
            "iter 6000\n",
            "loss 0.4852142071723938\n",
            "trg [1, 27, 61, 48, 38, 24, 62, 9, 48, 2]\n",
            "pred [1, 27, 61, 48, 38, 24, 62, 9, 48]\n",
            "iter 7000\n",
            "loss 0.4939931184053421\n",
            "trg [1, 27, 61, 43, 38, 24, 62, 26, 43, 4, 10, 32, 3, 43, 2]\n",
            "pred [1, 27, 61, 43, 38, 24, 62, 26, 43, 4, 10, 32, 3, 43]\n",
            "iter 8000\n",
            "loss 0.5039756613969802\n",
            "trg [1, 27, 61, 58, 38, 24, 62, 23, 61, 13, 25, 7, 3, 16, 31, 62, 61, 9, 25, 10, 58, 3, 12, 31, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 23, 61, 9, 25, 58, 3, 4, 16, 62, 3, 4, 58, 58, 3, 31, 62, 31, 62]\n",
            "iter 9000\n",
            "loss 0.48258608758449556\n",
            "trg [1, 27, 61, 57, 38, 15, 62, 23, 61, 23, 61, 45, 62, 61, 45, 57, 62, 16, 33, 61, 25, 9, 57, 31, 62, 62, 61, 23, 61, 45, 62, 61, 45, 57, 62, 14, 57, 62, 2]\n",
            "pred [1, 27, 61, 57, 38, 15, 62, 23, 61, 23, 61, 45, 62, 61, 45, 57, 62, 10, 20, 61, 25, 57, 57, 31, 62, 62, 61, 23, 61, 45, 62, 61, 45, 57, 62, 57, 62, 62]\n",
            "iter 10000\n",
            "loss 0.4798736923933029\n",
            "trg [1, 23, 61, 27, 61, 58, 38, 16, 62, 23, 61, 45, 62, 61, 45, 58, 62, 8, 15, 36, 61, 25, 15, 58, 31, 62, 20, 61, 25, 10, 58, 31, 62, 62, 61, 27, 61, 58, 38, 8, 62, 23, 61, 45, 62, 61, 45, 58, 62, 12, 58, 62, 2]\n",
            "pred [1, 23, 61, 27, 61, 58, 38, 16, 62, 23, 61, 45, 62, 61, 45, 58, 62, 25, 12, 34, 61, 25, 58, 58, 31, 62, 20, 61, 25, 58, 58, 31, 62, 62, 61, 27, 61, 58, 38, 8, 62, 23, 61, 45, 62, 61, 45, 58, 62, 58, 58, 62]\n",
            "iter 11000\n",
            "loss 0.4873086667060852\n",
            "trg [1, 27, 61, 43, 38, 24, 62, 23, 61, 13, 62, 61, 43, 40, 61, 4, 10, 62, 62, 3, 4, 9, 23, 61, 34, 61, 10, 6, 43, 62, 62, 61, 43, 40, 61, 4, 12, 62, 62, 2]\n",
            "pred [1, 27, 61, 43, 38, 24, 62, 23, 61, 43, 62, 61, 43, 40, 61, 4, 62, 62, 61, 61, 43, 61, 61, 61, 61, 61, 43, 62, 61, 43, 40, 62, 61, 40, 61, 4, 62, 62, 62]\n",
            "iter 12000\n",
            "loss 0.4498000872135162\n",
            "trg [1, 27, 61, 52, 38, 10, 40, 61, 3, 62, 62, 4, 12, 12, 22, 61, 52, 62, 2]\n",
            "pred [1, 27, 61, 52, 38, 14, 40, 61, 3, 62, 62, 4, 12, 12, 36, 61, 52, 62]\n",
            "iter 13000\n",
            "loss 0.476918523311615\n",
            "trg [1, 27, 61, 47, 38, 16, 62, 23, 61, 9, 3, 20, 61, 47, 62, 62, 61, 8, 3, 4, 9, 34, 40, 61, 9, 62, 61, 47, 62, 62, 2]\n",
            "pred [1, 27, 61, 47, 38, 8, 62, 23, 61, 9, 3, 4, 9, 20, 61, 9, 62, 62, 61, 9, 9, 20, 40, 61, 9, 62, 61, 47, 62, 62]\n",
            "iter 14000\n",
            "loss 0.4814662373065948\n",
            "trg [1, 27, 61, 48, 38, 4, 24, 62, 23, 61, 35, 61, 14, 10, 48, 40, 61, 14, 62, 4, 13, 62, 62, 61, 48, 4, 12, 14, 62, 2]\n",
            "pred [1, 27, 61, 48, 38, 4, 24, 62, 23, 61, 35, 61, 48, 40, 61, 11, 62, 62, 61, 61, 61, 61, 61, 61, 61, 48, 62, 61, 62, 62]\n",
            "iter 1000\n",
            "loss 0.6169812911748886\n",
            "trg [1, 27, 61, 42, 38, 8, 40, 61, 3, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 42, 62, 25, 11, 3, 4, 13, 36, 40, 61, 16, 62, 61, 42, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 42, 62, 25, 36, 61, 42, 62, 3, 42, 34, 40, 61, 7, 62, 61, 42, 62, 31, 62, 2]\n",
            "pred [1, 27, 61, 42, 38, 8, 40, 61, 3, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 42, 62, 25, 12, 3, 4, 36, 40, 61, 61, 62, 61, 42, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 42, 62, 25, 36, 61, 42, 62, 3, 42, 20, 40, 61, 8, 62, 61, 42, 62, 31, 62]\n",
            "iter 2000\n",
            "loss 0.6091440904140473\n",
            "trg [1, 27, 61, 37, 38, 30, 6, 13, 62, 23, 61, 9, 36, 61, 37, 62, 3, 4, 11, 34, 61, 37, 62, 62, 61, 9, 37, 3, 4, 12, 30, 6, 9, 62, 2]\n",
            "pred [1, 27, 61, 37, 38, 30, 6, 9, 62, 23, 61, 9, 36, 61, 37, 62, 3, 4, 9, 36, 61, 37, 62, 62, 61, 9, 37, 3, 4, 9, 30, 6, 9, 62]\n",
            "iter 3000\n",
            "loss 0.588226056098938\n",
            "trg [1, 27, 61, 43, 38, 7, 62, 23, 61, 43, 20, 61, 43, 62, 62, 61, 9, 3, 4, 16, 34, 61, 43, 62, 62, 2]\n",
            "pred [1, 27, 61, 43, 38, 7, 62, 23, 61, 43, 3, 4, 16, 62, 61, 43, 62, 62, 61, 43, 40, 61, 43, 62, 62]\n",
            "iter 4000\n",
            "loss 0.6032670360803604\n",
            "trg [1, 27, 61, 57, 38, 8, 40, 61, 3, 62, 62, 23, 61, 7, 36, 61, 57, 62, 36, 40, 61, 12, 62, 61, 57, 62, 62, 61, 36, 40, 61, 9, 62, 61, 57, 62, 3, 25, 12, 57, 34, 61, 57, 62, 3, 8, 31, 34, 40, 61, 12, 62, 61, 57, 62, 62, 2]\n",
            "pred [1, 27, 61, 57, 38, 8, 40, 61, 3, 62, 62, 23, 61, 7, 36, 61, 57, 62, 36, 40, 61, 8, 62, 61, 57, 62, 62, 61, 36, 40, 61, 8, 62, 61, 57, 62, 3, 25, 7, 57, 36, 61, 57, 62, 3, 8, 31, 36, 40, 61, 8, 62, 61, 57, 62, 62]\n",
            "iter 5000\n",
            "loss 0.6042360293865204\n",
            "trg [1, 27, 61, 60, 38, 23, 61, 30, 62, 61, 16, 62, 62, 23, 61, 36, 40, 61, 9, 62, 61, 60, 62, 3, 34, 40, 61, 10, 62, 61, 60, 62, 62, 61, 13, 62, 2]\n",
            "pred [1, 27, 61, 60, 38, 23, 61, 30, 62, 61, 16, 62, 62, 23, 61, 36, 40, 61, 9, 62, 61, 60, 62, 3, 34, 40, 61, 9, 62, 61, 60, 62, 62, 61, 16, 62]\n",
            "iter 6000\n",
            "loss 0.5741219383478164\n",
            "trg [1, 27, 61, 47, 38, 15, 40, 61, 4, 62, 62, 23, 61, 20, 61, 47, 62, 62, 61, 34, 40, 61, 16, 62, 61, 47, 62, 4, 15, 62, 2]\n",
            "pred [1, 27, 61, 47, 38, 15, 40, 61, 4, 62, 62, 23, 61, 34, 61, 47, 62, 62, 61, 34, 40, 61, 13, 62, 61, 47, 62, 62]\n",
            "iter 7000\n",
            "loss 0.615436982512474\n",
            "trg [1, 27, 61, 60, 38, 24, 62, 23, 61, 10, 62, 61, 60, 40, 61, 12, 62, 62, 2]\n",
            "pred [1, 27, 61, 60, 38, 24, 62, 23, 61, 10, 62, 61, 60, 62]\n",
            "iter 8000\n",
            "loss 0.5680223309993744\n",
            "trg [1, 27, 61, 58, 38, 24, 62, 23, 61, 29, 41, 61, 11, 9, 62, 61, 58, 62, 29, 41, 61, 13, 8, 62, 61, 8, 62, 62, 61, 29, 41, 61, 8, 16, 62, 61, 14, 62, 29, 41, 61, 14, 16, 62, 61, 58, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 23, 61, 29, 41, 61, 8, 8, 62, 61, 58, 62, 29, 41, 61, 8, 12, 62, 61, 8, 62, 62, 61, 29, 41, 61, 8, 8, 62, 61, 8, 62, 29, 41, 61, 8, 7, 62, 61, 58, 62, 62]\n",
            "iter 9000\n",
            "loss 0.5820618671178818\n",
            "trg [1, 27, 61, 43, 38, 24, 62, 23, 61, 29, 41, 61, 16, 10, 62, 61, 43, 62, 29, 41, 61, 9, 7, 62, 61, 12, 62, 62, 61, 29, 41, 61, 14, 14, 62, 61, 8, 62, 29, 41, 61, 8, 10, 62, 61, 43, 62, 62, 2]\n",
            "pred [1, 27, 61, 43, 38, 24, 62, 23, 61, 29, 41, 61, 16, 62, 62, 61, 43, 62, 29, 41, 61, 16, 12, 62, 61, 12, 62, 62, 61, 29, 41, 61, 12, 62, 62, 61, 8, 62, 29, 41, 61, 8, 7, 62, 61, 43, 62, 62]\n",
            "iter 10000\n",
            "loss 0.5671173697710037\n",
            "trg [1, 27, 61, 58, 38, 8, 62, 23, 61, 58, 4, 16, 40, 61, 8, 62, 4, 8, 10, 62, 61, 58, 4, 14, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 8, 62, 23, 61, 58, 4, 8, 62, 61, 58, 40, 61, 8, 62, 4, 8, 62, 61, 58, 4, 8, 62]\n",
            "iter 11000\n",
            "loss 0.5687067657709122\n",
            "trg [1, 27, 61, 51, 38, 4, 24, 62, 23, 61, 11, 7, 51, 40, 61, 13, 62, 62, 61, 10, 26, 51, 40, 61, 13, 62, 32, 62, 2]\n",
            "pred [1, 27, 61, 51, 38, 4, 24, 62, 23, 61, 10, 51, 40, 61, 61, 62, 62, 62, 61, 10, 26, 51, 40, 61, 10, 62, 32, 62]\n",
            "iter 12000\n",
            "loss 0.5731609785556793\n",
            "trg [1, 27, 61, 48, 38, 24, 62, 23, 61, 48, 40, 61, 10, 62, 3, 4, 9, 48, 3, 8, 62, 61, 16, 48, 3, 14, 62, 2]\n",
            "pred [1, 27, 61, 48, 38, 24, 62, 23, 61, 10, 48, 40, 61, 9, 62, 3, 4, 48, 48, 40, 61, 62, 62, 3, 4, 48, 40, 61]\n",
            "iter 13000\n",
            "loss 0.5640331739187241\n",
            "trg [1, 27, 61, 55, 38, 14, 62, 55, 23, 61, 16, 62, 61, 34, 61, 55, 62, 62, 2]\n",
            "pred [1, 27, 61, 55, 38, 14, 62, 23, 61, 55, 62, 61, 34, 61, 55, 62, 62, 61, 55, 62]\n",
            "iter 14000\n",
            "loss 0.57158587038517\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|        | 1/5 [13:47<55:08, 827.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\tTrain Loss:   0.894 | Train PPL:   2.446\n",
            "\tValid Loss:   0.480 | Valid PPL:   1.616\n",
            "\\Test Loss:   0.587 | Valid PPL:   1.798\n",
            "trg [1, 27, 61, 58, 38, 24, 62, 23, 61, 23, 61, 29, 41, 61, 13, 15, 62, 61, 58, 62, 62, 61, 29, 41, 61, 16, 14, 62, 61, 9, 62, 62, 62, 61, 23, 61, 29, 41, 61, 16, 8, 62, 61, 58, 62, 62, 61, 29, 41, 61, 16, 13, 62, 61, 15, 62, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 23, 61, 23, 61, 29, 41, 61, 14, 14, 62, 61, 58, 62, 62, 61, 29, 41, 61, 9, 9, 62, 61, 8, 62, 62, 62, 61, 23, 61, 29, 41, 61, 13, 62, 62, 61, 58, 62, 62, 61, 29, 41, 61, 8, 9, 62, 61, 16, 62, 62, 62]\n",
            "iter 1000\n",
            "loss 0.4986289924383163\n",
            "trg [1, 17, 27, 61, 50, 38, 15, 40, 61, 3, 62, 62, 23, 61, 28, 3, 4, 11, 25, 50, 4, 10, 31, 62, 61, 28, 61, 25, 50, 4, 8, 31, 62, 62, 2]\n",
            "pred [1, 17, 27, 61, 50, 38, 15, 40, 61, 3, 62, 62, 23, 61, 28, 61, 50, 62, 3, 4, 25, 50, 3, 4, 31, 62, 28, 61, 25, 25, 50, 3, 50, 31, 62]\n",
            "iter 2000\n",
            "loss 0.4737651437520981\n",
            "trg [1, 27, 61, 53, 38, 14, 62, 23, 61, 16, 62, 61, 53, 62, 3, 4, 11, 23, 61, 13, 62, 61, 34, 61, 53, 62, 62, 2]\n",
            "pred [1, 27, 61, 53, 38, 15, 62, 23, 61, 61, 3, 4, 61, 34, 61, 53, 62, 62, 61, 53, 3, 4, 61, 34, 61, 53, 62, 62]\n",
            "iter 3000\n",
            "loss 0.4589796149730682\n",
            "trg [1, 27, 61, 57, 38, 10, 40, 61, 3, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 57, 62, 25, 8, 3, 4, 14, 34, 40, 61, 8, 62, 61, 57, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 57, 62, 25, 20, 61, 57, 62, 3, 57, 20, 40, 61, 9, 62, 61, 57, 62, 31, 62, 2]\n",
            "pred [1, 27, 61, 57, 38, 10, 40, 61, 3, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 57, 62, 25, 10, 3, 4, 10, 20, 40, 61, 9, 62, 61, 57, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 57, 62, 25, 34, 61, 57, 62, 3, 57, 20, 40, 61, 9, 62, 61, 57, 62, 31, 62, 2]\n",
            "iter 4000\n",
            "loss 0.4621885424852371\n",
            "trg [1, 27, 61, 53, 38, 23, 61, 30, 62, 61, 16, 62, 62, 34, 40, 61, 15, 62, 61, 53, 62, 3, 34, 40, 61, 11, 62, 61, 53, 62, 2]\n",
            "pred [1, 27, 61, 53, 38, 23, 61, 30, 62, 61, 11, 62, 62, 34, 40, 61, 11, 62, 61, 53, 62, 3, 34, 40, 61, 11, 62, 61, 53, 62]\n",
            "iter 5000\n",
            "loss 0.4858662408590317\n",
            "trg [1, 27, 61, 43, 38, 9, 40, 61, 3, 62, 62, 4, 10, 9, 21, 61, 43, 62, 2]\n",
            "pred [1, 27, 61, 43, 38, 9, 40, 61, 3, 62, 62, 4, 9, 9, 20, 61, 43, 62]\n",
            "iter 6000\n",
            "loss 0.45866955041885377\n",
            "trg [1, 27, 61, 44, 38, 8, 62, 23, 61, 34, 61, 44, 62, 3, 4, 9, 20, 61, 44, 62, 62, 61, 44, 40, 61, 15, 62, 62, 2]\n",
            "pred [1, 27, 61, 44, 38, 8, 62, 23, 61, 34, 61, 44, 62, 3, 4, 9, 34, 61, 44, 62, 62, 61, 44, 62, 61, 9, 62, 62]\n",
            "iter 7000\n",
            "loss 0.46791068851947787\n",
            "trg [1, 27, 61, 58, 38, 30, 6, 15, 40, 61, 4, 62, 62, 23, 61, 36, 40, 61, 10, 62, 61, 58, 62, 62, 61, 23, 61, 12, 62, 61, 9, 58, 3, 25, 15, 30, 31, 40, 61, 9, 62, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 30, 6, 15, 40, 61, 4, 62, 62, 23, 61, 36, 40, 61, 9, 62, 61, 58, 62, 62, 61, 23, 61, 4, 62, 61, 9, 58, 3, 25, 12, 30, 31, 40, 61, 9, 62, 62, 62]\n",
            "iter 8000\n",
            "loss 0.4378039938211441\n",
            "trg [1, 17, 23, 61, 27, 61, 48, 38, 9, 62, 23, 61, 45, 62, 61, 45, 48, 62, 25, 10, 3, 7, 21, 61, 25, 7, 31, 62, 31, 62, 61, 27, 61, 48, 38, 9, 62, 23, 61, 45, 62, 61, 45, 48, 62, 7, 62, 2]\n",
            "pred [1, 23, 61, 27, 61, 48, 38, 9, 62, 23, 61, 45, 62, 61, 45, 48, 62, 25, 9, 3, 3, 4, 10, 3, 4, 10, 31, 62, 62, 61, 61, 27, 61, 48, 38, 9, 62, 23, 61, 45, 62, 61, 45, 48, 62, 46, 40, 61, 9, 62, 62]\n",
            "iter 9000\n",
            "loss 0.4319640654325485\n",
            "trg [1, 27, 61, 54, 38, 23, 61, 30, 62, 61, 11, 62, 40, 61, 4, 62, 62, 34, 61, 54, 62, 3, 4, 9, 20, 61, 54, 62, 2]\n",
            "pred [1, 27, 61, 54, 38, 23, 61, 30, 62, 61, 11, 62, 40, 61, 4, 62, 62, 34, 61, 54, 62, 3, 4, 9, 20, 61, 54, 62]\n",
            "iter 10000\n",
            "loss 0.4751976379752159\n",
            "trg [1, 27, 61, 48, 38, 15, 62, 23, 61, 8, 3, 20, 61, 48, 62, 62, 61, 8, 3, 4, 16, 22, 40, 61, 13, 62, 61, 48, 62, 62, 2]\n",
            "pred [1, 27, 61, 48, 38, 15, 62, 23, 61, 8, 3, 4, 16, 20, 40, 61, 62, 62, 3, 4, 16, 20, 61, 61, 62, 62, 61, 48, 62, 62]\n",
            "iter 11000\n",
            "loss 0.4461180564761162\n",
            "trg [1, 27, 61, 60, 38, 10, 62, 23, 61, 22, 61, 60, 62, 3, 14, 62, 61, 60, 62, 2]\n",
            "pred [1, 27, 61, 60, 38, 10, 62, 23, 61, 20, 61, 60, 62, 3, 14, 62, 61, 60, 62]\n",
            "iter 12000\n",
            "loss 0.43162643671035766\n",
            "trg [1, 27, 61, 43, 38, 4, 8, 62, 23, 61, 9, 25, 43, 40, 61, 14, 62, 3, 4, 10, 43, 4, 10, 31, 62, 61, 43, 3, 11, 62, 2]\n",
            "pred [1, 27, 61, 43, 38, 4, 8, 62, 23, 61, 9, 25, 43, 40, 61, 61, 62, 3, 43, 3, 62, 61, 43, 3, 3, 3, 4, 10, 62]\n",
            "iter 13000\n",
            "loss 0.42014689385890963\n",
            "trg [1, 27, 61, 58, 38, 10, 40, 61, 3, 62, 62, 23, 61, 9, 62, 61, 11, 3, 9, 58, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 10, 40, 61, 3, 62, 62, 23, 61, 9, 62, 61, 9, 3, 9, 58, 62, 62, 9, 62, 62]\n",
            "iter 14000\n",
            "loss 0.39255732953548433\n",
            "trg [1, 27, 61, 43, 38, 16, 62, 23, 61, 43, 40, 61, 15, 62, 3, 4, 14, 43, 40, 61, 7, 62, 3, 14, 9, 43, 62, 61, 7, 3, 7, 62, 2]\n",
            "pred [1, 27, 61, 43, 38, 16, 62, 23, 61, 43, 40, 61, 14, 62, 3, 7, 43, 3, 7, 62, 61, 62, 61, 61, 40, 61, 7, 62, 3, 7, 62]\n",
            "iter 15000\n",
            "loss 0.4345785304903984\n",
            "trg [1, 27, 61, 59, 38, 7, 62, 4, 15, 23, 61, 10, 59, 62, 61, 35, 61, 59, 3, 7, 62, 62, 2]\n",
            "pred [1, 27, 61, 59, 38, 7, 62, 4, 15, 23, 61, 15, 59, 61, 35, 61, 59, 3, 59, 59, 62, 3, 59, 62, 62]\n",
            "iter 16000\n",
            "loss 0.39177446901798246\n",
            "trg [1, 27, 61, 56, 38, 4, 24, 62, 10, 56, 40, 61, 8, 62, 3, 56, 40, 61, 9, 62, 2]\n",
            "pred [1, 27, 61, 56, 38, 4, 24, 62, 10, 56, 40, 61, 8, 62, 3, 9, 40, 61, 9, 62]\n",
            "iter 17000\n",
            "loss 0.3768742397427559\n",
            "trg [1, 27, 61, 51, 38, 11, 40, 61, 3, 62, 62, 46, 40, 61, 23, 61, 12, 62, 61, 14, 3, 28, 61, 51, 62, 62, 28, 61, 51, 62, 62, 2]\n",
            "pred [1, 27, 61, 51, 38, 11, 40, 61, 3, 62, 62, 46, 40, 61, 23, 61, 12, 62, 61, 51, 3, 12, 62, 61, 28, 61, 51, 62, 62, 62, 62]\n",
            "iter 18000\n",
            "loss 0.40123376458883286\n",
            "trg [1, 27, 61, 55, 38, 23, 61, 30, 62, 61, 9, 62, 62, 23, 61, 20, 40, 61, 10, 62, 61, 55, 62, 3, 22, 40, 61, 11, 62, 61, 55, 62, 62, 61, 16, 62, 2]\n",
            "pred [1, 27, 61, 55, 38, 23, 61, 30, 62, 61, 9, 62, 62, 23, 61, 20, 40, 61, 10, 62, 61, 55, 62, 3, 22, 40, 61, 11, 62, 61, 55, 62, 62, 61, 16, 62]\n",
            "iter 19000\n",
            "loss 0.37709410429000856\n",
            "trg [1, 27, 61, 53, 38, 24, 62, 23, 61, 29, 41, 61, 12, 12, 62, 61, 53, 62, 62, 61, 29, 41, 61, 14, 10, 62, 61, 8, 62, 62, 23, 61, 29, 41, 61, 10, 10, 62, 61, 16, 62, 62, 61, 29, 41, 61, 8, 12, 62, 61, 53, 62, 62, 2]\n",
            "pred [1, 27, 61, 53, 38, 24, 62, 23, 61, 29, 41, 61, 12, 14, 62, 61, 53, 62, 62, 61, 29, 41, 61, 12, 12, 62, 61, 9, 62, 62, 23, 61, 29, 41, 61, 8, 10, 62, 61, 9, 62, 62, 61, 29, 41, 61, 8, 10, 62, 61, 53, 62, 62]\n",
            "iter 20000\n",
            "loss 0.33886959195137023\n",
            "trg [1, 27, 61, 44, 38, 4, 16, 62, 23, 61, 12, 44, 40, 61, 12, 62, 3, 4, 14, 44, 3, 11, 4, 13, 62, 61, 44, 3, 10, 62, 2]\n",
            "pred [1, 27, 61, 44, 38, 4, 16, 62, 23, 61, 12, 44, 40, 61, 12, 62, 3, 4, 13, 44, 3, 62, 61, 44, 3, 3, 4, 3, 4, 62]\n",
            "iter 21000\n",
            "loss 0.35311018854379655\n",
            "trg [1, 23, 61, 14, 62, 61, 14, 62, 27, 61, 44, 38, 24, 62, 23, 61, 23, 61, 14, 36, 61, 23, 61, 9, 62, 61, 44, 62, 62, 62, 61, 44, 40, 61, 9, 62, 62, 62, 61, 23, 61, 4, 15, 62, 61, 44, 40, 61, 10, 62, 62, 62, 2]\n",
            "pred [1, 23, 61, 9, 62, 61, 14, 62, 27, 61, 44, 38, 24, 62, 23, 61, 23, 61, 23, 61, 9, 23, 61, 9, 62, 61, 44, 62, 62, 62, 61, 23, 61, 61, 62, 61, 62, 62, 62, 23, 61, 61, 62, 61, 61, 61, 62, 62, 62, 62, 62, 62]\n",
            "iter 22000\n",
            "loss 0.36992916256189345\n",
            "trg [1, 27, 61, 42, 38, 23, 61, 30, 62, 61, 9, 62, 62, 23, 61, 36, 61, 42, 62, 4, 10, 62, 61, 20, 40, 61, 10, 62, 61, 42, 62, 3, 9, 34, 61, 42, 62, 4, 13, 62, 2]\n",
            "pred [1, 27, 61, 42, 38, 23, 61, 30, 62, 61, 9, 62, 62, 23, 61, 36, 61, 42, 62, 4, 9, 62, 61, 20, 40, 61, 10, 62, 61, 42, 62, 4, 9, 23, 61, 42, 62, 4, 13, 62]\n",
            "iter 23000\n",
            "loss 0.3254374605417252\n",
            "trg [1, 28, 61, 58, 62, 17, 23, 61, 27, 61, 52, 38, 23, 61, 30, 62, 61, 16, 62, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 52, 62, 33, 61, 52, 62, 62, 61, 27, 61, 52, 38, 23, 61, 30, 62, 61, 12, 62, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 52, 62, 4, 9, 36, 40, 61, 11, 62, 61, 52, 62, 62, 2]\n",
            "pred [1, 28, 61, 57, 62, 17, 23, 61, 27, 61, 52, 38, 23, 61, 30, 62, 61, 16, 62, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 52, 62, 20, 61, 52, 62, 62, 61, 27, 61, 52, 38, 23, 61, 30, 62, 61, 12, 62, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 52, 62, 4, 9, 36, 40, 61, 11, 62, 61, 52, 62, 62, 2]\n",
            "iter 24000\n",
            "loss 0.38225596815347673\n",
            "trg [1, 27, 61, 59, 38, 13, 40, 61, 3, 62, 62, 23, 61, 4, 11, 34, 61, 59, 62, 34, 40, 61, 8, 62, 61, 59, 62, 62, 61, 25, 8, 3, 14, 59, 34, 61, 59, 62, 31, 34, 40, 61, 12, 62, 61, 59, 62, 62, 2]\n",
            "pred [1, 27, 61, 59, 38, 13, 40, 61, 3, 62, 62, 23, 61, 4, 11, 34, 61, 59, 62, 34, 40, 61, 8, 62, 61, 59, 62, 62, 61, 25, 8, 3, 14, 59, 34, 61, 59, 62, 31, 34, 40, 61, 12, 62, 61, 59, 62, 62]\n",
            "iter 25000\n",
            "loss 0.3675989556312561\n",
            "trg [1, 28, 61, 54, 62, 17, 23, 61, 27, 61, 58, 38, 9, 40, 61, 3, 62, 62, 23, 61, 45, 62, 61, 45, 58, 62, 26, 28, 61, 58, 62, 32, 62, 61, 27, 61, 58, 38, 16, 40, 61, 3, 62, 62, 23, 61, 45, 62, 61, 45, 58, 62, 9, 6, 58, 62, 2]\n",
            "pred [1, 28, 61, 58, 62, 17, 23, 61, 27, 61, 58, 38, 9, 40, 61, 3, 62, 62, 23, 61, 45, 62, 61, 45, 58, 62, 26, 28, 61, 58, 62, 32, 62, 61, 27, 61, 58, 38, 16, 40, 61, 3, 62, 62, 23, 61, 45, 62, 61, 45, 58, 62, 23, 6, 58, 62]\n",
            "iter 26000\n",
            "loss 0.3422182038426399\n",
            "trg [1, 27, 61, 47, 38, 16, 40, 61, 3, 62, 62, 23, 61, 4, 20, 61, 47, 62, 36, 40, 61, 10, 62, 61, 47, 62, 62, 61, 25, 8, 3, 7, 36, 61, 47, 62, 31, 34, 40, 61, 10, 62, 61, 47, 62, 62, 2]\n",
            "pred [1, 27, 61, 47, 38, 16, 40, 61, 3, 62, 62, 23, 61, 4, 20, 61, 47, 62, 36, 40, 61, 10, 62, 61, 47, 62, 62, 61, 25, 8, 3, 7, 36, 61, 47, 62, 31, 34, 40, 61, 10, 62, 61, 10, 62, 62]\n",
            "iter 27000\n",
            "loss 0.30320101112127307\n",
            "trg [1, 27, 61, 42, 38, 9, 62, 23, 61, 22, 61, 10, 62, 42, 62, 61, 34, 61, 9, 62, 42, 62, 2]\n",
            "pred [1, 27, 61, 42, 38, 9, 62, 23, 61, 36, 61, 10, 62, 42, 62, 61, 34, 61, 10, 62, 42, 62]\n",
            "iter 28000\n",
            "loss 0.28728494346141814\n",
            "trg [1, 27, 61, 52, 38, 30, 62, 23, 61, 20, 61, 52, 62, 3, 16, 62, 61, 52, 3, 25, 4, 13, 30, 31, 40, 61, 9, 62, 62, 2]\n",
            "pred [1, 27, 61, 52, 38, 30, 62, 23, 61, 20, 61, 52, 62, 3, 13, 62, 61, 52, 25, 52, 3, 25, 31, 31, 62, 61, 52, 62]\n",
            "iter 29000\n",
            "loss 0.3346970793604851\n",
            "trg [1, 23, 61, 9, 62, 61, 9, 62, 27, 61, 54, 38, 9, 62, 23, 61, 34, 61, 25, 9, 54, 31, 62, 62, 61, 11, 54, 62, 2]\n",
            "pred [1, 23, 61, 9, 62, 61, 9, 62, 27, 61, 54, 38, 9, 62, 23, 61, 34, 61, 25, 9, 54, 31, 62, 62, 61, 11, 54, 62]\n",
            "iter 30000\n",
            "loss 0.3475130072236061\n",
            "trg [1, 28, 61, 54, 62, 17, 23, 61, 27, 61, 44, 38, 30, 6, 10, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 44, 62, 20, 61, 44, 62, 62, 61, 27, 61, 44, 38, 30, 6, 16, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 44, 62, 4, 10, 34, 40, 61, 10, 62, 61, 44, 62, 62, 2]\n",
            "pred [1, 28, 61, 58, 62, 17, 23, 61, 27, 61, 44, 38, 30, 6, 10, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 44, 62, 20, 61, 44, 62, 62, 61, 27, 61, 44, 38, 30, 6, 16, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 44, 62, 4, 10, 34, 40, 61, 10, 62, 61, 44, 62, 62]\n",
            "iter 31000\n",
            "loss 0.30535121202468873\n",
            "trg [1, 27, 61, 51, 38, 23, 61, 30, 62, 61, 16, 62, 62, 23, 61, 34, 40, 61, 12, 62, 61, 51, 62, 3, 22, 40, 61, 9, 62, 61, 51, 62, 62, 61, 12, 62, 2]\n",
            "pred [1, 27, 61, 51, 38, 23, 61, 30, 62, 61, 16, 62, 62, 23, 61, 34, 40, 61, 12, 62, 61, 51, 62, 3, 22, 40, 61, 9, 62, 61, 51, 62, 62, 61, 12, 62]\n",
            "iter 32000\n",
            "loss 0.29020517140626906\n",
            "trg [1, 27, 61, 47, 38, 10, 40, 61, 3, 62, 62, 46, 40, 61, 28, 61, 25, 16, 3, 47, 40, 61, 21, 61, 47, 62, 62, 31, 62, 62, 2]\n",
            "pred [1, 27, 61, 47, 38, 10, 40, 61, 3, 62, 62, 46, 40, 61, 28, 61, 25, 16, 3, 47, 40, 61, 21, 61, 47, 62, 62, 31, 62, 62]\n",
            "iter 33000\n",
            "loss 0.2699781364202499\n",
            "trg [1, 27, 61, 60, 38, 23, 61, 30, 62, 61, 11, 62, 40, 61, 4, 62, 62, 23, 61, 34, 40, 61, 13, 62, 61, 60, 62, 62, 61, 23, 61, 11, 62, 61, 10, 60, 3, 25, 9, 30, 31, 40, 61, 14, 62, 62, 62, 2]\n",
            "pred [1, 27, 61, 60, 38, 23, 61, 30, 62, 61, 11, 62, 40, 61, 4, 62, 62, 23, 61, 34, 40, 61, 13, 62, 61, 60, 62, 62, 61, 23, 61, 4, 62, 61, 10, 10, 3, 25, 9, 30, 31, 40, 61, 14, 62, 62, 62]\n",
            "iter 34000\n",
            "loss 0.30563103795051577\n",
            "trg [1, 27, 61, 37, 38, 4, 24, 62, 23, 61, 12, 15, 37, 40, 61, 7, 62, 62, 61, 7, 26, 37, 40, 61, 15, 62, 32, 62, 2]\n",
            "pred [1, 27, 61, 37, 38, 4, 24, 62, 23, 61, 12, 37, 40, 61, 7, 62, 62, 61, 12, 26, 37, 40, 61, 61, 15, 62, 32, 62]\n",
            "iter 35000\n",
            "loss 0.28600582748651504\n",
            "trg [1, 27, 61, 58, 38, 24, 62, 23, 61, 15, 62, 61, 46, 40, 61, 9, 58, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 23, 61, 15, 62, 61, 46, 40, 61, 15, 58, 62, 62]\n",
            "iter 36000\n",
            "loss 0.2871410001814365\n",
            "trg [1, 27, 61, 50, 38, 13, 62, 23, 61, 34, 61, 25, 12, 50, 31, 62, 36, 61, 25, 9, 50, 31, 62, 23, 61, 10, 62, 61, 9, 62, 23, 61, 9, 62, 61, 50, 62, 62, 61, 34, 61, 25, 9, 50, 31, 62, 23, 61, 13, 62, 61, 10, 62, 23, 61, 9, 62, 61, 50, 62, 62, 2]\n",
            "pred [1, 27, 61, 50, 38, 13, 62, 23, 61, 34, 61, 25, 12, 50, 31, 62, 36, 61, 25, 9, 50, 31, 62, 23, 61, 9, 62, 61, 50, 62, 23, 61, 9, 62, 61, 50, 62, 62, 61, 25, 14, 50, 9, 50, 31, 62, 23, 61, 10, 62, 61, 14, 62, 23, 61, 13, 62, 61, 50, 62, 62]\n",
            "iter 37000\n",
            "loss 0.25717055827379226\n",
            "trg [1, 23, 61, 27, 61, 57, 38, 46, 62, 23, 61, 45, 62, 61, 45, 57, 62, 25, 28, 61, 57, 62, 4, 11, 31, 62, 61, 27, 61, 57, 38, 46, 62, 23, 61, 45, 62, 61, 45, 57, 62, 25, 57, 3, 4, 13, 46, 31, 62, 2]\n",
            "pred [1, 23, 61, 27, 61, 57, 38, 46, 62, 23, 61, 45, 62, 61, 45, 57, 62, 25, 28, 61, 25, 62, 3, 57, 31, 62, 61, 27, 61, 57, 38, 38, 62, 23, 61, 45, 62, 61, 45, 57, 62, 25, 57, 4, 4, 11, 46, 62]\n",
            "iter 38000\n",
            "loss 0.263900171816349\n",
            "trg [1, 27, 61, 60, 38, 23, 61, 30, 62, 61, 13, 62, 40, 61, 4, 62, 62, 23, 61, 33, 40, 61, 9, 62, 61, 60, 62, 62, 61, 23, 61, 4, 10, 62, 61, 9, 60, 3, 25, 4, 16, 30, 31, 40, 61, 12, 62, 62, 62, 2]\n",
            "pred [1, 27, 61, 60, 38, 23, 61, 30, 62, 61, 13, 62, 40, 61, 4, 62, 62, 23, 61, 33, 40, 61, 9, 62, 61, 60, 62, 62, 61, 23, 61, 4, 10, 62, 61, 16, 60, 3, 25, 4, 10, 30, 31, 40, 61, 12, 62, 62, 62]\n",
            "iter 39000\n",
            "loss 0.25603410705924035\n",
            "trg [1, 27, 61, 55, 38, 30, 6, 9, 62, 20, 40, 61, 13, 62, 61, 55, 62, 3, 27, 61, 55, 38, 30, 6, 12, 62, 22, 40, 61, 16, 62, 61, 55, 62, 2]\n",
            "pred [1, 27, 61, 55, 38, 30, 6, 9, 62, 20, 40, 61, 13, 62, 61, 55, 62, 3, 27, 61, 55, 38, 30, 6, 12, 62, 22, 40, 61, 16, 62, 61, 55, 62]\n",
            "iter 40000\n",
            "loss 0.2860546565055847\n",
            "trg [1, 27, 61, 51, 38, 16, 40, 61, 3, 62, 62, 23, 61, 9, 6, 51, 62, 61, 4, 9, 20, 61, 51, 62, 22, 61, 51, 62, 62, 2]\n",
            "pred [1, 27, 61, 51, 38, 16, 40, 61, 3, 62, 62, 23, 61, 9, 6, 51, 62, 61, 4, 9, 20, 61, 51, 62, 22, 61, 51, 62, 62]\n",
            "iter 41000\n",
            "loss 0.24387601494789124\n",
            "trg [1, 27, 61, 48, 38, 23, 61, 30, 62, 61, 10, 62, 62, 23, 61, 16, 36, 61, 48, 62, 3, 4, 10, 33, 61, 48, 62, 62, 61, 9, 48, 3, 4, 13, 23, 61, 30, 62, 61, 12, 62, 62, 2]\n",
            "pred [1, 27, 61, 48, 38, 23, 61, 30, 62, 61, 10, 62, 62, 23, 61, 16, 36, 61, 48, 62, 3, 4, 10, 33, 61, 48, 62, 62, 61, 9, 48, 3, 4, 13, 23, 61, 30, 62, 61, 12, 62, 62]\n",
            "iter 42000\n",
            "loss 0.2440240600705147\n",
            "trg [1, 27, 61, 55, 38, 10, 40, 61, 3, 62, 62, 23, 61, 9, 6, 55, 62, 61, 4, 9, 22, 61, 55, 62, 34, 61, 55, 62, 62, 2]\n",
            "pred [1, 27, 61, 55, 38, 10, 40, 61, 3, 62, 62, 23, 61, 9, 6, 55, 62, 61, 4, 9, 22, 61, 55, 62, 34, 61, 55, 62, 62]\n",
            "iter 43000\n",
            "loss 0.27090538769960404\n",
            "trg [1, 27, 61, 57, 38, 30, 6, 10, 62, 36, 40, 61, 9, 62, 61, 57, 62, 3, 34, 40, 61, 12, 62, 61, 57, 62, 2]\n",
            "pred [1, 27, 61, 57, 38, 30, 6, 10, 62, 36, 40, 61, 9, 62, 61, 57, 62, 3, 34, 40, 61, 12, 62, 61, 57, 62]\n",
            "iter 44000\n",
            "loss 0.26485265523195267\n",
            "trg [1, 27, 61, 52, 38, 16, 40, 61, 3, 62, 62, 23, 61, 20, 61, 52, 62, 62, 61, 52, 62, 27, 61, 52, 38, 15, 40, 61, 3, 62, 62, 35, 61, 52, 25, 12, 3, 16, 52, 31, 62, 2]\n",
            "pred [1, 27, 61, 52, 38, 16, 40, 61, 3, 62, 62, 23, 61, 20, 61, 52, 62, 62, 61, 52, 62, 27, 61, 52, 38, 15, 40, 61, 3, 62, 62, 35, 61, 52, 25, 12, 3, 16, 31, 62, 62]\n",
            "iter 45000\n",
            "loss 0.23380330070853234\n",
            "trg [1, 27, 61, 57, 38, 15, 40, 61, 4, 62, 62, 4, 9, 33, 61, 57, 62, 2]\n",
            "pred [1, 27, 61, 57, 38, 15, 40, 61, 4, 62, 62, 4, 9, 33, 61, 57, 62]\n",
            "iter 46000\n",
            "loss 0.225044097751379\n",
            "trg [1, 27, 61, 51, 38, 11, 40, 61, 3, 62, 62, 23, 61, 4, 34, 61, 51, 62, 62, 61, 15, 3, 51, 36, 61, 51, 62, 62, 2]\n",
            "pred [1, 27, 61, 51, 38, 11, 40, 61, 3, 62, 62, 23, 61, 4, 34, 61, 51, 62, 62, 61, 15, 3, 4, 36, 61, 51, 62, 62]\n",
            "iter 47000\n",
            "loss 0.24495458483695984\n",
            "trg [1, 23, 61, 27, 61, 57, 38, 9, 62, 12, 25, 23, 61, 14, 62, 61, 16, 62, 25, 15, 57, 3, 25, 4, 9, 57, 40, 61, 16, 62, 31, 40, 61, 23, 61, 16, 62, 61, 12, 62, 62, 31, 25, 10, 3, 4, 14, 57, 40, 61, 9, 62, 31, 3, 4, 10, 23, 61, 45, 62, 61, 45, 57, 62, 35, 18, 10, 39, 61, 58, 62, 31, 62, 61, 27, 61, 57, 38, 9, 62, 23, 61, 45, 62, 61, 45, 57, 62, 9, 3, 4, 14, 23, 61, 45, 62, 61, 45, 57, 62, 57, 40, 61, 23, 61, 14, 62, 61, 12, 62, 62, 62, 2]\n",
            "pred [1, 23, 61, 27, 61, 57, 38, 9, 62, 12, 25, 23, 61, 16, 62, 61, 25, 61, 25, 57, 57, 57, 3, 4, 9, 57, 40, 61, 9, 62, 31, 62, 61, 9, 62, 31, 62, 61, 62, 61, 61, 4, 9, 62, 31, 62, 61, 62, 61, 4, 9, 57, 31, 62, 61, 9, 62, 61, 9, 62, 61, 57, 62, 31, 62, 61, 62, 62, 61, 61, 45, 62, 61, 45, 45, 57, 61, 45, 57, 62, 23, 61, 45, 62, 61, 45, 57, 62, 23, 61, 45, 62, 61, 45, 57, 62, 23, 61, 45, 62, 61, 45, 57, 62, 61, 45, 62, 62, 62, 62, 62, 62, 2]\n",
            "iter 48000\n",
            "loss 0.24080976828932762\n",
            "trg [1, 46, 40, 61, 27, 61, 43, 38, 10, 40, 61, 3, 62, 62, 10, 23, 61, 28, 61, 43, 62, 62, 61, 10, 6, 43, 62, 62, 2]\n",
            "pred [1, 46, 40, 61, 27, 61, 43, 38, 10, 40, 61, 3, 62, 62, 10, 23, 61, 28, 61, 43, 62, 62, 61, 10, 43, 62, 62, 62, 62, 62]\n",
            "iter 49000\n",
            "loss 0.23535781145095824\n",
            "trg [1, 27, 61, 59, 38, 16, 40, 61, 3, 62, 62, 23, 61, 4, 9, 36, 61, 59, 62, 36, 40, 61, 13, 62, 61, 59, 62, 62, 61, 25, 7, 3, 59, 20, 61, 59, 62, 31, 36, 40, 61, 15, 62, 61, 59, 62, 62, 2]\n",
            "pred [1, 27, 61, 59, 38, 16, 40, 61, 3, 62, 62, 23, 61, 4, 9, 36, 61, 59, 62, 36, 40, 61, 13, 62, 61, 59, 62, 62, 61, 25, 7, 3, 59, 20, 61, 59, 62, 31, 36, 40, 61, 15, 62, 61, 59, 62, 62]\n",
            "iter 50000\n",
            "loss 0.24658568307757378\n",
            "trg [1, 27, 61, 52, 38, 10, 40, 61, 3, 62, 62, 23, 61, 52, 25, 14, 3, 4, 9, 52, 31, 62, 61, 52, 25, 52, 3, 52, 28, 61, 52, 62, 4, 12, 31, 62, 2]\n",
            "pred [1, 27, 61, 52, 38, 10, 40, 61, 3, 62, 62, 23, 61, 52, 25, 14, 62, 61, 52, 31, 62, 31, 62, 61, 52, 31, 25, 52, 3, 52, 31, 62, 31, 62, 62]\n",
            "iter 51000\n",
            "loss 0.2330361671745777\n",
            "trg [1, 23, 61, 46, 40, 61, 23, 61, 27, 61, 57, 38, 16, 62, 23, 61, 45, 62, 61, 45, 57, 62, 28, 61, 25, 14, 3, 12, 57, 31, 62, 62, 61, 9, 62, 62, 62, 61, 10, 46, 40, 61, 11, 62, 62, 2]\n",
            "pred [1, 23, 61, 46, 40, 61, 27, 61, 27, 61, 57, 38, 16, 62, 23, 61, 45, 62, 61, 45, 57, 62, 28, 61, 25, 14, 3, 12, 57, 31, 62, 62, 62, 61, 61, 61, 62, 62, 62, 46, 40, 61, 11, 62, 62, 62]\n",
            "iter 52000\n",
            "loss 0.2053966687619686\n",
            "trg [1, 27, 61, 58, 38, 14, 40, 61, 3, 62, 62, 23, 61, 14, 3, 7, 20, 40, 61, 12, 62, 61, 58, 62, 62, 61, 36, 61, 58, 62, 3, 58, 20, 40, 61, 15, 62, 61, 58, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 14, 40, 61, 3, 62, 62, 23, 61, 14, 3, 7, 20, 40, 61, 12, 62, 61, 58, 62, 62, 61, 36, 61, 58, 62, 3, 58, 20, 40, 61, 15, 62, 61, 58, 62, 62]\n",
            "iter 53000\n",
            "loss 0.21072623685002326\n",
            "trg [1, 27, 61, 59, 38, 11, 40, 61, 3, 62, 62, 23, 61, 4, 36, 61, 59, 62, 34, 40, 61, 12, 62, 61, 59, 62, 62, 61, 20, 40, 61, 9, 62, 61, 59, 62, 3, 25, 10, 59, 36, 61, 59, 62, 3, 16, 31, 20, 40, 61, 8, 62, 61, 59, 62, 62, 2]\n",
            "pred [1, 27, 61, 59, 38, 11, 40, 61, 3, 62, 62, 23, 61, 4, 36, 61, 59, 62, 34, 40, 61, 12, 62, 61, 59, 62, 62, 61, 20, 40, 61, 9, 62, 61, 59, 62, 3, 25, 10, 59, 36, 61, 59, 62, 3, 16, 31, 20, 40, 61, 8, 62, 61, 59, 62, 62]\n",
            "iter 54000\n",
            "loss 0.21591382578015328\n",
            "trg [1, 27, 61, 48, 38, 23, 61, 30, 62, 61, 15, 62, 62, 23, 61, 33, 40, 61, 10, 62, 61, 48, 62, 3, 20, 40, 61, 9, 62, 61, 48, 62, 62, 61, 15, 62, 2]\n",
            "pred [1, 27, 61, 48, 38, 23, 61, 30, 62, 61, 15, 62, 62, 23, 61, 33, 40, 61, 10, 62, 61, 48, 62, 3, 20, 40, 61, 9, 62, 61, 48, 62, 62, 61, 15, 62]\n",
            "iter 55000\n",
            "loss 0.2238402333855629\n",
            "trg [1, 28, 61, 57, 62, 17, 23, 61, 27, 61, 50, 38, 30, 6, 16, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 50, 62, 21, 61, 50, 62, 62, 61, 27, 61, 50, 38, 30, 6, 16, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 50, 62, 4, 16, 34, 40, 61, 14, 62, 61, 50, 62, 62, 2]\n",
            "pred [1, 28, 61, 58, 62, 17, 23, 61, 27, 61, 50, 38, 30, 6, 16, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 50, 62, 21, 61, 50, 62, 62, 61, 27, 61, 50, 38, 30, 6, 16, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 50, 62, 4, 16, 34, 40, 61, 14, 62, 61, 50, 62, 62, 2]\n",
            "iter 56000\n",
            "loss 0.23656033590435982\n",
            "trg [1, 27, 61, 52, 38, 8, 40, 61, 3, 62, 62, 36, 40, 61, 34, 61, 25, 52, 31, 62, 62, 25, 52, 31, 2]\n",
            "pred [1, 27, 61, 52, 38, 8, 40, 61, 3, 62, 62, 36, 40, 61, 34, 61, 25, 52, 31, 62, 62, 25, 52, 31]\n",
            "iter 57000\n",
            "loss 0.21990267366170882\n",
            "trg [1, 17, 27, 61, 58, 38, 10, 62, 23, 61, 11, 3, 4, 9, 25, 10, 3, 4, 11, 34, 40, 61, 8, 62, 61, 58, 62, 31, 62, 61, 34, 61, 58, 62, 62, 2]\n",
            "pred [1, 17, 27, 61, 58, 38, 10, 62, 23, 61, 10, 3, 4, 9, 25, 10, 3, 4, 11, 34, 40, 61, 8, 62, 61, 58, 62, 31, 62, 61, 34, 61, 58, 62, 62]\n",
            "iter 58000\n",
            "loss 0.22413645803928375\n",
            "trg [1, 27, 61, 59, 38, 24, 62, 23, 61, 9, 62, 61, 59, 40, 61, 15, 62, 62, 3, 12, 23, 61, 59, 34, 61, 23, 61, 10, 62, 61, 59, 62, 62, 62, 61, 59, 40, 61, 10, 62, 62, 2]\n",
            "pred [1, 27, 61, 59, 38, 24, 62, 23, 61, 9, 62, 61, 59, 40, 61, 15, 62, 62, 3, 12, 23, 61, 34, 61, 61, 61, 61, 62, 62, 61, 59, 62, 62, 62, 61, 59, 40, 61, 10, 62, 62, 62]\n",
            "iter 59000\n",
            "loss 0.22563693597912787\n",
            "trg [1, 27, 61, 59, 38, 16, 40, 61, 3, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 59, 62, 25, 12, 3, 4, 15, 34, 40, 61, 9, 62, 61, 59, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 59, 62, 25, 34, 61, 59, 62, 3, 59, 36, 40, 61, 16, 62, 61, 59, 62, 31, 62, 2]\n",
            "pred [1, 27, 61, 59, 38, 16, 40, 61, 3, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 59, 62, 25, 12, 3, 4, 15, 34, 40, 61, 9, 62, 61, 59, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 59, 62, 25, 34, 61, 59, 62, 3, 59, 36, 40, 61, 16, 62, 61, 59, 62, 31, 62]\n",
            "iter 60000\n",
            "loss 0.2335258235037327\n",
            "trg [1, 27, 61, 48, 38, 23, 61, 30, 62, 61, 9, 62, 62, 23, 61, 12, 20, 40, 61, 9, 62, 61, 48, 62, 3, 4, 9, 33, 40, 61, 15, 62, 61, 48, 62, 62, 61, 10, 62, 2]\n",
            "pred [1, 27, 61, 48, 38, 23, 61, 30, 62, 61, 9, 62, 62, 23, 61, 12, 20, 40, 61, 9, 62, 61, 48, 62, 3, 4, 9, 33, 40, 61, 15, 62, 61, 48, 62, 62, 61, 10, 62]\n",
            "iter 61000\n",
            "loss 0.21741154834628104\n",
            "trg [1, 27, 61, 55, 38, 10, 62, 55, 40, 61, 9, 62, 34, 61, 23, 61, 16, 62, 61, 55, 62, 62, 2]\n",
            "pred [1, 27, 61, 55, 38, 10, 62, 55, 40, 61, 9, 62, 34, 61, 23, 61, 62, 62, 61, 55, 62, 62]\n",
            "iter 62000\n",
            "loss 0.20252830445766448\n",
            "trg [1, 27, 61, 54, 38, 13, 40, 61, 3, 62, 62, 54, 28, 61, 54, 62, 2]\n",
            "pred [1, 27, 61, 54, 38, 13, 40, 61, 3, 62, 62, 54, 28, 61, 54, 62]\n",
            "iter 63000\n",
            "loss 0.1928946040570736\n",
            "trg [1, 23, 61, 16, 62, 61, 15, 62, 27, 61, 57, 38, 24, 62, 23, 61, 57, 20, 61, 23, 61, 15, 62, 61, 57, 62, 62, 62, 61, 12, 62, 2]\n",
            "pred [1, 23, 61, 15, 62, 61, 16, 62, 27, 61, 57, 38, 24, 62, 23, 61, 57, 20, 61, 23, 61, 12, 62, 61, 57, 62, 62, 62, 61, 12, 40, 61]\n",
            "iter 64000\n",
            "loss 0.2226423864066601\n",
            "trg [1, 27, 61, 58, 38, 24, 62, 23, 61, 29, 41, 61, 9, 12, 62, 61, 58, 62, 29, 41, 61, 10, 16, 62, 61, 8, 62, 62, 61, 29, 41, 61, 14, 8, 62, 61, 12, 62, 29, 41, 61, 11, 9, 62, 61, 58, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 23, 61, 29, 41, 61, 9, 12, 62, 61, 58, 62, 29, 41, 61, 10, 16, 62, 61, 8, 62, 62, 61, 29, 41, 61, 14, 8, 62, 61, 12, 62, 29, 41, 61, 11, 9, 62, 61, 58, 62, 62]\n",
            "iter 65000\n",
            "loss 0.21743533074855803\n",
            "trg [1, 27, 61, 50, 38, 10, 62, 23, 61, 23, 61, 45, 62, 61, 45, 50, 62, 25, 46, 40, 61, 50, 62, 3, 4, 11, 20, 61, 50, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 50, 62, 25, 8, 50, 40, 61, 15, 62, 3, 10, 11, 50, 40, 61, 15, 62, 3, 12, 16, 50, 31, 62, 2]\n",
            "pred [1, 27, 61, 50, 38, 10, 62, 23, 61, 23, 61, 45, 62, 61, 45, 50, 62, 25, 46, 40, 61, 50, 50, 3, 4, 11, 20, 61, 50, 62, 31, 62, 31, 62, 61, 23, 61, 61, 45, 62, 61, 45, 50, 62, 25, 8, 50, 40, 61, 15, 62, 3, 16, 11, 50, 50, 40, 16, 31, 62]\n",
            "iter 66000\n",
            "loss 0.20681835547089578\n",
            "trg [1, 12, 6, 10, 27, 61, 54, 38, 30, 6, 10, 40, 61, 4, 62, 62, 23, 61, 15, 54, 3, 4, 10, 30, 62, 61, 34, 61, 54, 62, 20, 61, 54, 62, 62, 2]\n",
            "pred [1, 9, 6, 9, 27, 61, 54, 38, 30, 6, 10, 40, 61, 4, 62, 62, 23, 61, 15, 54, 3, 4, 10, 30, 62, 61, 34, 61, 54, 62, 20, 61, 54, 62, 62]\n",
            "iter 67000\n",
            "loss 0.18844839915633202\n",
            "trg [1, 27, 61, 55, 38, 24, 62, 23, 61, 23, 61, 29, 41, 61, 13, 11, 62, 61, 55, 62, 62, 61, 29, 41, 61, 14, 16, 62, 61, 8, 62, 62, 62, 61, 23, 61, 29, 41, 61, 9, 8, 62, 61, 55, 62, 62, 61, 29, 41, 61, 8, 16, 62, 61, 16, 62, 62, 62, 2]\n",
            "pred [1, 27, 61, 55, 38, 24, 62, 23, 61, 23, 61, 29, 41, 61, 13, 16, 62, 61, 55, 62, 62, 61, 29, 41, 61, 11, 16, 62, 61, 8, 62, 62, 62, 61, 23, 61, 29, 41, 61, 9, 16, 62, 61, 55, 62, 62, 61, 29, 41, 61, 8, 16, 62, 61, 16, 62, 62, 62]\n",
            "iter 68000\n",
            "loss 0.18459665536880493\n",
            "trg [1, 27, 61, 54, 38, 7, 62, 23, 61, 25, 46, 40, 61, 54, 62, 4, 10, 31, 25, 46, 40, 61, 7, 62, 3, 7, 31, 62, 61, 46, 40, 61, 54, 62, 4, 12, 62, 2]\n",
            "pred [1, 27, 61, 54, 38, 7, 62, 23, 61, 25, 46, 40, 61, 54, 62, 4, 46, 31, 25, 46, 40, 61, 7, 62, 3, 7, 31, 62, 61, 46, 46, 61, 54, 62, 62]\n",
            "iter 69000\n",
            "loss 0.18605517864227294\n",
            "trg [1, 17, 27, 61, 51, 38, 11, 62, 23, 61, 35, 61, 15, 14, 3, 51, 62, 4, 15, 62, 61, 51, 62, 2]\n",
            "pred [1, 17, 27, 61, 51, 38, 11, 62, 23, 61, 35, 61, 15, 14, 3, 51, 62, 15, 62, 61, 61, 51, 62]\n",
            "iter 1000\n",
            "loss 0.2143273161351681\n",
            "trg [1, 27, 61, 48, 38, 9, 40, 61, 3, 62, 62, 23, 61, 14, 62, 61, 12, 3, 28, 61, 48, 62, 3, 16, 62, 2]\n",
            "pred [1, 27, 61, 48, 38, 9, 40, 61, 3, 62, 62, 23, 61, 14, 62, 61, 48, 3, 61, 3, 61, 16, 62, 62, 62]\n",
            "iter 2000\n",
            "loss 0.2201640574634075\n",
            "trg [1, 27, 61, 48, 38, 10, 62, 23, 61, 25, 48, 4, 15, 31, 25, 35, 61, 14, 48, 3, 14, 62, 3, 12, 31, 62, 61, 9, 48, 3, 10, 4, 11, 62, 2]\n",
            "pred [1, 27, 61, 48, 38, 10, 62, 23, 61, 25, 48, 4, 15, 31, 35, 61, 61, 14, 3, 14, 62, 3, 3, 12, 31, 62, 61, 3, 4, 11, 62, 62]\n",
            "iter 3000\n",
            "loss 0.20659701645374298\n",
            "trg [1, 9, 6, 10, 27, 61, 44, 38, 30, 6, 9, 40, 61, 4, 62, 62, 23, 61, 10, 44, 3, 25, 4, 15, 30, 31, 40, 61, 13, 62, 62, 61, 34, 40, 61, 16, 62, 61, 44, 62, 62, 2]\n",
            "pred [1, 9, 6, 13, 27, 61, 44, 38, 30, 6, 9, 40, 61, 4, 62, 62, 23, 61, 10, 44, 3, 25, 4, 15, 30, 31, 40, 61, 13, 62, 62, 61, 34, 40, 61, 16, 62, 61, 44, 62, 62]\n",
            "iter 4000\n",
            "loss 0.20894424185156824\n",
            "trg [1, 27, 61, 48, 38, 16, 62, 23, 61, 15, 3, 34, 61, 48, 62, 62, 61, 9, 3, 4, 16, 20, 40, 61, 9, 62, 61, 48, 62, 62, 2]\n",
            "pred [1, 27, 61, 48, 38, 16, 62, 23, 61, 15, 3, 34, 61, 48, 62, 62, 61, 9, 3, 4, 16, 20, 61, 9, 62, 62, 61, 48, 62, 62]\n",
            "iter 5000\n",
            "loss 0.20479323759675025\n",
            "trg [1, 28, 61, 53, 62, 17, 23, 61, 27, 61, 42, 38, 30, 6, 11, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 42, 62, 20, 61, 42, 62, 62, 61, 27, 61, 42, 38, 30, 6, 14, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 42, 62, 4, 12, 36, 40, 61, 15, 62, 61, 42, 62, 62, 2]\n",
            "pred [1, 28, 61, 58, 62, 17, 23, 61, 27, 61, 42, 38, 30, 6, 11, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 42, 62, 20, 61, 42, 62, 62, 61, 27, 61, 42, 38, 30, 6, 14, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 42, 62, 4, 12, 36, 40, 61, 15, 62, 61, 42, 62, 62, 2]\n",
            "iter 6000\n",
            "loss 0.20555471152067184\n",
            "trg [1, 28, 61, 56, 62, 17, 23, 61, 27, 61, 44, 38, 23, 61, 30, 62, 61, 16, 62, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 44, 62, 34, 61, 44, 62, 62, 61, 27, 61, 44, 38, 23, 61, 30, 62, 61, 15, 62, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 44, 62, 4, 11, 33, 40, 61, 14, 62, 61, 44, 62, 62, 2]\n",
            "pred [1, 28, 61, 58, 62, 17, 23, 61, 27, 61, 44, 38, 23, 61, 30, 62, 61, 16, 62, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 44, 62, 34, 61, 44, 62, 62, 61, 27, 61, 44, 38, 23, 61, 30, 62, 61, 15, 62, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 44, 62, 4, 11, 33, 40, 61, 14, 62, 61, 44, 62, 62, 2]\n",
            "iter 7000\n",
            "loss 0.21294573366641997\n",
            "trg [1, 27, 61, 59, 38, 12, 62, 4, 10, 23, 61, 25, 59, 4, 9, 31, 25, 59, 3, 11, 31, 62, 61, 59, 4, 9, 62, 2]\n",
            "pred [1, 27, 61, 59, 38, 12, 62, 4, 10, 23, 61, 25, 59, 4, 9, 31, 25, 59, 3, 11, 31, 62, 61, 59, 4, 9, 62]\n",
            "iter 8000\n",
            "loss 0.1964858940243721\n",
            "trg [1, 27, 61, 49, 38, 8, 40, 61, 3, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 49, 62, 25, 9, 3, 4, 10, 22, 40, 61, 10, 62, 61, 49, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 49, 62, 25, 20, 61, 49, 62, 3, 49, 20, 40, 61, 9, 62, 61, 49, 62, 31, 62, 2]\n",
            "pred [1, 27, 61, 49, 38, 8, 40, 61, 3, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 49, 62, 25, 9, 3, 4, 10, 22, 40, 61, 10, 62, 61, 49, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 49, 62, 25, 20, 61, 49, 62, 3, 49, 20, 40, 61, 9, 62, 61, 49, 62, 31, 62]\n",
            "iter 9000\n",
            "loss 0.208551637083292\n",
            "trg [1, 27, 61, 58, 38, 37, 62, 9, 58, 40, 61, 8, 62, 3, 14, 58, 40, 61, 9, 62, 3, 9, 58, 3, 12, 2]\n",
            "pred [1, 27, 61, 58, 38, 9, 62, 23, 40, 40, 61, 8, 62, 3, 14, 9, 40, 61, 9, 62, 3, 9, 58, 3, 12, 62]\n",
            "iter 10000\n",
            "loss 0.2333710791170597\n",
            "trg [1, 27, 61, 60, 38, 15, 40, 61, 3, 62, 62, 23, 61, 4, 9, 36, 61, 60, 62, 36, 40, 61, 14, 62, 61, 60, 62, 62, 61, 36, 40, 61, 13, 62, 61, 60, 62, 3, 25, 10, 60, 36, 61, 60, 62, 3, 10, 31, 34, 40, 61, 12, 62, 61, 60, 62, 62, 2]\n",
            "pred [1, 27, 61, 60, 38, 15, 40, 61, 3, 62, 62, 23, 61, 4, 9, 36, 61, 60, 62, 36, 40, 61, 14, 62, 61, 60, 62, 62, 61, 36, 40, 61, 13, 62, 61, 60, 62, 3, 25, 10, 60, 36, 61, 60, 62, 3, 10, 31, 34, 40, 61, 12, 62, 61, 60, 62, 62]\n",
            "iter 11000\n",
            "loss 0.207395299077034\n",
            "trg [1, 27, 61, 58, 38, 23, 61, 30, 62, 61, 16, 62, 62, 23, 61, 16, 36, 61, 58, 62, 3, 4, 16, 20, 61, 58, 62, 62, 61, 13, 58, 3, 4, 13, 23, 61, 30, 62, 61, 12, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 23, 61, 30, 62, 61, 16, 62, 62, 23, 61, 16, 36, 61, 58, 62, 3, 4, 16, 20, 61, 58, 62, 62, 61, 13, 58, 3, 4, 13, 23, 61, 30, 62, 61, 12, 62, 62]\n",
            "iter 12000\n",
            "loss 0.21562704101204871\n",
            "trg [1, 28, 61, 60, 62, 17, 23, 61, 27, 61, 48, 38, 23, 61, 30, 62, 61, 13, 62, 40, 61, 4, 62, 62, 22, 61, 48, 62, 62, 61, 27, 61, 48, 38, 23, 61, 30, 62, 61, 14, 62, 40, 61, 4, 62, 62, 4, 9, 36, 40, 61, 14, 62, 61, 48, 62, 62, 2]\n",
            "pred [1, 28, 61, 58, 62, 17, 23, 61, 27, 61, 48, 38, 23, 61, 30, 62, 61, 13, 62, 40, 61, 4, 62, 62, 22, 61, 48, 62, 62, 61, 27, 61, 48, 38, 23, 61, 30, 62, 61, 14, 62, 40, 61, 4, 62, 62, 4, 9, 36, 40, 61, 14, 62, 61, 48, 62, 62]\n",
            "iter 13000\n",
            "loss 0.21131264179944992\n",
            "trg [1, 27, 61, 54, 38, 30, 6, 9, 40, 61, 4, 62, 62, 23, 61, 20, 40, 61, 11, 62, 61, 54, 62, 62, 61, 9, 23, 61, 14, 62, 61, 14, 54, 3, 25, 15, 30, 31, 40, 61, 12, 62, 62, 62, 2]\n",
            "pred [1, 27, 61, 54, 38, 30, 6, 9, 40, 61, 4, 62, 62, 23, 61, 20, 40, 61, 11, 62, 61, 54, 62, 62, 61, 9, 23, 61, 11, 62, 61, 14, 54, 3, 25, 15, 30, 31, 40, 61, 12, 62, 62, 62]\n",
            "iter 14000\n",
            "loss 0.21230055004358292\n",
            "trg [1, 27, 61, 44, 38, 4, 24, 62, 14, 44, 40, 61, 9, 62, 2]\n",
            "pred [1, 27, 61, 44, 38, 4, 24, 62, 14, 44, 40, 61, 9, 62]\n",
            "iter 1000\n",
            "loss 0.30161911606788633\n",
            "trg [1, 27, 61, 43, 38, 30, 6, 12, 40, 61, 4, 62, 62, 23, 61, 33, 40, 61, 12, 62, 61, 43, 62, 62, 61, 12, 23, 61, 12, 62, 61, 13, 43, 3, 25, 9, 30, 31, 40, 61, 9, 62, 62, 62, 2]\n",
            "pred [1, 27, 61, 43, 38, 30, 6, 12, 40, 61, 4, 62, 62, 23, 61, 33, 40, 61, 12, 62, 61, 43, 62, 62, 61, 12, 23, 61, 12, 62, 61, 13, 43, 3, 25, 9, 30, 31, 40, 61, 9, 62, 62, 62]\n",
            "iter 2000\n",
            "loss 0.26621718019247054\n",
            "trg [1, 27, 61, 58, 38, 10, 40, 61, 4, 62, 62, 23, 61, 12, 62, 61, 58, 40, 61, 11, 62, 3, 4, 14, 58, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 10, 40, 61, 4, 62, 62, 23, 61, 12, 62, 61, 58, 40, 61, 11, 62, 3, 4, 14, 58, 62]\n",
            "iter 3000\n",
            "loss 0.26531748458743093\n",
            "trg [1, 27, 61, 53, 38, 24, 62, 23, 61, 13, 7, 9, 53, 40, 61, 11, 62, 62, 61, 46, 40, 61, 53, 62, 62, 2]\n",
            "pred [1, 27, 61, 53, 38, 24, 62, 23, 61, 13, 7, 9, 53, 40, 61, 11, 62, 62, 62, 46, 40, 61, 53, 62, 62]\n",
            "iter 4000\n",
            "loss 0.25765358939766886\n",
            "trg [1, 28, 61, 48, 62, 17, 23, 61, 27, 61, 43, 38, 30, 6, 10, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 43, 62, 21, 61, 43, 62, 62, 61, 27, 61, 43, 38, 30, 6, 13, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 43, 62, 4, 14, 33, 40, 61, 12, 62, 61, 43, 62, 62, 2]\n",
            "pred [1, 28, 61, 44, 62, 17, 23, 61, 27, 61, 43, 38, 30, 6, 10, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 43, 62, 21, 61, 43, 62, 62, 61, 27, 61, 43, 38, 30, 6, 13, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 43, 62, 4, 14, 33, 40, 61, 12, 62, 61, 43, 62, 62]\n",
            "iter 5000\n",
            "loss 0.25779140934348105\n",
            "trg [1, 27, 61, 37, 38, 16, 40, 61, 3, 62, 62, 46, 40, 61, 34, 61, 37, 62, 28, 61, 25, 8, 3, 37, 31, 62, 62, 2]\n",
            "pred [1, 27, 61, 37, 38, 16, 40, 61, 3, 62, 62, 46, 40, 61, 34, 61, 37, 62, 28, 61, 25, 8, 3, 37, 31, 62, 62]\n",
            "iter 6000\n",
            "loss 0.28988847851753236\n",
            "trg [1, 23, 61, 27, 61, 57, 38, 16, 62, 23, 61, 45, 62, 61, 45, 57, 62, 13, 14, 36, 61, 25, 13, 57, 31, 62, 20, 61, 25, 14, 57, 31, 62, 62, 61, 27, 61, 57, 38, 13, 62, 23, 61, 45, 62, 61, 45, 57, 62, 57, 62, 2]\n",
            "pred [1, 23, 61, 27, 61, 57, 38, 16, 62, 23, 61, 45, 62, 61, 45, 57, 62, 13, 14, 36, 61, 25, 13, 57, 31, 62, 20, 61, 25, 14, 57, 31, 62, 62, 61, 27, 61, 57, 38, 13, 62, 23, 61, 45, 62, 61, 45, 57, 62, 57, 62]\n",
            "iter 7000\n",
            "loss 0.27565083965659143\n",
            "trg [1, 27, 61, 58, 38, 9, 62, 23, 61, 34, 61, 25, 12, 58, 31, 62, 62, 61, 34, 61, 25, 58, 31, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 9, 62, 23, 61, 34, 61, 25, 12, 58, 31, 62, 62, 61, 34, 61, 25, 58, 31, 62, 62]\n",
            "iter 8000\n",
            "loss 0.2602848772704601\n",
            "trg [1, 27, 61, 55, 38, 23, 61, 30, 62, 61, 10, 62, 62, 23, 61, 10, 20, 40, 61, 12, 62, 61, 55, 62, 3, 10, 36, 40, 61, 13, 62, 61, 55, 62, 62, 61, 13, 62, 2]\n",
            "pred [1, 27, 61, 55, 38, 23, 61, 30, 62, 61, 10, 62, 62, 23, 61, 10, 20, 40, 61, 12, 62, 61, 55, 62, 3, 10, 36, 40, 61, 13, 62, 61, 55, 62, 62, 61, 13, 62]\n",
            "iter 9000\n",
            "loss 0.2563055892288685\n",
            "trg [1, 27, 61, 60, 38, 24, 62, 36, 40, 61, 60, 40, 61, 11, 62, 62, 23, 61, 13, 62, 61, 60, 40, 61, 11, 62, 62, 2]\n",
            "pred [1, 27, 61, 60, 38, 24, 62, 23, 61, 11, 36, 40, 61, 11, 62, 62, 62, 61, 11, 40, 61, 11, 62, 62]\n",
            "iter 10000\n",
            "loss 0.25935728281736375\n",
            "trg [1, 27, 61, 54, 38, 24, 62, 54, 4, 9, 3, 54, 2]\n",
            "pred [1, 27, 61, 54, 38, 24, 62, 54, 40, 61, 4, 9, 3, 3, 54]\n",
            "iter 11000\n",
            "loss 0.265169780254364\n",
            "trg [1, 23, 61, 9, 62, 61, 15, 62, 27, 61, 58, 38, 9, 62, 23, 61, 23, 61, 20, 61, 25, 10, 58, 31, 62, 62, 61, 9, 58, 62, 20, 61, 25, 9, 58, 31, 62, 62, 61, 23, 61, 36, 61, 25, 15, 58, 31, 62, 62, 61, 11, 58, 62, 62, 2]\n",
            "pred [1, 23, 61, 10, 62, 61, 9, 62, 27, 61, 58, 38, 9, 62, 23, 61, 23, 61, 20, 61, 25, 10, 58, 31, 62, 62, 61, 9, 58, 62, 20, 61, 25, 9, 58, 31, 62, 62, 61, 23, 61, 36, 61, 25, 15, 58, 31, 62, 62, 61, 11, 58, 62, 62]\n",
            "iter 12000\n",
            "loss 0.28732615649700166\n",
            "trg [1, 27, 61, 57, 38, 11, 40, 61, 4, 62, 62, 23, 61, 20, 61, 57, 62, 62, 61, 34, 40, 61, 8, 62, 61, 57, 62, 4, 13, 62, 2]\n",
            "pred [1, 27, 61, 57, 38, 11, 40, 61, 4, 62, 62, 23, 61, 20, 61, 57, 62, 62, 61, 34, 40, 61, 8, 62, 61, 57, 62, 4, 13, 62]\n",
            "iter 13000\n",
            "loss 0.2592596335709095\n",
            "trg [1, 27, 61, 59, 38, 8, 62, 23, 61, 23, 61, 45, 62, 61, 45, 59, 62, 22, 61, 25, 59, 31, 62, 62, 61, 23, 61, 45, 62, 61, 45, 59, 62, 34, 61, 25, 59, 31, 62, 62, 2]\n",
            "pred [1, 27, 61, 59, 38, 8, 62, 23, 61, 23, 61, 45, 62, 61, 45, 59, 62, 22, 61, 25, 59, 31, 62, 62, 23, 61, 45, 62, 61, 45, 59, 62, 34, 61, 59, 62, 62]\n",
            "iter 14000\n",
            "loss 0.29730094105005267\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|      | 2/5 [27:26<41:07, 822.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\tTrain Loss:   0.308 | Train PPL:   1.361\n",
            "\tValid Loss:   0.211 | Valid PPL:   1.235\n",
            "\\Test Loss:   0.272 | Valid PPL:   1.312\n",
            "trg [1, 27, 61, 53, 38, 4, 13, 62, 23, 61, 53, 62, 61, 53, 40, 61, 14, 62, 3, 10, 53, 3, 12, 40, 61, 11, 62, 62, 2]\n",
            "pred [1, 27, 61, 53, 38, 4, 13, 62, 23, 61, 53, 62, 61, 53, 40, 61, 14, 62, 3, 10, 53, 3, 12, 62, 11, 62]\n",
            "iter 1000\n",
            "loss 0.19435080096125604\n",
            "trg [1, 28, 61, 55, 62, 17, 23, 61, 27, 61, 51, 38, 30, 6, 15, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 51, 62, 20, 61, 51, 62, 62, 61, 27, 61, 51, 38, 30, 6, 15, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 51, 62, 4, 10, 20, 40, 61, 15, 62, 61, 51, 62, 62, 2]\n",
            "pred [1, 28, 61, 58, 62, 17, 23, 61, 27, 61, 51, 38, 30, 6, 15, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 51, 62, 20, 61, 51, 62, 62, 61, 27, 61, 51, 38, 30, 6, 15, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 51, 62, 4, 10, 20, 40, 61, 15, 62, 61, 51, 62, 62, 2]\n",
            "iter 2000\n",
            "loss 0.17365456253290176\n",
            "trg [1, 27, 61, 54, 38, 7, 40, 61, 3, 62, 62, 23, 61, 4, 14, 22, 61, 54, 62, 36, 40, 61, 14, 62, 61, 54, 62, 62, 61, 36, 40, 61, 10, 62, 61, 54, 62, 3, 25, 15, 54, 36, 61, 54, 62, 3, 13, 31, 20, 40, 61, 10, 62, 61, 54, 62, 62, 2]\n",
            "pred [1, 27, 61, 54, 38, 7, 40, 61, 3, 62, 62, 23, 61, 4, 14, 22, 61, 54, 62, 36, 40, 61, 14, 62, 61, 54, 62, 62, 61, 36, 40, 61, 10, 62, 61, 54, 62, 3, 25, 15, 54, 36, 61, 54, 62, 3, 13, 31, 20, 40, 61, 10, 62, 61, 54, 62, 62]\n",
            "iter 3000\n",
            "loss 0.17012860797345639\n",
            "trg [1, 23, 61, 27, 61, 56, 38, 15, 62, 15, 9, 25, 4, 9, 34, 40, 61, 10, 62, 61, 25, 13, 56, 31, 62, 3, 21, 40, 61, 16, 62, 61, 25, 13, 56, 31, 62, 31, 62, 61, 10, 62, 2]\n",
            "pred [1, 23, 61, 27, 61, 56, 38, 15, 62, 15, 15, 25, 4, 9, 34, 40, 61, 10, 62, 61, 25, 13, 56, 31, 62, 3, 21, 40, 61, 16, 62, 61, 25, 13, 56, 31, 62, 31, 62, 61, 10, 62]\n",
            "iter 4000\n",
            "loss 0.17331923499703408\n",
            "trg [1, 23, 61, 27, 61, 48, 38, 12, 62, 23, 61, 45, 62, 61, 45, 48, 62, 16, 25, 35, 61, 9, 48, 3, 4, 12, 48, 40, 61, 11, 62, 62, 3, 4, 14, 35, 18, 10, 39, 61, 58, 62, 31, 62, 61, 27, 61, 48, 38, 10, 62, 23, 61, 45, 62, 61, 45, 48, 62, 25, 12, 3, 4, 10, 48, 40, 61, 23, 61, 15, 62, 61, 14, 62, 62, 31, 62, 2]\n",
            "pred [1, 23, 61, 27, 61, 48, 38, 12, 62, 23, 61, 45, 62, 61, 45, 48, 62, 16, 35, 35, 61, 9, 3, 3, 4, 12, 48, 40, 61, 11, 62, 3, 4, 12, 48, 31, 62, 61, 62, 61, 61, 61, 48, 62, 61, 27, 61, 48, 38, 10, 62, 23, 61, 45, 62, 61, 45, 48, 62, 12, 12, 48, 4, 10, 31, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62]\n",
            "iter 5000\n",
            "loss 0.16800040513277054\n",
            "trg [1, 27, 61, 42, 38, 23, 61, 30, 62, 61, 11, 62, 62, 23, 61, 34, 61, 42, 62, 3, 4, 15, 34, 61, 42, 62, 62, 61, 42, 3, 4, 10, 23, 61, 30, 62, 61, 12, 62, 62, 2]\n",
            "pred [1, 27, 61, 42, 38, 23, 61, 30, 62, 61, 11, 62, 62, 23, 61, 34, 61, 42, 62, 3, 4, 15, 34, 61, 42, 62, 62, 61, 42, 3, 4, 10, 23, 61, 30, 62, 61, 12, 62, 62]\n",
            "iter 6000\n",
            "loss 0.1813351272046566\n",
            "trg [1, 14, 6, 14, 27, 61, 44, 38, 30, 6, 16, 40, 61, 4, 62, 62, 23, 61, 9, 44, 3, 4, 13, 30, 62, 61, 34, 61, 44, 62, 36, 61, 44, 62, 62, 2]\n",
            "pred [1, 9, 6, 9, 27, 61, 44, 38, 30, 6, 16, 40, 61, 4, 62, 62, 23, 61, 9, 44, 3, 4, 13, 30, 62, 61, 34, 61, 44, 62, 36, 61, 44, 62, 62]\n",
            "iter 7000\n",
            "loss 0.19115966379642488\n",
            "trg [1, 27, 61, 55, 38, 30, 6, 10, 40, 61, 4, 62, 62, 23, 61, 20, 40, 61, 15, 62, 61, 55, 62, 25, 11, 55, 3, 25, 4, 9, 30, 31, 40, 61, 13, 62, 31, 62, 61, 4, 10, 62, 2]\n",
            "pred [1, 27, 61, 55, 38, 30, 6, 10, 40, 61, 4, 62, 62, 23, 61, 20, 40, 61, 15, 62, 61, 55, 62, 25, 11, 55, 3, 25, 4, 9, 30, 31, 40, 61, 13, 62, 31, 62, 61, 4, 10, 62]\n",
            "iter 8000\n",
            "loss 0.21720656931400298\n",
            "trg [1, 27, 61, 44, 38, 16, 40, 61, 3, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 44, 62, 25, 12, 3, 4, 12, 36, 40, 61, 16, 62, 61, 44, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 44, 62, 25, 33, 61, 44, 62, 3, 44, 20, 40, 61, 11, 62, 61, 44, 62, 31, 62, 2]\n",
            "pred [1, 27, 61, 44, 38, 16, 40, 61, 3, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 44, 62, 25, 12, 3, 4, 12, 36, 40, 61, 16, 62, 61, 44, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 44, 62, 25, 33, 61, 44, 62, 3, 44, 20, 40, 61, 11, 62, 61, 44, 62, 31, 62]\n",
            "iter 9000\n",
            "loss 0.1854160948097706\n",
            "trg [1, 27, 61, 53, 38, 24, 62, 23, 61, 29, 41, 61, 13, 9, 62, 61, 9, 62, 62, 61, 29, 41, 61, 9, 13, 62, 61, 16, 62, 62, 2]\n",
            "pred [1, 27, 61, 53, 38, 24, 62, 23, 61, 29, 41, 61, 13, 9, 62, 61, 9, 62, 62, 61, 29, 41, 61, 9, 13, 62, 61, 16, 62, 62]\n",
            "iter 10000\n",
            "loss 0.2272133806347847\n",
            "trg [1, 27, 61, 55, 38, 11, 40, 61, 3, 62, 62, 23, 61, 4, 16, 36, 61, 55, 62, 20, 40, 61, 13, 62, 61, 55, 62, 62, 61, 34, 40, 61, 9, 62, 61, 55, 62, 3, 25, 14, 55, 20, 61, 55, 62, 3, 16, 31, 34, 40, 61, 16, 62, 61, 55, 62, 62, 2]\n",
            "pred [1, 27, 61, 55, 38, 11, 40, 61, 3, 62, 62, 23, 61, 4, 16, 36, 61, 55, 62, 20, 40, 61, 13, 62, 61, 55, 62, 62, 61, 34, 40, 61, 9, 62, 61, 55, 62, 3, 25, 14, 55, 20, 61, 55, 62, 3, 16, 31, 34, 40, 61, 16, 62, 61, 55, 62, 62]\n",
            "iter 11000\n",
            "loss 0.2277262908220291\n",
            "trg [1, 28, 61, 43, 62, 17, 23, 61, 27, 61, 58, 38, 30, 6, 10, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 58, 62, 20, 61, 58, 62, 62, 61, 27, 61, 58, 38, 30, 6, 12, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 58, 62, 4, 10, 22, 40, 61, 14, 62, 61, 58, 62, 62, 2]\n",
            "pred [1, 28, 61, 57, 62, 17, 23, 61, 27, 61, 58, 38, 30, 6, 10, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 58, 62, 20, 61, 58, 62, 62, 61, 27, 61, 58, 38, 30, 6, 12, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 58, 62, 4, 10, 22, 40, 61, 14, 62, 61, 58, 62, 62, 2]\n",
            "iter 12000\n",
            "loss 0.1680261044204235\n",
            "trg [1, 27, 61, 58, 38, 9, 62, 23, 61, 34, 61, 25, 10, 58, 31, 62, 62, 61, 34, 61, 58, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 9, 62, 23, 61, 34, 61, 25, 10, 58, 31, 62, 62, 61, 34, 61, 58, 62, 62]\n",
            "iter 13000\n",
            "loss 0.1741386905312538\n",
            "trg [1, 23, 61, 27, 61, 58, 38, 13, 62, 9, 12, 25, 15, 20, 40, 61, 11, 62, 61, 25, 13, 58, 31, 62, 3, 36, 40, 61, 9, 62, 61, 25, 9, 58, 31, 62, 31, 62, 61, 12, 62, 2]\n",
            "pred [1, 23, 61, 27, 61, 58, 38, 13, 62, 9, 12, 25, 15, 20, 40, 61, 11, 62, 61, 25, 13, 58, 31, 62, 3, 36, 40, 61, 9, 62, 61, 25, 9, 58, 31, 62, 31, 62, 61, 12, 62]\n",
            "iter 14000\n",
            "loss 0.18514308005571364\n",
            "trg [1, 27, 61, 37, 38, 23, 61, 30, 62, 61, 15, 62, 62, 23, 61, 11, 36, 61, 37, 62, 3, 4, 14, 21, 61, 37, 62, 62, 61, 9, 37, 3, 4, 14, 23, 61, 30, 62, 61, 13, 62, 62, 2]\n",
            "pred [1, 27, 61, 37, 38, 23, 61, 30, 62, 61, 15, 62, 62, 23, 61, 11, 36, 61, 37, 62, 3, 4, 14, 21, 61, 37, 62, 62, 61, 9, 37, 3, 4, 14, 23, 61, 30, 62, 61, 13, 62, 62]\n",
            "iter 15000\n",
            "loss 0.16781094051897527\n",
            "trg [1, 27, 61, 43, 38, 7, 62, 23, 61, 35, 18, 11, 39, 61, 58, 62, 4, 9, 62, 61, 25, 35, 61, 58, 62, 4, 16, 31, 25, 35, 61, 58, 62, 3, 11, 31, 62, 2]\n",
            "pred [1, 27, 61, 43, 38, 7, 62, 23, 61, 35, 61, 58, 62, 4, 9, 62, 61, 25, 35, 61, 58, 62, 4, 16, 31, 25, 35, 61, 58, 62, 3, 11, 31, 62]\n",
            "iter 16000\n",
            "loss 0.18350993074476718\n",
            "trg [1, 23, 61, 10, 62, 61, 10, 62, 27, 61, 48, 38, 23, 61, 30, 62, 61, 14, 62, 40, 61, 4, 62, 62, 23, 61, 9, 62, 61, 20, 40, 61, 12, 62, 61, 48, 62, 3, 12, 22, 40, 61, 9, 62, 61, 48, 62, 62, 2]\n",
            "pred [1, 23, 61, 10, 62, 61, 10, 62, 27, 61, 48, 38, 23, 61, 30, 62, 61, 14, 62, 40, 61, 4, 62, 62, 23, 61, 9, 62, 61, 20, 40, 61, 12, 62, 61, 48, 62, 3, 12, 22, 40, 61, 9, 62, 61, 48, 62, 62]\n",
            "iter 17000\n",
            "loss 0.1784901174157858\n",
            "trg [1, 27, 61, 60, 38, 8, 62, 23, 61, 15, 34, 40, 61, 13, 62, 61, 25, 11, 60, 31, 62, 62, 61, 60, 40, 61, 14, 62, 62, 2]\n",
            "pred [1, 27, 61, 60, 38, 8, 62, 23, 61, 15, 34, 40, 61, 13, 62, 61, 25, 11, 60, 31, 62, 62, 61, 60, 40, 61, 14, 62, 62]\n",
            "iter 18000\n",
            "loss 0.16121185421943665\n",
            "trg [1, 27, 61, 37, 38, 30, 6, 11, 62, 36, 40, 61, 9, 62, 61, 37, 62, 3, 22, 40, 61, 9, 62, 61, 37, 62, 2]\n",
            "pred [1, 27, 61, 37, 38, 30, 6, 11, 62, 36, 40, 61, 9, 62, 61, 37, 62, 3, 22, 40, 61, 9, 62, 61, 37, 62]\n",
            "iter 19000\n",
            "loss 0.15569692909717558\n",
            "trg [1, 27, 61, 60, 38, 15, 62, 4, 10, 23, 61, 25, 60, 3, 7, 31, 25, 10, 3, 60, 31, 62, 61, 25, 60, 4, 14, 31, 25, 60, 4, 8, 31, 62, 2]\n",
            "pred [1, 27, 61, 60, 38, 15, 62, 4, 10, 23, 61, 25, 60, 3, 7, 7, 25, 60, 31, 4, 31, 25, 60, 3, 4, 31, 62, 61, 25, 60, 4, 8, 31, 62]\n",
            "iter 20000\n",
            "loss 0.1787058925628662\n",
            "trg [1, 28, 61, 53, 62, 17, 23, 61, 27, 61, 47, 38, 23, 61, 30, 62, 61, 14, 62, 40, 61, 4, 62, 62, 4, 10, 20, 40, 61, 12, 62, 61, 47, 62, 62, 61, 27, 61, 47, 38, 23, 61, 30, 62, 61, 13, 62, 40, 61, 4, 62, 62, 14, 21, 40, 61, 9, 62, 61, 47, 62, 34, 61, 47, 62, 62, 2]\n",
            "pred [1, 28, 61, 48, 62, 17, 23, 61, 27, 61, 47, 38, 23, 61, 30, 62, 61, 14, 62, 40, 61, 4, 62, 62, 4, 10, 20, 40, 61, 12, 62, 61, 47, 62, 62, 61, 27, 61, 47, 38, 23, 61, 30, 62, 61, 13, 62, 40, 61, 4, 62, 62, 14, 21, 40, 61, 9, 62, 61, 47, 62, 34, 61, 47, 62, 62, 2]\n",
            "iter 21000\n",
            "loss 0.17707255184650422\n",
            "trg [1, 27, 61, 57, 38, 23, 61, 30, 62, 61, 9, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 57, 62, 25, 34, 61, 57, 62, 3, 4, 15, 21, 61, 57, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 57, 62, 25, 57, 3, 4, 9, 23, 61, 30, 62, 61, 12, 62, 31, 62, 2]\n",
            "pred [1, 27, 61, 57, 38, 23, 61, 30, 62, 61, 9, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 57, 62, 25, 34, 61, 57, 62, 3, 4, 15, 21, 61, 57, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 57, 62, 25, 57, 3, 4, 9, 23, 61, 30, 62, 61, 12, 62, 31, 62]\n",
            "iter 22000\n",
            "loss 0.17279532864689828\n",
            "trg [1, 27, 61, 58, 38, 7, 40, 61, 4, 62, 62, 23, 61, 58, 40, 61, 11, 62, 3, 4, 15, 58, 3, 9, 62, 61, 58, 40, 61, 15, 13, 62, 3, 4, 58, 40, 61, 8, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 7, 40, 61, 4, 62, 62, 23, 61, 58, 40, 61, 11, 62, 3, 4, 15, 58, 3, 8, 9, 61, 58, 40, 61, 15, 62, 62, 3, 4, 58, 58, 62]\n",
            "iter 23000\n",
            "loss 0.18199131153523923\n",
            "trg [1, 27, 61, 44, 38, 15, 40, 61, 3, 62, 62, 23, 61, 4, 14, 36, 61, 44, 62, 62, 61, 10, 3, 44, 34, 61, 44, 62, 62, 2]\n",
            "pred [1, 27, 61, 44, 38, 15, 40, 61, 3, 62, 62, 23, 61, 4, 14, 36, 61, 44, 62, 62, 61, 10, 3, 44, 34, 61, 44, 62, 62]\n",
            "iter 24000\n",
            "loss 0.17341159105300905\n",
            "trg [1, 27, 61, 53, 38, 30, 6, 10, 40, 61, 4, 62, 62, 11, 6, 16, 36, 40, 61, 10, 62, 61, 53, 62, 25, 9, 53, 3, 25, 4, 15, 30, 31, 40, 61, 10, 62, 31, 2]\n",
            "pred [1, 27, 61, 53, 38, 30, 6, 10, 40, 61, 4, 62, 62, 11, 6, 16, 36, 40, 61, 10, 62, 61, 53, 62, 25, 9, 53, 3, 25, 4, 15, 30, 31, 40, 61, 10, 62, 31]\n",
            "iter 25000\n",
            "loss 0.14383528858423233\n",
            "trg [1, 27, 61, 47, 38, 14, 40, 61, 3, 62, 62, 23, 61, 23, 61, 10, 62, 61, 47, 62, 62, 61, 4, 9, 34, 61, 47, 62, 20, 61, 47, 62, 62, 2]\n",
            "pred [1, 27, 61, 47, 38, 14, 40, 61, 3, 62, 62, 23, 61, 23, 61, 10, 62, 61, 47, 62, 62, 61, 4, 9, 34, 61, 47, 62, 20, 61, 47, 62, 62]\n",
            "iter 26000\n",
            "loss 0.15910106234252452\n",
            "trg [1, 27, 61, 42, 38, 24, 62, 23, 61, 29, 41, 61, 10, 62, 61, 9, 62, 62, 61, 29, 41, 61, 14, 13, 62, 61, 14, 62, 62, 2]\n",
            "pred [1, 27, 61, 42, 38, 24, 62, 23, 61, 29, 41, 61, 10, 62, 61, 9, 62, 62, 61, 29, 41, 61, 14, 13, 62, 61, 14, 62, 62]\n",
            "iter 27000\n",
            "loss 0.16192367672920227\n",
            "trg [1, 27, 61, 55, 38, 30, 6, 9, 62, 23, 61, 20, 61, 55, 62, 3, 4, 16, 20, 61, 55, 62, 62, 61, 55, 3, 4, 15, 30, 6, 16, 62, 2]\n",
            "pred [1, 27, 61, 55, 38, 30, 6, 9, 62, 23, 61, 20, 61, 55, 62, 3, 4, 16, 20, 61, 55, 62, 62, 61, 55, 3, 4, 15, 30, 6, 16, 62]\n",
            "iter 28000\n",
            "loss 0.1523546324670315\n",
            "trg [1, 27, 61, 52, 38, 16, 62, 23, 61, 34, 61, 52, 62, 3, 11, 62, 61, 52, 62, 2]\n",
            "pred [1, 27, 61, 52, 38, 16, 62, 23, 61, 34, 61, 52, 62, 3, 11, 62, 61, 52, 62]\n",
            "iter 29000\n",
            "loss 0.16565637454390525\n",
            "trg [1, 28, 61, 58, 62, 17, 27, 61, 55, 38, 15, 40, 61, 3, 62, 62, 55, 26, 28, 61, 55, 62, 32, 2]\n",
            "pred [1, 28, 61, 55, 62, 17, 27, 61, 55, 38, 15, 40, 61, 3, 62, 62, 26, 26, 28, 61, 55, 62, 32]\n",
            "iter 30000\n",
            "loss 0.17432261109352112\n",
            "trg [1, 28, 61, 43, 62, 17, 23, 61, 27, 61, 51, 38, 30, 6, 15, 40, 61, 4, 62, 62, 34, 61, 51, 62, 62, 61, 27, 61, 51, 38, 30, 6, 13, 40, 61, 4, 62, 62, 4, 9, 20, 40, 61, 16, 62, 61, 51, 62, 62, 2]\n",
            "pred [1, 28, 61, 58, 62, 17, 23, 61, 27, 61, 51, 38, 30, 6, 15, 40, 61, 4, 62, 62, 34, 61, 51, 62, 62, 61, 27, 61, 51, 38, 30, 6, 13, 40, 61, 4, 62, 62, 4, 9, 20, 40, 61, 16, 62, 61, 51, 62, 62]\n",
            "iter 31000\n",
            "loss 0.15771647825837135\n",
            "trg [1, 28, 61, 54, 62, 17, 23, 61, 27, 61, 58, 38, 30, 6, 16, 40, 61, 4, 62, 62, 34, 61, 58, 62, 62, 61, 27, 61, 58, 38, 30, 6, 11, 40, 61, 4, 62, 62, 4, 9, 34, 40, 61, 10, 62, 61, 58, 62, 62, 2]\n",
            "pred [1, 28, 61, 55, 62, 17, 23, 61, 27, 61, 58, 38, 30, 6, 16, 40, 61, 4, 62, 62, 34, 61, 58, 62, 62, 61, 27, 61, 58, 38, 30, 6, 11, 40, 61, 4, 62, 62, 4, 9, 34, 40, 61, 10, 62, 61, 58, 62, 62]\n",
            "iter 32000\n",
            "loss 0.15334452427923678\n",
            "trg [1, 28, 61, 60, 62, 17, 23, 61, 27, 61, 58, 38, 23, 61, 30, 62, 61, 9, 62, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 58, 62, 36, 61, 58, 62, 62, 61, 27, 61, 58, 38, 23, 61, 30, 62, 61, 10, 62, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 58, 62, 4, 11, 22, 40, 61, 15, 62, 61, 58, 62, 62, 2]\n",
            "pred [1, 28, 61, 58, 62, 17, 23, 61, 27, 61, 58, 38, 23, 61, 30, 62, 61, 9, 62, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 58, 62, 36, 61, 58, 62, 62, 61, 27, 61, 58, 38, 23, 61, 30, 62, 61, 10, 62, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 58, 62, 4, 11, 22, 40, 61, 15, 62, 61, 58, 62, 62, 2]\n",
            "iter 33000\n",
            "loss 0.1537494930624962\n",
            "trg [1, 27, 61, 55, 38, 23, 61, 30, 62, 61, 16, 62, 62, 36, 40, 61, 9, 62, 61, 55, 62, 3, 27, 61, 55, 38, 23, 61, 30, 62, 61, 9, 62, 62, 34, 40, 61, 9, 62, 61, 55, 62, 2]\n",
            "pred [1, 27, 61, 55, 38, 23, 61, 30, 62, 61, 16, 62, 62, 36, 40, 61, 9, 62, 61, 55, 62, 3, 27, 61, 55, 38, 23, 61, 30, 62, 61, 9, 62, 62, 34, 40, 61, 9, 62, 61, 55, 62]\n",
            "iter 34000\n",
            "loss 0.1784224320948124\n",
            "trg [1, 27, 61, 58, 38, 24, 62, 23, 61, 4, 14, 58, 40, 61, 9, 62, 62, 61, 58, 40, 61, 11, 62, 3, 58, 40, 61, 7, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 23, 61, 4, 14, 58, 40, 61, 9, 62, 62, 61, 58, 40, 61, 11, 62, 3, 7, 62]\n",
            "iter 35000\n",
            "loss 0.18008191138505936\n",
            "trg [1, 27, 61, 59, 38, 13, 40, 61, 3, 62, 62, 59, 40, 61, 59, 62, 2]\n",
            "pred [1, 27, 61, 59, 38, 13, 40, 61, 3, 62, 62, 59, 40, 61, 59, 62]\n",
            "iter 36000\n",
            "loss 0.15518519386649132\n",
            "trg [1, 27, 61, 51, 38, 4, 9, 62, 23, 61, 8, 25, 51, 40, 61, 13, 62, 3, 4, 9, 51, 4, 9, 31, 62, 61, 51, 3, 14, 62, 2]\n",
            "pred [1, 27, 61, 51, 38, 4, 9, 62, 23, 61, 8, 25, 51, 40, 61, 13, 62, 3, 4, 9, 51, 4, 9, 31, 62, 61, 51, 3, 14, 62]\n",
            "iter 37000\n",
            "loss 0.16321414604783058\n",
            "trg [1, 27, 61, 58, 38, 11, 40, 61, 3, 62, 62, 23, 61, 14, 58, 40, 61, 8, 62, 25, 58, 4, 8, 31, 62, 61, 58, 3, 7, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 11, 40, 61, 3, 62, 62, 23, 61, 14, 58, 40, 61, 8, 62, 25, 58, 4, 8, 31, 62, 61, 58, 3, 7, 62]\n",
            "iter 38000\n",
            "loss 0.16178700171411037\n",
            "trg [1, 27, 61, 43, 38, 24, 62, 23, 61, 29, 41, 61, 9, 11, 62, 61, 43, 62, 62, 61, 29, 41, 61, 14, 13, 62, 61, 13, 62, 62, 23, 61, 29, 41, 61, 15, 9, 62, 61, 8, 62, 62, 61, 29, 41, 61, 16, 8, 62, 61, 43, 62, 62, 2]\n",
            "pred [1, 27, 61, 43, 38, 24, 62, 23, 61, 29, 41, 61, 9, 11, 62, 61, 43, 62, 62, 61, 29, 41, 61, 14, 13, 62, 61, 13, 62, 62, 23, 61, 29, 41, 61, 15, 9, 62, 61, 8, 62, 62, 61, 29, 41, 61, 16, 8, 62, 61, 43, 62, 62]\n",
            "iter 39000\n",
            "loss 0.13878052830696105\n",
            "trg [1, 27, 61, 50, 38, 4, 15, 62, 23, 61, 50, 40, 61, 14, 62, 4, 11, 62, 61, 50, 40, 61, 10, 62, 4, 15, 62, 2]\n",
            "pred [1, 27, 61, 50, 38, 4, 15, 62, 23, 61, 50, 40, 61, 14, 62, 4, 11, 62, 61, 50, 40, 61, 10, 62, 4, 15, 62]\n",
            "iter 40000\n",
            "loss 0.15402298793196678\n",
            "trg [1, 27, 61, 59, 38, 4, 24, 62, 23, 61, 9, 46, 40, 61, 9, 59, 62, 62, 61, 8, 46, 40, 61, 14, 59, 62, 62, 2]\n",
            "pred [1, 27, 61, 59, 38, 4, 24, 62, 23, 61, 9, 46, 40, 61, 9, 59, 62, 62, 61, 8, 46, 40, 61, 14, 59, 62, 62]\n",
            "iter 41000\n",
            "loss 0.15433622077107428\n",
            "trg [1, 27, 61, 58, 38, 9, 62, 23, 61, 23, 61, 36, 61, 25, 16, 58, 31, 62, 62, 61, 21, 61, 25, 14, 58, 31, 62, 62, 62, 61, 58, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 9, 62, 23, 61, 23, 61, 36, 61, 25, 16, 58, 31, 62, 62, 61, 36, 61, 25, 14, 58, 31, 62, 62, 62, 61, 58, 62]\n",
            "iter 42000\n",
            "loss 0.14399198725819587\n",
            "trg [1, 28, 61, 53, 62, 17, 23, 61, 27, 61, 57, 38, 30, 6, 9, 40, 61, 4, 62, 62, 4, 13, 20, 40, 61, 10, 62, 61, 57, 62, 62, 61, 27, 61, 57, 38, 30, 6, 9, 40, 61, 4, 62, 62, 9, 20, 40, 61, 12, 62, 61, 57, 62, 36, 61, 57, 62, 62, 2]\n",
            "pred [1, 28, 61, 57, 62, 17, 23, 61, 27, 61, 57, 38, 30, 6, 9, 40, 61, 4, 62, 62, 4, 13, 20, 40, 61, 10, 62, 61, 57, 62, 62, 61, 27, 61, 57, 38, 30, 6, 9, 40, 61, 4, 62, 62, 9, 20, 40, 61, 12, 62, 61, 57, 62, 36, 61, 57, 62, 62]\n",
            "iter 43000\n",
            "loss 0.13694045029580593\n",
            "trg [1, 46, 40, 61, 27, 61, 55, 38, 15, 40, 61, 3, 62, 62, 8, 62, 2]\n",
            "pred [1, 46, 40, 61, 27, 61, 55, 38, 15, 40, 61, 3, 62, 62, 8, 62]\n",
            "iter 44000\n",
            "loss 0.13719835609197617\n",
            "trg [1, 23, 61, 46, 40, 61, 27, 61, 42, 38, 16, 62, 23, 61, 15, 62, 61, 11, 3, 10, 42, 62, 62, 62, 61, 13, 46, 40, 61, 16, 62, 62, 2]\n",
            "pred [1, 23, 61, 46, 40, 61, 27, 61, 42, 38, 16, 62, 23, 61, 15, 62, 61, 15, 3, 10, 42, 62, 62, 62, 61, 46, 40, 61, 62, 62]\n",
            "iter 45000\n",
            "loss 0.13491636216640474\n",
            "trg [1, 27, 61, 37, 38, 12, 62, 23, 61, 37, 34, 61, 37, 62, 62, 61, 8, 3, 4, 10, 20, 61, 37, 62, 62, 2]\n",
            "pred [1, 27, 61, 37, 38, 12, 62, 23, 61, 37, 34, 61, 37, 62, 62, 61, 8, 3, 4, 10, 20, 61, 37, 62, 62]\n",
            "iter 46000\n",
            "loss 0.15955268174409867\n",
            "trg [1, 17, 27, 61, 55, 38, 30, 6, 10, 40, 61, 4, 62, 62, 34, 40, 61, 34, 61, 25, 55, 31, 62, 62, 25, 55, 31, 2]\n",
            "pred [1, 17, 27, 61, 55, 38, 30, 6, 10, 40, 61, 4, 62, 62, 62, 34, 40, 61, 34, 34, 61, 55, 62, 62, 55, 31, 25, 55, 31]\n",
            "iter 47000\n",
            "loss 0.14687319569289684\n",
            "trg [1, 11, 6, 9, 27, 61, 54, 38, 13, 62, 23, 61, 36, 61, 25, 15, 54, 31, 62, 62, 61, 13, 54, 62, 2]\n",
            "pred [1, 12, 6, 9, 27, 61, 54, 38, 13, 62, 23, 61, 36, 61, 25, 15, 54, 31, 62, 62, 61, 13, 54, 62]\n",
            "iter 48000\n",
            "loss 0.13925318226218222\n",
            "trg [1, 27, 61, 42, 38, 4, 9, 62, 4, 23, 61, 10, 42, 62, 61, 42, 3, 11, 62, 2]\n",
            "pred [1, 27, 61, 42, 38, 4, 9, 40, 61, 4, 62, 62, 42, 61, 42, 62, 61, 42, 3, 11, 62]\n",
            "iter 49000\n",
            "loss 0.13801782749593258\n",
            "trg [1, 27, 61, 58, 38, 24, 62, 23, 61, 23, 61, 29, 41, 61, 8, 8, 62, 61, 58, 62, 62, 61, 29, 41, 61, 12, 15, 62, 61, 8, 62, 62, 62, 61, 23, 61, 29, 41, 61, 14, 13, 62, 61, 58, 62, 62, 61, 29, 41, 61, 16, 13, 62, 61, 12, 62, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 23, 61, 23, 61, 29, 41, 61, 12, 8, 62, 61, 58, 62, 62, 61, 29, 41, 61, 12, 8, 62, 61, 8, 62, 62, 62, 61, 23, 61, 29, 41, 61, 14, 13, 62, 61, 58, 62, 62, 61, 29, 41, 61, 16, 13, 62, 61, 12, 62, 62, 62]\n",
            "iter 50000\n",
            "loss 0.147313629090786\n",
            "trg [1, 27, 61, 48, 38, 4, 24, 62, 13, 6, 9, 2]\n",
            "pred [1, 27, 61, 48, 38, 4, 24, 62, 13, 6, 9]\n",
            "iter 51000\n",
            "loss 0.14901704207062721\n",
            "trg [1, 27, 61, 54, 38, 24, 62, 23, 61, 54, 40, 61, 13, 62, 3, 15, 62, 61, 54, 40, 61, 10, 62, 3, 54, 40, 61, 14, 62, 3, 4, 54, 62, 2]\n",
            "pred [1, 27, 61, 54, 38, 24, 62, 23, 61, 54, 40, 61, 13, 62, 3, 15, 62, 61, 54, 40, 61, 10, 62, 3, 54, 40, 61, 14, 62, 3, 4, 54]\n",
            "iter 52000\n",
            "loss 0.1588887256383896\n",
            "trg [1, 27, 61, 50, 38, 4, 24, 62, 50, 3, 35, 61, 50, 40, 61, 8, 62, 3, 4, 16, 50, 62, 2]\n",
            "pred [1, 27, 61, 50, 38, 4, 24, 62, 50, 3, 35, 61, 50, 40, 61, 8, 62, 3, 4, 16, 50, 62]\n",
            "iter 53000\n",
            "loss 0.14380057238042354\n",
            "trg [1, 27, 61, 56, 38, 24, 62, 4, 10, 56, 40, 61, 12, 62, 2]\n",
            "pred [1, 27, 61, 56, 38, 24, 62, 4, 10, 56, 40, 61, 12, 62]\n",
            "iter 54000\n",
            "loss 0.16038694903254508\n",
            "trg [1, 27, 61, 54, 38, 23, 61, 30, 62, 61, 15, 62, 62, 34, 40, 61, 13, 62, 61, 54, 62, 3, 36, 40, 61, 9, 62, 61, 54, 62, 2]\n",
            "pred [1, 27, 61, 54, 38, 23, 61, 30, 62, 61, 15, 62, 62, 34, 40, 61, 13, 62, 61, 54, 62, 3, 36, 40, 61, 9, 62, 61, 54, 62]\n",
            "iter 55000\n",
            "loss 0.16043877303600312\n",
            "trg [1, 27, 61, 58, 38, 7, 40, 61, 3, 62, 62, 46, 40, 61, 28, 61, 25, 9, 3, 58, 40, 61, 33, 61, 58, 62, 62, 31, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 7, 40, 61, 3, 62, 62, 46, 40, 61, 28, 61, 25, 9, 3, 58, 40, 61, 33, 61, 58, 62, 62, 31, 62, 62]\n",
            "iter 56000\n",
            "loss 0.1434689224511385\n",
            "trg [1, 27, 61, 55, 38, 23, 61, 30, 62, 61, 16, 62, 62, 23, 61, 36, 61, 55, 62, 3, 4, 11, 20, 61, 55, 62, 62, 61, 55, 3, 4, 16, 23, 61, 30, 62, 61, 11, 62, 62, 2]\n",
            "pred [1, 27, 61, 55, 38, 23, 61, 30, 62, 61, 16, 62, 62, 23, 61, 36, 61, 55, 62, 3, 4, 11, 20, 61, 55, 62, 62, 61, 55, 3, 4, 16, 23, 61, 30, 62, 61, 11, 62, 62]\n",
            "iter 57000\n",
            "loss 0.14670576237142086\n",
            "trg [1, 27, 61, 58, 38, 23, 61, 30, 62, 61, 11, 62, 40, 61, 4, 62, 62, 23, 61, 12, 62, 61, 13, 62, 20, 40, 61, 9, 62, 61, 58, 62, 25, 10, 58, 3, 25, 4, 9, 30, 31, 40, 61, 12, 62, 31, 2]\n",
            "pred [1, 27, 61, 58, 38, 23, 61, 30, 62, 61, 11, 62, 40, 61, 4, 62, 62, 23, 61, 12, 62, 61, 13, 62, 20, 40, 61, 9, 62, 61, 58, 62, 25, 10, 58, 3, 25, 4, 9, 30, 31, 40, 61, 12, 62, 31]\n",
            "iter 58000\n",
            "loss 0.1316873948276043\n",
            "trg [1, 27, 61, 54, 38, 30, 6, 15, 62, 36, 40, 61, 14, 62, 61, 54, 62, 3, 20, 40, 61, 9, 62, 61, 54, 62, 2]\n",
            "pred [1, 27, 61, 54, 38, 30, 6, 15, 62, 36, 40, 61, 14, 62, 61, 54, 62, 3, 20, 40, 61, 9, 62, 61, 54, 62]\n",
            "iter 59000\n",
            "loss 0.14587090224027632\n",
            "trg [1, 11, 6, 14, 27, 61, 60, 38, 11, 62, 23, 61, 23, 61, 34, 61, 25, 14, 60, 31, 62, 62, 61, 10, 60, 62, 20, 61, 25, 15, 60, 31, 62, 62, 61, 23, 61, 34, 61, 25, 12, 60, 31, 62, 62, 61, 14, 60, 62, 62, 2]\n",
            "pred [1, 15, 6, 14, 27, 61, 60, 38, 11, 62, 23, 61, 23, 61, 34, 61, 25, 14, 60, 31, 62, 62, 61, 10, 60, 62, 20, 61, 25, 15, 60, 31, 62, 62, 61, 23, 61, 34, 61, 25, 12, 60, 31, 62, 62, 61, 14, 60, 62, 62]\n",
            "iter 60000\n",
            "loss 0.1252315090596676\n",
            "trg [1, 27, 61, 58, 38, 30, 6, 9, 62, 23, 61, 9, 36, 61, 58, 62, 3, 4, 9, 20, 61, 58, 62, 62, 61, 14, 58, 3, 4, 11, 30, 6, 9, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 30, 6, 9, 62, 23, 61, 9, 36, 61, 58, 62, 3, 4, 9, 20, 61, 58, 62, 62, 61, 14, 58, 3, 4, 11, 30, 6, 9, 62]\n",
            "iter 61000\n",
            "loss 0.1250161899626255\n",
            "trg [1, 27, 61, 55, 38, 9, 40, 61, 3, 62, 62, 23, 61, 16, 3, 13, 55, 62, 61, 55, 62, 23, 61, 55, 62, 61, 55, 3, 55, 28, 61, 55, 62, 4, 14, 62, 2]\n",
            "pred [1, 27, 61, 55, 38, 9, 40, 61, 3, 62, 62, 23, 61, 16, 3, 13, 55, 40, 61, 55, 62, 62, 55, 62, 55, 55, 55, 28, 55, 28, 55, 55, 62, 4, 14, 62]\n",
            "iter 62000\n",
            "loss 0.1396028361469507\n",
            "trg [1, 27, 61, 54, 38, 8, 62, 23, 61, 36, 61, 8, 62, 54, 62, 61, 34, 61, 8, 62, 54, 62, 2]\n",
            "pred [1, 27, 61, 54, 38, 8, 62, 23, 61, 36, 61, 8, 62, 54, 62, 61, 34, 61, 8, 62, 54, 62]\n",
            "iter 63000\n",
            "loss 0.13394861735403538\n",
            "trg [1, 17, 27, 61, 55, 38, 23, 61, 30, 62, 61, 16, 62, 62, 23, 61, 9, 36, 61, 55, 62, 3, 4, 15, 34, 61, 55, 62, 62, 61, 9, 55, 3, 4, 13, 23, 61, 30, 62, 61, 9, 62, 62, 2]\n",
            "pred [1, 17, 27, 61, 55, 38, 23, 61, 30, 62, 61, 16, 62, 62, 23, 61, 9, 36, 61, 55, 62, 3, 4, 15, 34, 61, 55, 62, 62, 61, 9, 55, 3, 4, 13, 23, 61, 30, 62, 61, 9, 62, 62]\n",
            "iter 64000\n",
            "loss 0.1452898171544075\n",
            "trg [1, 27, 61, 52, 38, 23, 61, 30, 62, 61, 9, 62, 62, 23, 61, 9, 36, 61, 52, 62, 3, 4, 16, 36, 61, 52, 62, 62, 61, 16, 52, 3, 4, 14, 23, 61, 30, 62, 61, 9, 62, 62, 2]\n",
            "pred [1, 27, 61, 52, 38, 23, 61, 30, 62, 61, 9, 62, 62, 23, 61, 9, 36, 61, 52, 62, 3, 4, 16, 36, 61, 52, 62, 62, 61, 16, 52, 3, 4, 14, 23, 61, 30, 62, 61, 9, 62, 62]\n",
            "iter 65000\n",
            "loss 0.1335202845185995\n",
            "trg [1, 28, 61, 51, 62, 17, 23, 61, 27, 61, 54, 38, 13, 40, 61, 3, 62, 62, 23, 61, 45, 62, 61, 45, 54, 62, 26, 28, 61, 54, 62, 32, 62, 61, 27, 61, 54, 38, 16, 40, 61, 3, 62, 62, 23, 61, 45, 62, 61, 45, 54, 62, 10, 6, 54, 62, 2]\n",
            "pred [1, 28, 61, 48, 62, 17, 23, 61, 27, 61, 54, 38, 13, 40, 61, 3, 62, 62, 23, 61, 45, 62, 61, 45, 54, 62, 26, 28, 61, 54, 62, 32, 62, 61, 27, 61, 54, 38, 16, 40, 61, 3, 62, 62, 23, 61, 45, 62, 61, 45, 54, 62, 10, 6, 54, 62]\n",
            "iter 66000\n",
            "loss 0.11187124997377396\n",
            "trg [1, 27, 61, 42, 38, 13, 62, 9, 33, 61, 42, 62, 2]\n",
            "pred [1, 27, 61, 42, 38, 13, 62, 9, 33, 61, 42, 62]\n",
            "iter 67000\n",
            "loss 0.12417864814400673\n",
            "trg [1, 27, 61, 48, 38, 23, 61, 30, 62, 61, 9, 62, 62, 23, 61, 36, 40, 61, 14, 62, 61, 48, 62, 3, 36, 40, 61, 13, 62, 61, 48, 62, 62, 61, 11, 62, 2]\n",
            "pred [1, 27, 61, 48, 38, 23, 61, 30, 62, 61, 9, 62, 62, 23, 61, 36, 40, 61, 14, 62, 61, 48, 62, 3, 36, 40, 61, 13, 62, 61, 48, 62, 62, 61, 11, 62]\n",
            "iter 68000\n",
            "loss 0.12409605711698532\n",
            "trg [1, 27, 61, 50, 38, 30, 62, 23, 61, 23, 61, 45, 62, 61, 45, 50, 62, 25, 20, 61, 50, 62, 3, 11, 31, 62, 61, 23, 61, 45, 62, 61, 45, 50, 62, 25, 50, 3, 25, 4, 12, 30, 31, 40, 61, 16, 62, 31, 62, 2]\n",
            "pred [1, 27, 61, 50, 38, 30, 62, 23, 61, 23, 61, 45, 62, 61, 45, 50, 62, 25, 20, 61, 50, 62, 3, 11, 31, 62, 61, 23, 61, 45, 62, 61, 45, 50, 62, 25, 50, 3, 25, 4, 12, 30, 31, 40, 61, 16, 62, 31, 62]\n",
            "iter 69000\n",
            "loss 0.16657876543700695\n",
            "trg [1, 27, 61, 55, 38, 24, 62, 23, 61, 9, 62, 61, 35, 61, 55, 3, 15, 62, 3, 35, 61, 55, 3, 12, 62, 62, 2]\n",
            "pred [1, 27, 61, 55, 38, 24, 62, 23, 61, 9, 62, 61, 35, 61, 55, 3, 15, 62, 3, 35, 61, 55, 3, 12, 62]\n",
            "iter 1000\n",
            "loss 0.20192433014512062\n",
            "trg [1, 27, 61, 60, 38, 24, 62, 25, 35, 61, 60, 40, 61, 11, 62, 3, 60, 3, 16, 62, 3, 4, 11, 35, 61, 60, 40, 61, 12, 62, 3, 4, 16, 60, 62, 31, 23, 61, 35, 61, 60, 40, 61, 10, 62, 3, 60, 3, 9, 62, 3, 35, 61, 60, 40, 61, 8, 62, 3, 4, 60, 62, 62, 61, 35, 61, 60, 40, 61, 8, 62, 3, 60, 3, 9, 62, 3, 35, 61, 60, 40, 61, 10, 62, 3, 4, 15, 60, 62, 62, 2]\n",
            "pred [1, 27, 61, 60, 38, 24, 62, 25, 35, 61, 11, 11, 60, 3, 60, 40, 61, 16, 62, 3, 3, 60, 60, 62, 62, 3, 3, 60, 35, 61, 60, 40, 61, 62, 3, 3, 60, 60, 60, 62, 62, 3, 4, 62, 62, 3, 60, 40, 61, 8, 62, 3, 60, 60, 62, 62, 62, 62, 3, 60, 40, 61, 62, 62, 3, 60, 40, 61, 62, 62, 3, 60, 40, 61, 62, 62, 3, 60, 62, 60, 62, 62, 62, 62, 62, 62, 2]\n",
            "iter 2000\n",
            "loss 0.17700536772608758\n",
            "trg [1, 27, 61, 59, 38, 30, 6, 12, 62, 23, 61, 36, 40, 61, 9, 62, 61, 59, 62, 3, 34, 40, 61, 9, 62, 61, 59, 62, 62, 61, 11, 62, 2]\n",
            "pred [1, 27, 61, 59, 38, 30, 6, 12, 62, 23, 61, 36, 40, 61, 9, 62, 61, 59, 62, 3, 34, 40, 61, 9, 62, 61, 59, 62, 62, 61, 11, 62]\n",
            "iter 3000\n",
            "loss 0.2352616959810257\n",
            "trg [1, 27, 61, 48, 38, 9, 40, 61, 3, 62, 62, 34, 61, 48, 62, 12, 6, 48, 35, 61, 48, 25, 15, 3, 4, 11, 48, 31, 62, 2]\n",
            "pred [1, 27, 61, 48, 38, 9, 40, 61, 3, 62, 62, 34, 61, 48, 62, 12, 6, 48, 35, 61, 48, 25, 15, 3, 4, 11, 48, 31, 62]\n",
            "iter 4000\n",
            "loss 0.2140749129652977\n",
            "trg [1, 17, 27, 61, 58, 38, 14, 62, 23, 61, 58, 3, 16, 40, 61, 14, 62, 3, 58, 3, 14, 4, 13, 10, 62, 61, 58, 62, 2]\n",
            "pred [1, 17, 27, 61, 58, 38, 14, 62, 23, 61, 58, 3, 16, 40, 61, 14, 62, 3, 58, 3, 4, 13, 10, 62, 61, 58, 62]\n",
            "iter 5000\n",
            "loss 0.2169867503643036\n",
            "trg [1, 27, 61, 57, 38, 24, 62, 23, 61, 23, 61, 29, 41, 61, 16, 16, 62, 61, 57, 62, 62, 61, 29, 41, 61, 10, 15, 62, 61, 9, 62, 62, 62, 61, 23, 61, 29, 41, 61, 9, 12, 62, 61, 57, 62, 62, 61, 29, 41, 61, 14, 13, 62, 61, 7, 62, 62, 62, 2]\n",
            "pred [1, 27, 61, 57, 38, 24, 62, 23, 61, 23, 61, 29, 41, 61, 16, 16, 62, 61, 57, 62, 62, 61, 29, 41, 61, 16, 15, 62, 61, 9, 62, 62, 62, 61, 23, 61, 29, 41, 61, 14, 13, 62, 61, 57, 62, 62, 61, 29, 41, 61, 14, 13, 62, 61, 7, 62, 62, 62]\n",
            "iter 6000\n",
            "loss 0.23817319691181182\n",
            "trg [1, 27, 61, 53, 38, 23, 61, 30, 62, 61, 9, 62, 62, 36, 40, 61, 14, 62, 61, 53, 62, 3, 36, 40, 61, 13, 62, 61, 53, 62, 2]\n",
            "pred [1, 27, 61, 53, 38, 23, 61, 30, 62, 61, 9, 62, 62, 36, 40, 61, 14, 62, 61, 53, 62, 3, 36, 40, 61, 13, 62, 61, 53, 62]\n",
            "iter 7000\n",
            "loss 0.2081247863173485\n",
            "trg [1, 27, 61, 37, 38, 10, 62, 23, 61, 37, 40, 61, 12, 62, 3, 10, 12, 37, 62, 61, 37, 62, 2]\n",
            "pred [1, 27, 61, 37, 38, 10, 62, 23, 61, 37, 40, 61, 12, 62, 3, 10, 37, 62, 61, 37, 62]\n",
            "iter 8000\n",
            "loss 0.20206018149852753\n",
            "trg [1, 27, 61, 54, 38, 4, 10, 62, 23, 61, 9, 19, 4, 9, 62, 61, 16, 19, 14, 54, 40, 61, 9, 62, 3, 11, 19, 9, 54, 4, 15, 62, 2]\n",
            "pred [1, 27, 61, 54, 38, 4, 10, 62, 23, 61, 9, 19, 62, 16, 16, 16, 19, 14, 54, 40, 61, 9, 62, 3, 11, 19, 54, 4, 15, 62]\n",
            "iter 9000\n",
            "loss 0.2228225976228714\n",
            "trg [1, 27, 61, 59, 38, 11, 62, 23, 61, 25, 59, 4, 16, 31, 25, 35, 61, 8, 7, 3, 14, 62, 3, 14, 31, 62, 61, 11, 16, 59, 3, 13, 4, 16, 9, 62, 2]\n",
            "pred [1, 27, 61, 59, 38, 11, 62, 23, 61, 25, 59, 4, 16, 31, 25, 35, 61, 8, 7, 3, 14, 62, 3, 14, 14, 14, 61, 11, 16, 3, 4, 16, 16, 16, 62]\n",
            "iter 10000\n",
            "loss 0.2123365917801857\n",
            "trg [1, 27, 61, 59, 38, 14, 62, 23, 61, 9, 59, 62, 61, 35, 61, 14, 59, 3, 8, 62, 4, 10, 62, 2]\n",
            "pred [1, 27, 61, 59, 38, 14, 62, 23, 61, 9, 59, 62, 61, 35, 61, 14, 59, 3, 8, 62, 4, 10, 62]\n",
            "iter 11000\n",
            "loss 0.1925026495754719\n",
            "trg [1, 28, 61, 51, 62, 17, 23, 61, 27, 61, 52, 38, 23, 61, 30, 62, 61, 9, 62, 40, 61, 4, 62, 62, 22, 61, 52, 62, 62, 61, 27, 61, 52, 38, 23, 61, 30, 62, 61, 10, 62, 40, 61, 4, 62, 62, 4, 16, 33, 40, 61, 9, 62, 61, 52, 62, 62, 2]\n",
            "pred [1, 28, 61, 58, 62, 17, 23, 61, 27, 61, 52, 38, 23, 61, 30, 62, 61, 9, 62, 40, 61, 4, 62, 62, 22, 61, 52, 62, 62, 61, 27, 61, 52, 38, 23, 61, 30, 62, 61, 10, 62, 40, 61, 4, 62, 62, 4, 16, 62, 40, 61, 9, 62, 61, 52, 62, 62]\n",
            "iter 12000\n",
            "loss 0.21701145440340042\n",
            "trg [1, 27, 61, 43, 38, 9, 40, 61, 3, 62, 62, 23, 61, 11, 62, 61, 36, 61, 43, 62, 62, 43, 6, 43, 3, 11, 14, 6, 43, 23, 61, 36, 61, 43, 62, 62, 61, 36, 61, 43, 62, 62, 2]\n",
            "pred [1, 27, 61, 43, 38, 9, 40, 61, 3, 62, 62, 23, 61, 11, 62, 61, 36, 61, 43, 62, 62, 6, 6, 43, 3, 14, 23, 61, 14, 62, 61, 36, 61, 43, 62, 62, 61, 36, 61, 43, 62, 62]\n",
            "iter 13000\n",
            "loss 0.23142729461193084\n",
            "trg [1, 27, 61, 50, 38, 24, 62, 23, 61, 4, 10, 25, 22, 61, 23, 61, 13, 62, 61, 50, 62, 62, 3, 4, 14, 23, 61, 14, 62, 61, 50, 62, 33, 61, 23, 61, 15, 62, 61, 50, 62, 62, 31, 62, 61, 4, 11, 50, 40, 61, 4, 10, 62, 62, 2]\n",
            "pred [1, 27, 61, 50, 38, 24, 62, 23, 61, 4, 10, 25, 22, 61, 23, 61, 13, 62, 61, 50, 62, 62, 3, 4, 14, 23, 61, 14, 62, 61, 50, 62, 33, 61, 23, 61, 15, 62, 61, 50, 62, 62, 31, 62, 61, 4, 11, 50, 40, 61, 4, 10, 62, 62]\n",
            "iter 14000\n",
            "loss 0.21474876843392848\n",
            "trg [1, 17, 27, 61, 48, 38, 10, 62, 23, 61, 15, 34, 61, 25, 12, 48, 31, 62, 62, 61, 14, 48, 34, 61, 25, 9, 48, 31, 62, 62, 2]\n",
            "pred [1, 17, 27, 61, 48, 38, 10, 62, 23, 61, 15, 34, 61, 25, 12, 48, 31, 62, 62, 61, 14, 48, 34, 61, 25, 9, 48, 31, 62, 62]\n",
            "iter 1000\n",
            "loss 0.27548449143767356\n",
            "trg [1, 17, 27, 61, 43, 38, 9, 62, 23, 61, 21, 61, 25, 12, 43, 31, 62, 62, 61, 20, 61, 25, 10, 43, 31, 62, 62, 2]\n",
            "pred [1, 17, 27, 61, 43, 38, 9, 62, 23, 61, 21, 61, 25, 12, 43, 31, 62, 62, 61, 20, 61, 25, 10, 43, 31, 62, 62]\n",
            "iter 2000\n",
            "loss 0.25252358987927437\n",
            "trg [1, 27, 61, 52, 38, 9, 62, 23, 61, 23, 61, 45, 62, 61, 45, 52, 62, 7, 36, 61, 25, 13, 52, 31, 62, 62, 61, 23, 61, 45, 62, 61, 45, 52, 62, 52, 62, 2]\n",
            "pred [1, 27, 61, 52, 38, 9, 62, 23, 61, 23, 61, 45, 62, 61, 45, 52, 62, 7, 36, 61, 25, 13, 52, 31, 62, 62, 61, 23, 61, 45, 62, 61, 45, 52, 62, 52, 62]\n",
            "iter 3000\n",
            "loss 0.28661148458719254\n",
            "trg [1, 27, 61, 56, 38, 30, 6, 9, 40, 61, 4, 62, 62, 12, 6, 11, 33, 40, 61, 15, 62, 61, 56, 62, 25, 12, 56, 3, 25, 4, 9, 30, 31, 40, 61, 14, 62, 31, 2]\n",
            "pred [1, 27, 61, 56, 38, 30, 6, 9, 40, 61, 4, 62, 62, 12, 6, 11, 33, 40, 61, 15, 62, 61, 56, 62, 25, 12, 56, 3, 25, 4, 9, 30, 31, 40, 61, 14, 62, 31]\n",
            "iter 4000\n",
            "loss 0.2937467658519745\n",
            "trg [1, 27, 61, 51, 38, 24, 62, 23, 61, 29, 41, 61, 15, 11, 62, 61, 8, 62, 62, 61, 29, 41, 61, 14, 10, 62, 61, 16, 62, 62, 2]\n",
            "pred [1, 27, 61, 51, 38, 24, 62, 23, 61, 29, 41, 61, 15, 62, 61, 8, 62, 62, 61, 29, 41, 61, 14, 10, 62, 61, 16, 62, 62]\n",
            "iter 5000\n",
            "loss 0.30174870550632477\n",
            "trg [1, 27, 61, 43, 38, 30, 6, 14, 40, 61, 4, 62, 62, 36, 61, 43, 62, 3, 4, 12, 20, 61, 43, 62, 2]\n",
            "pred [1, 27, 61, 43, 38, 30, 6, 14, 40, 61, 4, 62, 62, 36, 61, 43, 62, 3, 4, 12, 20, 61, 43, 62]\n",
            "iter 6000\n",
            "loss 0.2906912612915039\n",
            "trg [1, 27, 61, 57, 38, 8, 40, 61, 3, 62, 62, 8, 3, 57, 40, 61, 34, 61, 57, 62, 62, 2]\n",
            "pred [1, 27, 61, 57, 38, 8, 40, 61, 3, 62, 62, 8, 3, 57, 40, 61, 34, 61, 57, 62, 62]\n",
            "iter 7000\n",
            "loss 0.2927051205933094\n",
            "trg [1, 27, 61, 56, 38, 7, 62, 23, 61, 10, 25, 56, 4, 11, 31, 25, 56, 3, 8, 31, 62, 61, 56, 3, 7, 62, 2]\n",
            "pred [1, 27, 61, 56, 38, 7, 62, 23, 61, 10, 25, 56, 4, 11, 31, 25, 56, 3, 8, 31, 62, 61, 56, 3, 7, 62]\n",
            "iter 8000\n",
            "loss 0.30779948472976687\n",
            "trg [1, 27, 61, 59, 38, 16, 40, 61, 3, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 59, 62, 25, 9, 3, 4, 14, 36, 40, 61, 10, 62, 61, 59, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 59, 62, 25, 34, 61, 59, 62, 3, 59, 20, 40, 61, 11, 62, 61, 59, 62, 31, 62, 2]\n",
            "pred [1, 27, 61, 59, 38, 16, 40, 61, 3, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 59, 62, 25, 9, 3, 4, 14, 36, 40, 61, 10, 62, 61, 59, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 59, 62, 25, 34, 61, 59, 62, 3, 59, 20, 40, 61, 11, 62, 61, 59, 62, 31, 62]\n",
            "iter 9000\n",
            "loss 0.26576229616999625\n",
            "trg [1, 27, 61, 58, 38, 9, 62, 9, 6, 10, 23, 61, 34, 61, 25, 16, 58, 31, 62, 62, 61, 13, 58, 62, 23, 61, 10, 58, 62, 61, 36, 61, 25, 14, 58, 31, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 9, 62, 9, 6, 9, 34, 61, 58, 61, 25, 16, 58, 31, 62, 62, 61, 13, 58, 62, 23, 61, 10, 62, 61, 36, 61, 25, 14, 58, 31, 62, 62]\n",
            "iter 10000\n",
            "loss 0.26808014675974845\n",
            "trg [1, 27, 61, 54, 38, 4, 24, 62, 23, 61, 54, 40, 61, 9, 62, 3, 4, 10, 54, 40, 61, 7, 62, 3, 4, 11, 54, 40, 61, 13, 62, 62, 61, 54, 40, 61, 8, 62, 3, 35, 61, 54, 40, 61, 9, 62, 3, 13, 54, 40, 61, 11, 62, 62, 62, 2]\n",
            "pred [1, 27, 61, 54, 38, 4, 24, 62, 23, 61, 54, 40, 61, 9, 62, 3, 4, 10, 54, 40, 61, 7, 62, 3, 4, 11, 54, 40, 61, 54, 62, 62, 61, 54, 40, 61, 9, 62, 3, 4, 54, 40, 61, 11, 62, 62]\n",
            "iter 11000\n",
            "loss 0.31471490368247035\n",
            "trg [1, 46, 40, 61, 27, 61, 57, 38, 8, 40, 61, 3, 62, 62, 20, 61, 57, 62, 23, 61, 28, 61, 25, 10, 3, 57, 31, 62, 62, 61, 34, 61, 57, 62, 62, 62, 2]\n",
            "pred [1, 46, 40, 61, 27, 61, 57, 38, 8, 40, 61, 3, 62, 62, 20, 61, 57, 62, 23, 61, 28, 61, 25, 10, 3, 57, 31, 62, 62, 61, 34, 61, 57, 62, 62, 62]\n",
            "iter 12000\n",
            "loss 0.3078740805387497\n",
            "trg [1, 27, 61, 48, 38, 30, 6, 13, 62, 20, 40, 61, 10, 62, 61, 48, 62, 3, 27, 61, 48, 38, 30, 6, 14, 62, 36, 40, 61, 11, 62, 61, 48, 62, 2]\n",
            "pred [1, 27, 61, 48, 38, 30, 6, 13, 62, 20, 40, 61, 10, 62, 61, 48, 62, 3, 27, 61, 48, 38, 30, 6, 14, 62, 36, 40, 61, 11, 62, 61, 48, 62]\n",
            "iter 13000\n",
            "loss 0.32158844992518426\n",
            "trg [1, 27, 61, 55, 38, 24, 62, 23, 61, 29, 41, 61, 10, 62, 61, 15, 62, 62, 61, 29, 41, 61, 11, 9, 62, 61, 9, 62, 62, 2]\n",
            "pred [1, 27, 61, 55, 38, 24, 62, 23, 61, 29, 41, 61, 10, 15, 62, 61, 62, 62, 61, 29, 41, 61, 11, 9, 62, 61, 9, 62, 62]\n",
            "iter 14000\n",
            "loss 0.2823414580523968\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|    | 3/5 [41:08<27:24, 822.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\tTrain Loss:   0.160 | Train PPL:   1.174\n",
            "\tValid Loss:   0.213 | Valid PPL:   1.238\n",
            "\\Test Loss:   0.288 | Valid PPL:   1.334\n",
            "trg [1, 27, 61, 58, 38, 24, 62, 23, 61, 28, 58, 40, 61, 11, 62, 62, 61, 28, 58, 40, 61, 8, 62, 3, 13, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 23, 61, 28, 58, 40, 61, 11, 62, 62, 61, 28, 61, 58, 62, 3, 13, 62, 62]\n",
            "iter 1000\n",
            "loss 0.1709039730578661\n",
            "trg [1, 27, 61, 42, 38, 4, 24, 62, 14, 2]\n",
            "pred [1, 27, 61, 42, 38, 4, 24, 62, 14]\n",
            "iter 2000\n",
            "loss 0.14673392757773399\n",
            "trg [1, 27, 61, 57, 38, 8, 62, 23, 61, 15, 3, 36, 61, 57, 62, 62, 61, 11, 3, 4, 13, 25, 13, 3, 4, 15, 33, 40, 61, 15, 62, 61, 57, 62, 31, 62, 2]\n",
            "pred [1, 27, 61, 57, 38, 8, 62, 23, 61, 15, 3, 36, 61, 57, 62, 62, 61, 11, 3, 4, 13, 25, 13, 3, 4, 15, 33, 40, 61, 15, 62, 61, 57, 62, 31, 62]\n",
            "iter 3000\n",
            "loss 0.1223685747385025\n",
            "trg [1, 27, 61, 47, 38, 24, 62, 23, 61, 29, 41, 61, 14, 8, 62, 61, 47, 62, 62, 61, 29, 41, 61, 8, 15, 62, 61, 16, 62, 62, 23, 61, 29, 41, 61, 16, 8, 62, 61, 10, 62, 62, 61, 29, 41, 61, 8, 7, 62, 61, 47, 62, 62, 2]\n",
            "pred [1, 27, 61, 47, 38, 24, 62, 23, 61, 29, 41, 61, 14, 8, 62, 61, 47, 62, 62, 61, 29, 41, 61, 8, 15, 62, 61, 16, 62, 62, 23, 61, 29, 41, 61, 16, 8, 62, 61, 10, 62, 62, 61, 29, 41, 61, 8, 7, 62, 61, 47, 62, 62]\n",
            "iter 4000\n",
            "loss 0.1343165846168995\n",
            "trg [1, 27, 61, 58, 38, 12, 62, 23, 61, 58, 34, 61, 25, 10, 58, 31, 62, 62, 61, 7, 36, 61, 58, 62, 34, 61, 25, 11, 58, 31, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 12, 62, 23, 61, 58, 34, 61, 25, 10, 58, 31, 62, 62, 61, 7, 36, 61, 58, 62, 34, 61, 25, 11, 58, 31, 62, 62]\n",
            "iter 5000\n",
            "loss 0.1305632495880127\n",
            "trg [1, 27, 61, 53, 38, 11, 40, 61, 3, 62, 62, 23, 61, 4, 10, 34, 61, 53, 62, 36, 40, 61, 9, 62, 61, 53, 62, 62, 61, 25, 12, 3, 10, 53, 34, 61, 53, 62, 31, 36, 40, 61, 10, 62, 61, 53, 62, 62, 2]\n",
            "pred [1, 27, 61, 53, 38, 11, 40, 61, 3, 62, 62, 23, 61, 4, 10, 34, 61, 53, 62, 36, 40, 61, 9, 62, 61, 53, 62, 62, 61, 25, 12, 3, 10, 53, 34, 61, 53, 62, 31, 36, 40, 61, 10, 62, 61, 53, 62, 62]\n",
            "iter 6000\n",
            "loss 0.10569187529385089\n",
            "trg [1, 23, 61, 27, 61, 48, 38, 15, 62, 13, 14, 25, 13, 33, 40, 61, 14, 62, 61, 25, 10, 48, 31, 62, 3, 20, 40, 61, 15, 62, 61, 25, 11, 48, 31, 62, 31, 62, 61, 15, 62, 2]\n",
            "pred [1, 23, 61, 27, 61, 48, 38, 15, 62, 13, 14, 25, 13, 33, 40, 61, 14, 62, 61, 25, 10, 48, 31, 62, 3, 20, 40, 61, 15, 62, 61, 25, 11, 48, 31, 62, 31, 62, 61, 15, 62]\n",
            "iter 7000\n",
            "loss 0.12986485213041304\n",
            "trg [1, 28, 61, 59, 62, 17, 27, 61, 57, 38, 30, 6, 10, 40, 61, 4, 62, 62, 4, 15, 34, 61, 57, 62, 2]\n",
            "pred [1, 28, 61, 53, 62, 17, 27, 61, 57, 38, 30, 6, 10, 40, 61, 4, 62, 62, 4, 15, 34, 61, 57, 62]\n",
            "iter 8000\n",
            "loss 0.13873337797820567\n",
            "trg [1, 27, 61, 56, 38, 23, 61, 30, 62, 61, 13, 62, 62, 33, 40, 61, 9, 62, 61, 56, 62, 3, 27, 61, 56, 38, 23, 61, 30, 62, 61, 14, 62, 62, 34, 40, 61, 15, 62, 61, 56, 62, 2]\n",
            "pred [1, 27, 61, 56, 38, 23, 61, 30, 62, 61, 13, 62, 62, 33, 40, 61, 9, 62, 61, 56, 62, 3, 27, 61, 56, 38, 23, 61, 30, 62, 61, 14, 62, 62, 34, 40, 61, 15, 62, 61, 56, 62]\n",
            "iter 9000\n",
            "loss 0.1371051160246134\n",
            "trg [1, 27, 61, 54, 38, 12, 62, 23, 61, 23, 61, 45, 62, 61, 45, 54, 62, 33, 61, 25, 16, 54, 31, 62, 62, 61, 23, 61, 45, 62, 61, 45, 54, 62, 34, 61, 25, 11, 54, 31, 62, 62, 2]\n",
            "pred [1, 27, 61, 54, 38, 12, 62, 23, 61, 23, 61, 45, 62, 61, 45, 54, 62, 33, 61, 25, 16, 54, 31, 62, 62, 61, 23, 61, 45, 62, 61, 45, 54, 62, 34, 61, 25, 54, 54, 31, 62, 62]\n",
            "iter 10000\n",
            "loss 0.12488230235874653\n",
            "trg [1, 27, 61, 43, 38, 4, 24, 62, 23, 61, 11, 43, 40, 61, 11, 62, 62, 61, 43, 40, 61, 15, 62, 62, 2]\n",
            "pred [1, 27, 61, 43, 38, 4, 24, 62, 23, 61, 11, 43, 40, 61, 11, 62, 62, 61, 43, 40, 61, 15, 62, 62]\n",
            "iter 11000\n",
            "loss 0.11914283849298954\n",
            "trg [1, 27, 61, 54, 38, 30, 6, 14, 62, 36, 40, 61, 15, 62, 61, 54, 62, 3, 33, 40, 61, 10, 62, 61, 54, 62, 2]\n",
            "pred [1, 27, 61, 54, 38, 30, 6, 14, 62, 36, 40, 61, 15, 62, 61, 54, 62, 3, 33, 40, 61, 10, 62, 61, 54, 62]\n",
            "iter 12000\n",
            "loss 0.117052001953125\n",
            "trg [1, 17, 23, 61, 4, 10, 27, 61, 57, 38, 15, 62, 57, 40, 61, 10, 62, 62, 61, 27, 61, 57, 38, 9, 62, 13, 57, 3, 16, 40, 61, 23, 61, 11, 62, 61, 10, 62, 62, 62, 2]\n",
            "pred [1, 17, 23, 61, 10, 62, 27, 61, 57, 38, 24, 62, 57, 40, 61, 10, 62, 62, 61, 27, 61, 57, 38, 9, 62, 57, 57, 3, 16, 40, 61, 23, 61, 61, 62, 61, 61, 62, 62, 62]\n",
            "iter 13000\n",
            "loss 0.11066879414021968\n",
            "trg [1, 27, 61, 58, 38, 30, 6, 11, 40, 61, 4, 62, 62, 9, 6, 13, 22, 40, 61, 13, 62, 61, 58, 62, 25, 13, 58, 3, 25, 4, 13, 30, 31, 40, 61, 16, 62, 31, 2]\n",
            "pred [1, 27, 61, 58, 38, 30, 6, 11, 40, 61, 4, 62, 62, 9, 6, 13, 22, 40, 61, 13, 62, 61, 58, 62, 25, 13, 58, 3, 25, 4, 13, 30, 31, 40, 61, 16, 62, 31]\n",
            "iter 14000\n",
            "loss 0.1104926474392414\n",
            "trg [1, 27, 61, 59, 38, 9, 40, 61, 3, 62, 62, 23, 61, 59, 62, 61, 26, 59, 4, 13, 32, 62, 2]\n",
            "pred [1, 27, 61, 59, 38, 9, 40, 61, 3, 62, 62, 23, 61, 59, 62, 61, 26, 59, 4, 13, 32, 62]\n",
            "iter 15000\n",
            "loss 0.13429824002087115\n",
            "trg [1, 27, 61, 44, 38, 16, 40, 61, 3, 62, 62, 23, 61, 12, 6, 44, 62, 61, 23, 61, 4, 12, 62, 61, 34, 61, 44, 62, 62, 23, 61, 20, 61, 44, 62, 62, 61, 20, 61, 44, 62, 62, 62, 2]\n",
            "pred [1, 27, 61, 44, 38, 16, 40, 61, 3, 62, 62, 23, 61, 12, 6, 44, 62, 61, 23, 61, 4, 12, 62, 61, 34, 61, 44, 62, 62, 23, 61, 20, 61, 44, 62, 62, 61, 20, 61, 44, 62, 62]\n",
            "iter 16000\n",
            "loss 0.11816458187997342\n",
            "trg [1, 27, 61, 55, 38, 11, 40, 61, 3, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 55, 62, 25, 15, 3, 4, 12, 55, 31, 62, 61, 23, 61, 45, 62, 61, 45, 55, 62, 25, 55, 3, 55, 28, 61, 55, 62, 4, 10, 31, 62, 2]\n",
            "pred [1, 27, 61, 55, 38, 11, 40, 61, 3, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 55, 62, 25, 15, 3, 4, 12, 55, 31, 62, 61, 23, 61, 45, 62, 61, 45, 55, 62, 25, 55, 3, 28, 61, 55, 55, 62, 4, 10, 31, 62]\n",
            "iter 17000\n",
            "loss 0.09674981221556664\n",
            "trg [1, 28, 61, 59, 62, 17, 27, 61, 52, 38, 24, 62, 4, 13, 23, 61, 10, 62, 61, 9, 3, 10, 12, 6, 52, 62, 2]\n",
            "pred [1, 28, 61, 59, 62, 17, 27, 61, 52, 38, 24, 62, 4, 13, 23, 61, 10, 62, 61, 9, 3, 10, 6, 52, 62]\n",
            "iter 18000\n",
            "loss 0.13037462040781975\n",
            "trg [1, 28, 61, 37, 62, 17, 23, 61, 27, 61, 55, 38, 23, 61, 30, 62, 61, 9, 62, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 55, 62, 20, 61, 55, 62, 62, 61, 27, 61, 55, 38, 23, 61, 30, 62, 61, 11, 62, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 55, 62, 4, 15, 36, 40, 61, 13, 62, 61, 55, 62, 62, 2]\n",
            "pred [1, 28, 61, 57, 62, 17, 23, 61, 27, 61, 55, 38, 23, 61, 30, 62, 61, 9, 62, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 55, 62, 20, 61, 55, 62, 62, 61, 27, 61, 55, 38, 23, 61, 30, 62, 61, 11, 62, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 55, 62, 4, 15, 36, 40, 61, 13, 62, 61, 55, 62, 62, 2]\n",
            "iter 19000\n",
            "loss 0.11249850399792194\n",
            "trg [1, 27, 61, 44, 38, 14, 40, 61, 3, 62, 62, 23, 61, 4, 36, 61, 44, 62, 34, 40, 61, 9, 62, 61, 44, 62, 62, 61, 25, 7, 3, 15, 44, 21, 61, 44, 62, 31, 34, 40, 61, 9, 62, 61, 44, 62, 62, 2]\n",
            "pred [1, 27, 61, 44, 38, 14, 40, 61, 3, 62, 62, 23, 61, 4, 36, 61, 44, 62, 34, 40, 61, 9, 62, 61, 44, 62, 62, 61, 25, 7, 3, 15, 44, 21, 61, 44, 62, 31, 34, 40, 61, 9, 62, 61, 44, 62, 62]\n",
            "iter 20000\n",
            "loss 0.10812158666551114\n",
            "trg [1, 27, 61, 49, 38, 16, 40, 61, 3, 62, 62, 46, 40, 61, 28, 61, 25, 16, 3, 49, 40, 61, 36, 61, 49, 62, 62, 31, 62, 62, 2]\n",
            "pred [1, 27, 61, 49, 38, 16, 40, 61, 3, 62, 62, 46, 40, 61, 28, 61, 25, 16, 3, 49, 40, 61, 36, 61, 49, 62, 62, 31, 62, 62]\n",
            "iter 21000\n",
            "loss 0.10209770910441876\n",
            "trg [1, 27, 61, 59, 38, 4, 24, 62, 23, 61, 7, 62, 61, 59, 40, 61, 10, 62, 62, 2]\n",
            "pred [1, 27, 61, 59, 38, 4, 24, 62, 23, 61, 7, 62, 61, 59, 40, 61, 10, 62, 62]\n",
            "iter 22000\n",
            "loss 0.10144631616771221\n",
            "trg [1, 27, 61, 53, 38, 12, 62, 23, 61, 53, 4, 9, 40, 61, 13, 62, 4, 8, 9, 62, 61, 53, 4, 8, 62, 2]\n",
            "pred [1, 27, 61, 53, 38, 12, 62, 23, 61, 53, 4, 9, 40, 61, 13, 62, 4, 8, 9, 62, 61, 53, 4, 8, 62]\n",
            "iter 23000\n",
            "loss 0.10892073206603527\n",
            "trg [1, 23, 61, 27, 61, 58, 38, 14, 62, 23, 61, 45, 62, 61, 45, 58, 62, 15, 34, 40, 61, 8, 62, 61, 25, 7, 31, 62, 62, 61, 27, 61, 58, 38, 10, 62, 23, 61, 45, 62, 61, 45, 58, 62, 58, 40, 61, 9, 62, 62, 2]\n",
            "pred [1, 23, 61, 27, 61, 58, 38, 14, 62, 23, 61, 45, 62, 61, 45, 58, 62, 15, 34, 40, 61, 8, 62, 61, 25, 7, 31, 62, 62, 61, 27, 61, 58, 38, 10, 62, 23, 61, 45, 62, 61, 45, 58, 62, 58, 40, 61, 9, 62, 62]\n",
            "iter 24000\n",
            "loss 0.1077689465880394\n",
            "trg [1, 27, 61, 48, 38, 4, 24, 62, 23, 61, 11, 9, 48, 40, 61, 12, 62, 62, 61, 9, 26, 48, 40, 61, 10, 62, 32, 62, 2]\n",
            "pred [1, 27, 61, 48, 38, 4, 24, 62, 23, 61, 11, 9, 48, 40, 61, 12, 62, 62, 61, 9, 26, 48, 40, 61, 10, 62, 32, 62]\n",
            "iter 25000\n",
            "loss 0.12363740473985672\n",
            "trg [1, 23, 61, 27, 61, 60, 38, 9, 62, 23, 61, 45, 62, 61, 45, 60, 62, 9, 12, 36, 61, 25, 7, 31, 62, 22, 61, 25, 14, 60, 31, 62, 62, 61, 27, 61, 60, 38, 12, 62, 23, 61, 45, 62, 61, 45, 60, 62, 13, 60, 62, 2]\n",
            "pred [1, 23, 61, 27, 61, 60, 38, 9, 62, 23, 61, 45, 62, 61, 45, 60, 62, 9, 12, 36, 61, 25, 7, 31, 62, 22, 61, 25, 14, 60, 31, 62, 62, 61, 27, 61, 60, 38, 12, 62, 23, 61, 45, 62, 61, 45, 60, 62, 13, 60, 62]\n",
            "iter 26000\n",
            "loss 0.151862074136734\n",
            "trg [1, 27, 61, 37, 38, 30, 6, 10, 62, 23, 61, 9, 3, 20, 61, 10, 62, 37, 62, 61, 11, 3, 4, 14, 20, 61, 13, 62, 37, 62, 2]\n",
            "pred [1, 27, 61, 37, 38, 30, 6, 10, 62, 23, 61, 9, 3, 20, 61, 10, 62, 37, 62, 61, 11, 3, 4, 14, 20, 61, 13, 62, 37, 62]\n",
            "iter 27000\n",
            "loss 0.1239827510714531\n",
            "trg [1, 27, 61, 54, 38, 9, 40, 61, 3, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 54, 62, 25, 16, 3, 4, 9, 36, 40, 61, 8, 62, 61, 54, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 54, 62, 25, 36, 61, 54, 62, 3, 54, 20, 40, 61, 16, 62, 61, 54, 62, 31, 62, 2]\n",
            "pred [1, 27, 61, 54, 38, 9, 40, 61, 3, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 54, 62, 25, 16, 3, 4, 9, 36, 40, 61, 8, 62, 61, 54, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 54, 62, 25, 36, 61, 54, 62, 3, 54, 20, 40, 61, 16, 62, 61, 54, 62, 31, 62]\n",
            "iter 28000\n",
            "loss 0.12753290094435216\n",
            "trg [1, 27, 61, 59, 38, 14, 62, 4, 59, 2]\n",
            "pred [1, 27, 61, 59, 38, 14, 62, 4, 59]\n",
            "iter 29000\n",
            "loss 0.11811176598072053\n",
            "trg [1, 27, 61, 57, 38, 15, 62, 23, 61, 12, 25, 57, 3, 7, 31, 35, 61, 57, 3, 16, 62, 62, 61, 10, 3, 4, 12, 35, 61, 57, 3, 13, 62, 62, 2]\n",
            "pred [1, 27, 61, 57, 38, 15, 62, 23, 61, 12, 25, 57, 3, 7, 31, 35, 61, 57, 3, 16, 62, 62, 61, 10, 57, 3, 4, 12, 35, 61, 57, 3, 13, 62, 62]\n",
            "iter 30000\n",
            "loss 0.12253530956804752\n",
            "trg [1, 27, 61, 55, 38, 9, 62, 23, 61, 14, 34, 40, 61, 9, 62, 61, 25, 9, 55, 31, 62, 62, 61, 55, 40, 61, 13, 62, 62, 2]\n",
            "pred [1, 27, 61, 55, 38, 9, 62, 23, 61, 14, 34, 40, 61, 9, 62, 61, 25, 9, 55, 31, 62, 62, 61, 55, 40, 61, 13, 62, 62]\n",
            "iter 31000\n",
            "loss 0.13372025795280934\n",
            "trg [1, 27, 61, 52, 38, 9, 62, 23, 61, 15, 62, 61, 52, 62, 3, 11, 23, 61, 11, 62, 61, 34, 61, 52, 62, 62, 2]\n",
            "pred [1, 27, 61, 52, 38, 9, 62, 23, 61, 15, 62, 61, 52, 62, 61, 11, 23, 61, 11, 62, 61, 34, 61, 52, 62, 62]\n",
            "iter 32000\n",
            "loss 0.14399864867329598\n",
            "trg [1, 27, 61, 60, 38, 14, 40, 61, 3, 62, 62, 23, 61, 4, 11, 20, 61, 60, 62, 20, 40, 61, 9, 62, 61, 60, 62, 62, 61, 25, 13, 3, 15, 60, 36, 61, 60, 62, 31, 20, 40, 61, 16, 62, 61, 60, 62, 62, 2]\n",
            "pred [1, 27, 61, 60, 38, 14, 40, 61, 3, 62, 62, 23, 61, 4, 11, 20, 61, 60, 62, 20, 40, 61, 9, 62, 61, 60, 62, 62, 61, 25, 13, 3, 15, 60, 36, 61, 60, 62, 31, 20, 40, 61, 16, 62, 61, 60, 62, 62]\n",
            "iter 33000\n",
            "loss 0.1548715491592884\n",
            "trg [1, 27, 61, 42, 38, 11, 40, 61, 3, 62, 62, 23, 61, 23, 61, 9, 62, 61, 42, 62, 62, 61, 4, 9, 20, 61, 42, 62, 34, 61, 42, 62, 62, 2]\n",
            "pred [1, 27, 61, 42, 38, 11, 40, 61, 3, 62, 62, 23, 61, 23, 61, 9, 62, 61, 42, 62, 62, 61, 4, 9, 20, 61, 42, 62, 34, 61, 42, 62, 62]\n",
            "iter 34000\n",
            "loss 0.12171802304685116\n",
            "trg [1, 27, 61, 47, 38, 30, 6, 13, 62, 33, 40, 61, 11, 62, 61, 47, 62, 3, 20, 40, 61, 11, 62, 61, 47, 62, 2]\n",
            "pred [1, 27, 61, 47, 38, 30, 6, 13, 62, 33, 40, 61, 11, 62, 61, 47, 62, 3, 20, 40, 61, 11, 62, 61, 47, 62]\n",
            "iter 35000\n",
            "loss 0.09936689466238022\n",
            "trg [1, 8, 27, 61, 57, 38, 9, 62, 23, 61, 34, 61, 25, 15, 57, 31, 62, 62, 61, 14, 57, 62, 2]\n",
            "pred [1, 14, 6, 61, 27, 61, 57, 38, 23, 61, 34, 61, 25, 15, 57, 31, 62, 62, 61, 14, 57, 62]\n",
            "iter 36000\n",
            "loss 0.11322779759764671\n",
            "trg [1, 27, 61, 58, 38, 10, 40, 61, 3, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 58, 62, 25, 9, 3, 4, 12, 33, 40, 61, 9, 62, 61, 58, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 58, 62, 25, 36, 61, 58, 62, 3, 58, 33, 40, 61, 15, 62, 61, 58, 62, 31, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 10, 40, 61, 3, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 58, 62, 25, 9, 3, 4, 12, 33, 40, 61, 9, 62, 61, 58, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 58, 62, 25, 36, 61, 58, 62, 3, 58, 33, 40, 61, 15, 62, 61, 58, 62, 31, 62]\n",
            "iter 37000\n",
            "loss 0.12067153513431549\n",
            "trg [1, 27, 61, 44, 38, 9, 40, 61, 3, 62, 62, 4, 9, 36, 61, 44, 62, 2]\n",
            "pred [1, 27, 61, 44, 38, 9, 40, 61, 3, 62, 62, 4, 9, 36, 61, 44, 62]\n",
            "iter 38000\n",
            "loss 0.13246984854340554\n",
            "trg [1, 27, 61, 44, 38, 30, 6, 15, 62, 23, 61, 12, 3, 4, 11, 36, 61, 44, 62, 62, 61, 9, 44, 3, 4, 13, 30, 62, 2]\n",
            "pred [1, 27, 61, 44, 38, 30, 6, 15, 62, 23, 61, 12, 3, 4, 11, 36, 61, 44, 62, 62, 61, 9, 44, 3, 4, 13, 30, 62]\n",
            "iter 39000\n",
            "loss 0.11999947637319565\n",
            "trg [1, 27, 61, 49, 38, 30, 6, 9, 62, 36, 40, 61, 13, 62, 61, 49, 62, 3, 36, 40, 61, 9, 62, 61, 49, 62, 2]\n",
            "pred [1, 27, 61, 49, 38, 30, 6, 9, 62, 36, 40, 61, 13, 62, 61, 49, 62, 3, 36, 40, 61, 9, 62, 61, 49, 62]\n",
            "iter 40000\n",
            "loss 0.1198427790403366\n",
            "trg [1, 27, 61, 55, 38, 13, 62, 23, 61, 11, 3, 34, 61, 55, 62, 62, 61, 7, 3, 4, 9, 34, 40, 61, 10, 62, 61, 55, 62, 62, 2]\n",
            "pred [1, 27, 61, 55, 38, 13, 62, 23, 61, 11, 3, 34, 61, 55, 62, 62, 61, 7, 3, 4, 9, 34, 40, 61, 10, 62, 61, 55, 62, 62]\n",
            "iter 41000\n",
            "loss 0.11953762270510197\n",
            "trg [1, 27, 61, 59, 38, 9, 62, 23, 61, 15, 62, 61, 21, 61, 59, 62, 62, 27, 61, 59, 38, 9, 62, 23, 61, 15, 3, 4, 15, 20, 61, 59, 62, 62, 61, 59, 62, 2]\n",
            "pred [1, 27, 61, 59, 38, 9, 62, 23, 61, 15, 62, 61, 21, 61, 59, 62, 62, 27, 61, 59, 38, 9, 62, 23, 61, 15, 3, 4, 15, 20, 61, 59, 62, 62, 61, 59, 62]\n",
            "iter 42000\n",
            "loss 0.10918595358729362\n",
            "trg [1, 27, 61, 47, 38, 24, 62, 23, 61, 29, 41, 61, 11, 14, 62, 61, 47, 62, 29, 41, 61, 12, 62, 61, 8, 62, 62, 61, 29, 41, 61, 9, 7, 62, 61, 13, 62, 29, 41, 61, 16, 9, 62, 61, 47, 62, 62, 2]\n",
            "pred [1, 27, 61, 47, 38, 24, 62, 23, 61, 29, 41, 61, 11, 14, 62, 61, 47, 62, 29, 41, 61, 12, 12, 62, 61, 8, 62, 62, 61, 29, 41, 61, 9, 7, 62, 61, 13, 62, 29, 41, 61, 16, 9, 62, 61, 47, 62, 62]\n",
            "iter 43000\n",
            "loss 0.12531171269714833\n",
            "trg [1, 27, 61, 47, 38, 30, 6, 10, 40, 61, 4, 62, 62, 34, 61, 47, 62, 3, 4, 10, 33, 61, 47, 62, 2]\n",
            "pred [1, 27, 61, 47, 38, 30, 6, 10, 40, 61, 4, 62, 62, 34, 61, 47, 62, 3, 4, 10, 33, 61, 47, 62]\n",
            "iter 44000\n",
            "loss 0.11346500135958194\n",
            "trg [1, 27, 61, 53, 38, 23, 61, 30, 62, 61, 11, 62, 62, 23, 61, 9, 33, 40, 61, 16, 62, 61, 53, 62, 3, 4, 10, 22, 40, 61, 10, 62, 61, 53, 62, 62, 61, 10, 62, 2]\n",
            "pred [1, 27, 61, 53, 38, 23, 61, 30, 62, 61, 11, 62, 62, 23, 61, 9, 33, 40, 61, 16, 62, 61, 53, 62, 3, 4, 10, 22, 40, 61, 10, 62, 61, 53, 62, 62, 61, 10, 62]\n",
            "iter 45000\n",
            "loss 0.10296084709465504\n",
            "trg [1, 27, 61, 58, 38, 7, 62, 23, 61, 20, 61, 25, 13, 58, 31, 62, 62, 61, 33, 61, 58, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 7, 62, 23, 61, 20, 61, 25, 13, 58, 31, 62, 62, 61, 33, 61, 58, 62, 62]\n",
            "iter 46000\n",
            "loss 0.09199351347982883\n",
            "trg [1, 27, 61, 48, 38, 30, 6, 15, 40, 61, 4, 62, 62, 10, 6, 9, 20, 40, 61, 14, 62, 61, 48, 62, 25, 9, 48, 3, 25, 4, 16, 30, 31, 40, 61, 10, 62, 31, 2]\n",
            "pred [1, 27, 61, 48, 38, 30, 6, 15, 40, 61, 4, 62, 62, 10, 6, 9, 20, 40, 61, 14, 62, 61, 48, 62, 25, 9, 48, 3, 25, 4, 16, 30, 31, 40, 61, 10, 62, 31]\n",
            "iter 47000\n",
            "loss 0.10096009269356727\n",
            "trg [1, 27, 61, 55, 38, 8, 62, 55, 34, 61, 55, 62, 2]\n",
            "pred [1, 27, 61, 55, 38, 8, 62, 55, 34, 61, 55, 62]\n",
            "iter 48000\n",
            "loss 0.09213308781385422\n",
            "trg [1, 27, 61, 47, 38, 10, 40, 61, 3, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 47, 62, 25, 7, 3, 4, 15, 36, 40, 61, 16, 62, 61, 47, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 47, 62, 25, 34, 61, 47, 62, 3, 47, 34, 40, 61, 9, 62, 61, 47, 62, 31, 62, 2]\n",
            "pred [1, 27, 61, 47, 38, 10, 40, 61, 3, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 47, 62, 25, 7, 3, 4, 15, 36, 40, 61, 16, 62, 61, 47, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 47, 62, 25, 34, 61, 47, 62, 3, 47, 34, 40, 61, 9, 62, 61, 47, 62, 31, 62]\n",
            "iter 49000\n",
            "loss 0.11019215375185012\n",
            "trg [1, 27, 61, 48, 38, 14, 62, 35, 18, 10, 39, 61, 14, 48, 3, 10, 62, 2]\n",
            "pred [1, 27, 61, 48, 38, 14, 62, 35, 18, 10, 39, 61, 14, 48, 3, 10, 62]\n",
            "iter 50000\n",
            "loss 0.11361805409193039\n",
            "trg [1, 27, 61, 58, 38, 43, 62, 23, 61, 58, 40, 61, 11, 62, 3, 4, 10, 43, 58, 3, 43, 40, 61, 7, 62, 62, 61, 58, 3, 4, 13, 43, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 43, 62, 23, 61, 58, 40, 61, 11, 62, 3, 4, 10, 43, 58, 3, 7, 40, 61, 7, 62, 62, 61, 58, 3, 4, 13, 43, 62]\n",
            "iter 51000\n",
            "loss 0.10062578164041042\n",
            "trg [1, 27, 61, 53, 38, 23, 61, 30, 62, 61, 16, 62, 40, 61, 4, 62, 62, 33, 40, 61, 34, 61, 25, 53, 31, 62, 62, 25, 53, 31, 2]\n",
            "pred [1, 27, 61, 53, 38, 23, 61, 30, 62, 61, 16, 62, 40, 61, 4, 62, 62, 33, 40, 61, 34, 61, 25, 53, 31, 62, 62, 25, 53, 31]\n",
            "iter 52000\n",
            "loss 0.1259119477123022\n",
            "trg [1, 27, 61, 37, 38, 23, 61, 30, 62, 61, 14, 62, 40, 61, 4, 62, 62, 36, 61, 37, 62, 3, 4, 14, 33, 61, 37, 62, 2]\n",
            "pred [1, 27, 61, 37, 38, 23, 61, 30, 62, 61, 14, 62, 40, 61, 4, 62, 62, 36, 61, 37, 62, 3, 4, 14, 33, 61, 37, 62]\n",
            "iter 53000\n",
            "loss 0.11509125992655754\n",
            "trg [1, 17, 27, 61, 58, 38, 30, 6, 13, 62, 23, 61, 13, 20, 40, 61, 10, 62, 61, 58, 62, 3, 11, 20, 40, 61, 14, 62, 61, 58, 62, 62, 61, 12, 62, 2]\n",
            "pred [1, 17, 27, 61, 58, 38, 30, 6, 13, 62, 23, 61, 13, 20, 40, 61, 10, 62, 61, 58, 62, 3, 11, 20, 40, 61, 14, 62, 61, 58, 62, 62, 61, 12, 62]\n",
            "iter 54000\n",
            "loss 0.10475748360157013\n",
            "trg [1, 27, 61, 55, 38, 15, 62, 23, 61, 34, 61, 55, 62, 4, 10, 62, 61, 33, 40, 61, 8, 62, 61, 55, 62, 62, 2]\n",
            "pred [1, 27, 61, 55, 38, 15, 62, 23, 61, 34, 61, 55, 62, 4, 10, 62, 61, 33, 40, 61, 8, 62, 61, 55, 62, 62]\n",
            "iter 55000\n",
            "loss 0.09947205804288388\n",
            "trg [1, 27, 61, 54, 38, 8, 40, 61, 3, 62, 62, 54, 40, 61, 34, 61, 54, 62, 62, 2]\n",
            "pred [1, 27, 61, 54, 38, 8, 40, 61, 3, 62, 62, 54, 40, 61, 34, 61, 54, 62, 62]\n",
            "iter 56000\n",
            "loss 0.11652282796800137\n",
            "trg [1, 27, 61, 57, 38, 4, 24, 62, 23, 61, 13, 8, 57, 40, 61, 14, 62, 62, 61, 10, 26, 57, 40, 61, 16, 62, 32, 62, 2]\n",
            "pred [1, 27, 61, 57, 38, 4, 24, 62, 23, 61, 13, 8, 57, 40, 61, 14, 62, 62, 61, 10, 26, 57, 40, 61, 16, 62, 32, 62]\n",
            "iter 57000\n",
            "loss 0.09536384329199792\n",
            "trg [1, 27, 61, 55, 38, 4, 24, 62, 9, 3, 4, 11, 55, 3, 55, 2]\n",
            "pred [1, 27, 61, 55, 38, 4, 24, 62, 9, 3, 4, 11, 55, 3, 55]\n",
            "iter 58000\n",
            "loss 0.11358166076242923\n",
            "trg [1, 27, 61, 57, 38, 12, 40, 61, 3, 62, 62, 23, 61, 4, 36, 61, 57, 62, 33, 40, 61, 15, 62, 61, 57, 62, 62, 61, 34, 40, 61, 13, 62, 61, 57, 62, 3, 25, 57, 34, 61, 57, 62, 3, 14, 31, 34, 40, 61, 11, 62, 61, 57, 62, 62, 2]\n",
            "pred [1, 27, 61, 57, 38, 12, 40, 61, 3, 62, 62, 23, 61, 4, 36, 61, 57, 62, 33, 40, 61, 15, 62, 61, 57, 62, 62, 61, 34, 40, 61, 13, 62, 61, 57, 62, 3, 25, 57, 34, 61, 57, 62, 3, 14, 31, 34, 40, 61, 11, 62, 61, 57, 62, 62]\n",
            "iter 59000\n",
            "loss 0.09522653475403786\n",
            "trg [1, 27, 61, 47, 38, 30, 62, 20, 61, 47, 62, 3, 7, 2]\n",
            "pred [1, 27, 61, 47, 38, 30, 62, 20, 61, 47, 62, 3, 7]\n",
            "iter 60000\n",
            "loss 0.0948483456671238\n",
            "trg [1, 27, 61, 54, 38, 30, 6, 9, 40, 61, 4, 62, 62, 23, 61, 20, 40, 61, 9, 62, 61, 54, 62, 62, 61, 23, 61, 13, 62, 61, 9, 54, 3, 25, 13, 30, 31, 40, 61, 16, 62, 62, 62, 2]\n",
            "pred [1, 27, 61, 54, 38, 30, 6, 9, 40, 61, 4, 62, 62, 23, 61, 20, 40, 61, 9, 62, 61, 54, 62, 62, 61, 23, 61, 13, 62, 61, 9, 54, 3, 25, 13, 30, 31, 40, 61, 16, 62, 62, 62]\n",
            "iter 61000\n",
            "loss 0.09109291687607765\n",
            "trg [1, 27, 61, 56, 38, 10, 40, 61, 3, 62, 62, 23, 61, 4, 36, 61, 56, 62, 34, 40, 61, 9, 62, 61, 56, 62, 62, 61, 34, 40, 61, 14, 62, 61, 56, 62, 3, 25, 56, 36, 61, 56, 62, 3, 16, 31, 20, 40, 61, 14, 62, 61, 56, 62, 62, 2]\n",
            "pred [1, 27, 61, 56, 38, 10, 40, 61, 3, 62, 62, 23, 61, 4, 36, 61, 56, 62, 34, 40, 61, 9, 62, 61, 56, 62, 62, 61, 34, 40, 61, 14, 62, 61, 56, 62, 3, 25, 56, 36, 61, 56, 62, 3, 16, 31, 20, 40, 61, 14, 62, 61, 56, 62, 62]\n",
            "iter 62000\n",
            "loss 0.08398235760629177\n",
            "trg [1, 27, 61, 58, 38, 23, 61, 30, 62, 61, 14, 62, 62, 23, 61, 21, 40, 61, 16, 62, 61, 58, 62, 3, 36, 40, 61, 16, 62, 61, 58, 62, 62, 61, 16, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 23, 61, 30, 62, 61, 14, 62, 62, 23, 61, 21, 40, 61, 16, 62, 61, 58, 62, 3, 36, 40, 61, 16, 62, 61, 58, 62, 62, 61, 16, 62]\n",
            "iter 63000\n",
            "loss 0.10611289970576764\n",
            "trg [1, 27, 61, 44, 38, 23, 61, 30, 62, 61, 9, 62, 62, 23, 61, 20, 61, 44, 62, 3, 4, 14, 34, 61, 44, 62, 62, 61, 44, 3, 4, 16, 23, 61, 30, 62, 61, 15, 62, 62, 2]\n",
            "pred [1, 27, 61, 44, 38, 23, 61, 30, 62, 61, 9, 62, 62, 23, 61, 20, 61, 44, 62, 3, 4, 14, 34, 61, 44, 62, 62, 61, 44, 3, 4, 16, 23, 61, 30, 62, 61, 15, 62, 62]\n",
            "iter 64000\n",
            "loss 0.11025615610182285\n",
            "trg [1, 27, 61, 48, 38, 14, 40, 61, 3, 62, 62, 46, 40, 61, 28, 61, 25, 9, 3, 48, 40, 61, 36, 61, 48, 62, 62, 31, 62, 62, 2]\n",
            "pred [1, 27, 61, 48, 38, 14, 40, 61, 3, 62, 62, 46, 40, 61, 28, 61, 25, 9, 3, 48, 40, 61, 36, 61, 48, 62, 62, 31, 62, 62]\n",
            "iter 65000\n",
            "loss 0.10414808541536331\n",
            "trg [1, 27, 61, 60, 38, 4, 24, 62, 23, 61, 60, 40, 61, 11, 62, 3, 4, 10, 25, 60, 40, 61, 14, 62, 3, 16, 60, 40, 61, 13, 62, 31, 62, 61, 60, 40, 61, 9, 62, 3, 35, 61, 60, 40, 61, 8, 62, 3, 9, 60, 40, 61, 16, 62, 62, 62, 2]\n",
            "pred [1, 27, 61, 60, 38, 4, 24, 62, 23, 61, 11, 60, 3, 11, 62, 25, 60, 40, 61, 14, 62, 3, 16, 60, 62, 62, 61, 60, 40, 61, 61, 61, 62, 61, 60, 40, 61, 9, 62, 3, 35, 61, 60, 40, 61, 9, 62, 3, 9, 40, 40, 61, 16, 62, 62, 62]\n",
            "iter 66000\n",
            "loss 0.08794173948466778\n",
            "trg [1, 27, 61, 60, 38, 14, 62, 23, 61, 60, 4, 10, 62, 61, 35, 61, 60, 40, 61, 14, 62, 3, 4, 11, 60, 3, 10, 62, 62, 2]\n",
            "pred [1, 27, 61, 60, 38, 14, 62, 23, 61, 60, 4, 10, 62, 61, 35, 61, 14, 60, 3, 4, 11, 3, 10, 10, 62]\n",
            "iter 67000\n",
            "loss 0.103612614646554\n",
            "trg [1, 27, 61, 55, 38, 7, 62, 23, 61, 55, 3, 12, 40, 61, 16, 62, 62, 61, 55, 3, 8, 62, 2]\n",
            "pred [1, 27, 61, 55, 38, 7, 62, 23, 61, 55, 3, 12, 62, 61, 55, 3, 8, 62, 61, 62]\n",
            "iter 68000\n",
            "loss 0.08990846313536167\n",
            "trg [1, 27, 61, 56, 38, 23, 61, 30, 62, 61, 9, 62, 62, 23, 61, 9, 36, 40, 61, 10, 62, 61, 56, 62, 3, 4, 9, 34, 40, 61, 16, 62, 61, 56, 62, 62, 61, 9, 62, 2]\n",
            "pred [1, 27, 61, 56, 38, 23, 61, 30, 62, 61, 9, 62, 62, 23, 61, 9, 36, 40, 61, 10, 62, 61, 56, 62, 3, 4, 9, 34, 40, 61, 16, 62, 61, 56, 62, 62, 61, 9, 62]\n",
            "iter 69000\n",
            "loss 0.092593135535717\n",
            "trg [1, 27, 61, 37, 38, 9, 62, 23, 61, 23, 61, 12, 62, 61, 20, 61, 37, 62, 62, 3, 12, 62, 61, 37, 62, 2]\n",
            "pred [1, 27, 61, 37, 38, 9, 62, 23, 61, 23, 61, 12, 62, 61, 20, 61, 37, 62, 62, 3, 12, 62, 61, 37, 62]\n",
            "iter 1000\n",
            "loss 0.11673207029700279\n",
            "trg [1, 27, 61, 48, 38, 23, 61, 30, 62, 61, 10, 62, 62, 34, 40, 61, 11, 62, 61, 48, 62, 3, 27, 61, 48, 38, 23, 61, 30, 62, 61, 14, 62, 62, 33, 40, 61, 10, 62, 61, 48, 62, 2]\n",
            "pred [1, 27, 61, 48, 38, 23, 61, 30, 62, 61, 10, 62, 62, 34, 40, 61, 11, 62, 61, 48, 62, 3, 27, 61, 48, 38, 23, 61, 30, 62, 61, 14, 62, 62, 33, 40, 61, 10, 62, 61, 48, 62]\n",
            "iter 2000\n",
            "loss 0.11009140707552433\n",
            "trg [1, 27, 61, 57, 38, 10, 40, 61, 3, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 57, 62, 25, 13, 3, 4, 15, 33, 40, 61, 9, 62, 61, 57, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 57, 62, 25, 36, 61, 57, 62, 3, 57, 36, 40, 61, 8, 62, 61, 57, 62, 31, 62, 2]\n",
            "pred [1, 27, 61, 57, 38, 10, 40, 61, 3, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 57, 62, 25, 13, 3, 4, 15, 33, 40, 61, 9, 62, 61, 57, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 57, 62, 25, 36, 61, 57, 62, 3, 57, 36, 40, 61, 8, 62, 61, 57, 62, 31, 62]\n",
            "iter 3000\n",
            "loss 0.1069889434427023\n",
            "trg [1, 27, 61, 44, 38, 11, 40, 61, 3, 62, 62, 23, 61, 23, 61, 13, 62, 61, 44, 62, 62, 61, 4, 10, 34, 61, 44, 62, 33, 61, 44, 62, 62, 2]\n",
            "pred [1, 27, 61, 44, 38, 11, 40, 61, 3, 62, 62, 23, 61, 23, 61, 13, 62, 61, 44, 62, 62, 61, 4, 10, 34, 61, 44, 62, 33, 61, 44, 62, 62]\n",
            "iter 4000\n",
            "loss 0.10803364872932435\n",
            "trg [1, 27, 61, 51, 38, 16, 62, 23, 61, 7, 3, 4, 36, 61, 25, 11, 51, 31, 62, 62, 61, 8, 51, 40, 61, 10, 62, 62, 2]\n",
            "pred [1, 27, 61, 51, 38, 16, 62, 23, 61, 7, 3, 4, 36, 61, 25, 11, 51, 31, 62, 62, 61, 8, 51, 40, 61, 10, 62, 62]\n",
            "iter 5000\n",
            "loss 0.10655495561659337\n",
            "trg [1, 27, 61, 58, 38, 8, 40, 61, 3, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 58, 62, 25, 7, 3, 4, 10, 34, 40, 61, 10, 62, 61, 58, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 58, 62, 25, 34, 61, 58, 62, 3, 58, 36, 40, 61, 13, 62, 61, 58, 62, 31, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 8, 40, 61, 3, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 58, 62, 25, 7, 3, 4, 10, 34, 40, 61, 10, 62, 61, 58, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 58, 62, 25, 34, 61, 58, 62, 3, 58, 36, 40, 61, 13, 62, 61, 58, 62, 31, 62]\n",
            "iter 6000\n",
            "loss 0.11761442452669144\n",
            "trg [1, 27, 61, 52, 38, 12, 62, 23, 61, 25, 52, 4, 15, 31, 25, 35, 61, 14, 52, 3, 7, 62, 3, 15, 31, 62, 61, 9, 52, 3, 15, 4, 8, 62, 2]\n",
            "pred [1, 27, 61, 52, 38, 12, 62, 23, 61, 25, 52, 4, 15, 31, 25, 35, 61, 14, 52, 3, 15, 62, 3, 15, 31, 62, 61, 9, 52, 3, 15, 4, 8, 62]\n",
            "iter 7000\n",
            "loss 0.11618980318307877\n",
            "trg [1, 27, 61, 54, 38, 9, 40, 61, 4, 62, 62, 23, 61, 16, 62, 61, 54, 3, 13, 62, 2]\n",
            "pred [1, 27, 61, 54, 38, 9, 40, 61, 4, 62, 62, 23, 61, 16, 62, 61, 54, 3, 13, 62]\n",
            "iter 8000\n",
            "loss 0.1359407152235508\n",
            "trg [1, 27, 61, 54, 38, 24, 62, 10, 3, 23, 61, 13, 62, 61, 54, 62, 3, 23, 61, 8, 13, 62, 61, 54, 40, 61, 13, 62, 62, 2]\n",
            "pred [1, 27, 61, 54, 38, 24, 62, 10, 3, 23, 61, 13, 62, 61, 54, 62, 3, 23, 61, 8, 13, 62, 61, 54, 40, 61, 13, 62, 62]\n",
            "iter 9000\n",
            "loss 0.12291477739810944\n",
            "trg [1, 27, 61, 48, 38, 24, 62, 23, 61, 29, 41, 61, 10, 12, 62, 61, 48, 62, 62, 61, 29, 41, 61, 9, 16, 62, 61, 9, 62, 62, 23, 61, 29, 41, 61, 8, 16, 62, 61, 11, 62, 62, 61, 29, 41, 61, 14, 16, 62, 61, 48, 62, 62, 2]\n",
            "pred [1, 27, 61, 48, 38, 24, 62, 23, 61, 29, 41, 61, 10, 12, 62, 61, 48, 62, 62, 61, 29, 41, 61, 9, 16, 62, 61, 9, 62, 62, 23, 61, 29, 41, 61, 8, 16, 62, 61, 11, 62, 62, 61, 29, 41, 61, 14, 16, 62, 61, 48, 62, 62]\n",
            "iter 10000\n",
            "loss 0.11898258656263351\n",
            "trg [1, 27, 61, 48, 38, 12, 40, 61, 3, 62, 62, 23, 61, 25, 48, 4, 16, 31, 25, 48, 4, 14, 31, 62, 61, 48, 40, 61, 9, 62, 25, 48, 3, 7, 31, 62, 2]\n",
            "pred [1, 27, 61, 48, 38, 12, 40, 61, 3, 62, 62, 23, 61, 25, 48, 4, 16, 31, 25, 48, 4, 14, 31, 62, 61, 48, 40, 61, 9, 62, 25, 48, 3, 7, 31, 62]\n",
            "iter 11000\n",
            "loss 0.10274100758135318\n",
            "trg [1, 27, 61, 59, 38, 10, 40, 61, 3, 62, 62, 23, 61, 4, 9, 34, 61, 59, 62, 33, 40, 61, 14, 62, 61, 59, 62, 62, 61, 34, 40, 61, 8, 62, 61, 59, 62, 3, 25, 7, 20, 61, 59, 62, 3, 11, 31, 34, 40, 61, 8, 62, 61, 59, 62, 62, 2]\n",
            "pred [1, 27, 61, 59, 38, 10, 40, 61, 3, 62, 62, 23, 61, 4, 9, 34, 61, 59, 62, 33, 40, 61, 14, 62, 61, 59, 62, 62, 61, 34, 40, 61, 8, 62, 61, 59, 62, 3, 25, 7, 20, 61, 59, 62, 3, 11, 31, 34, 40, 61, 8, 62, 61, 59, 62, 62, 2]\n",
            "iter 12000\n",
            "loss 0.10921486862003803\n",
            "trg [1, 27, 61, 57, 38, 24, 62, 23, 61, 10, 57, 40, 61, 9, 62, 62, 61, 16, 57, 40, 61, 16, 62, 62, 2]\n",
            "pred [1, 27, 61, 57, 38, 24, 62, 23, 61, 10, 57, 40, 61, 9, 62, 62, 61, 16, 57, 40, 61, 16, 62, 62]\n",
            "iter 13000\n",
            "loss 0.11467870526015758\n",
            "trg [1, 27, 61, 54, 38, 23, 61, 30, 62, 61, 12, 62, 40, 61, 4, 62, 62, 23, 61, 9, 62, 61, 9, 62, 34, 40, 61, 9, 62, 61, 54, 62, 25, 11, 54, 3, 25, 4, 13, 30, 31, 40, 61, 9, 62, 31, 2]\n",
            "pred [1, 27, 61, 54, 38, 23, 61, 30, 62, 61, 12, 62, 40, 61, 4, 62, 62, 23, 61, 9, 62, 61, 9, 62, 34, 40, 61, 9, 62, 61, 54, 62, 25, 11, 54, 3, 25, 4, 13, 30, 31, 40, 61, 9, 62, 31]\n",
            "iter 14000\n",
            "loss 0.12923844069242477\n",
            "trg [1, 12, 6, 14, 27, 61, 43, 38, 11, 62, 23, 61, 34, 61, 25, 11, 43, 31, 62, 62, 61, 11, 43, 62, 2]\n",
            "pred [1, 9, 6, 14, 27, 61, 43, 38, 11, 62, 23, 61, 34, 61, 25, 11, 43, 31, 62, 62, 61, 11, 43, 62]\n",
            "iter 1000\n",
            "loss 0.13201686829328538\n",
            "trg [1, 27, 61, 50, 38, 24, 62, 8, 50, 40, 61, 8, 12, 62, 2]\n",
            "pred [1, 27, 61, 50, 38, 24, 62, 8, 50, 40, 61, 8, 12, 62]\n",
            "iter 2000\n",
            "loss 0.14280238978564738\n",
            "trg [1, 27, 61, 52, 38, 10, 62, 23, 61, 36, 61, 52, 62, 4, 13, 62, 61, 36, 40, 61, 11, 62, 61, 52, 62, 62, 2]\n",
            "pred [1, 27, 61, 52, 38, 10, 62, 23, 61, 36, 61, 52, 62, 4, 13, 62, 61, 36, 40, 61, 11, 62, 61, 52, 62, 62]\n",
            "iter 3000\n",
            "loss 0.14508890807628633\n",
            "trg [1, 27, 61, 42, 38, 30, 6, 9, 40, 61, 4, 62, 62, 23, 61, 36, 40, 61, 9, 62, 61, 42, 62, 62, 61, 13, 23, 61, 4, 16, 62, 61, 9, 42, 3, 25, 4, 14, 30, 31, 40, 61, 9, 62, 62, 62, 2]\n",
            "pred [1, 27, 61, 42, 38, 30, 6, 9, 40, 61, 4, 62, 62, 23, 61, 36, 40, 61, 9, 62, 61, 42, 62, 62, 61, 13, 23, 61, 4, 16, 62, 61, 9, 42, 3, 25, 4, 14, 30, 31, 40, 61, 9, 62, 62, 62]\n",
            "iter 4000\n",
            "loss 0.15377154640853405\n",
            "trg [1, 17, 27, 61, 55, 38, 24, 62, 23, 61, 23, 61, 29, 41, 61, 13, 8, 62, 61, 55, 62, 62, 61, 29, 41, 61, 12, 10, 62, 61, 14, 62, 62, 62, 61, 23, 61, 29, 41, 61, 12, 13, 62, 61, 55, 62, 62, 61, 29, 41, 61, 10, 15, 62, 61, 11, 62, 62, 62, 2]\n",
            "pred [1, 17, 27, 61, 55, 38, 24, 62, 23, 61, 23, 61, 29, 41, 61, 13, 8, 62, 61, 55, 62, 62, 61, 29, 41, 61, 12, 8, 62, 61, 14, 62, 62, 62, 61, 23, 61, 29, 41, 61, 12, 10, 62, 61, 55, 62, 62, 61, 29, 41, 61, 10, 15, 62, 61, 11, 62, 62, 62]\n",
            "iter 5000\n",
            "loss 0.1398535452783108\n",
            "trg [1, 27, 61, 51, 38, 24, 62, 23, 61, 13, 62, 61, 46, 40, 61, 11, 10, 51, 62, 62, 2]\n",
            "pred [1, 27, 61, 51, 38, 24, 62, 23, 61, 13, 62, 61, 46, 40, 61, 11, 10, 51, 62, 62]\n",
            "iter 6000\n",
            "loss 0.15412836909294128\n",
            "trg [1, 27, 61, 42, 38, 12, 40, 61, 3, 62, 62, 26, 28, 61, 42, 62, 32, 40, 61, 42, 62, 2]\n",
            "pred [1, 27, 61, 42, 38, 12, 40, 61, 3, 62, 62, 26, 28, 61, 42, 62, 32, 40, 61, 42, 62]\n",
            "iter 7000\n",
            "loss 0.1594722905009985\n",
            "trg [1, 23, 61, 27, 61, 50, 38, 15, 62, 8, 9, 25, 4, 10, 36, 40, 61, 9, 62, 61, 25, 9, 50, 31, 62, 3, 20, 40, 61, 10, 62, 61, 25, 10, 50, 31, 62, 31, 62, 61, 9, 62, 2]\n",
            "pred [1, 23, 61, 27, 61, 50, 38, 15, 62, 8, 9, 25, 4, 10, 36, 40, 61, 9, 62, 61, 25, 9, 50, 31, 62, 3, 20, 40, 61, 10, 62, 61, 25, 10, 50, 31, 62, 31, 62, 61, 9, 62, 50]\n",
            "iter 8000\n",
            "loss 0.1484777980297804\n",
            "trg [1, 27, 61, 58, 38, 30, 6, 13, 40, 61, 4, 62, 62, 12, 6, 10, 34, 40, 61, 13, 62, 61, 58, 62, 25, 9, 58, 3, 25, 4, 13, 30, 31, 40, 61, 16, 62, 31, 2]\n",
            "pred [1, 27, 61, 58, 38, 30, 6, 13, 40, 61, 4, 62, 62, 12, 6, 10, 34, 40, 61, 13, 62, 61, 58, 62, 25, 9, 58, 3, 25, 4, 13, 30, 31, 40, 61, 16, 62, 31]\n",
            "iter 9000\n",
            "loss 0.14718029893934725\n",
            "trg [1, 27, 61, 56, 38, 30, 6, 12, 62, 23, 61, 9, 33, 40, 61, 12, 62, 61, 56, 62, 3, 16, 22, 40, 61, 9, 62, 61, 56, 62, 62, 61, 14, 62, 2]\n",
            "pred [1, 27, 61, 56, 38, 30, 6, 12, 62, 23, 61, 9, 33, 40, 61, 12, 62, 61, 56, 62, 3, 16, 22, 40, 61, 9, 62, 61, 56, 62, 62, 61, 14, 62]\n",
            "iter 10000\n",
            "loss 0.15160386092960834\n",
            "trg [1, 27, 61, 48, 38, 24, 62, 23, 61, 20, 61, 48, 62, 62, 61, 46, 40, 61, 48, 62, 62, 2]\n",
            "pred [1, 27, 61, 48, 38, 24, 62, 23, 61, 20, 61, 48, 62, 62, 61, 46, 40, 61, 48, 62, 62]\n",
            "iter 11000\n",
            "loss 0.15593309283256532\n",
            "trg [1, 27, 61, 57, 38, 13, 62, 23, 61, 10, 62, 61, 57, 40, 61, 11, 62, 3, 13, 57, 62, 3, 14, 23, 61, 13, 62, 61, 57, 4, 16, 62, 2]\n",
            "pred [1, 27, 61, 57, 38, 13, 62, 23, 61, 10, 62, 61, 57, 40, 61, 11, 62, 3, 13, 57, 3, 14, 23, 23, 61, 13, 62, 61, 57, 4, 16, 62]\n",
            "iter 12000\n",
            "loss 0.16309697799384593\n",
            "trg [1, 28, 61, 48, 62, 17, 23, 61, 27, 61, 49, 38, 30, 6, 9, 40, 61, 4, 62, 62, 4, 11, 36, 40, 61, 16, 62, 61, 49, 62, 62, 61, 27, 61, 49, 38, 30, 6, 10, 40, 61, 4, 62, 62, 10, 22, 40, 61, 16, 62, 61, 49, 62, 20, 61, 49, 62, 62, 2]\n",
            "pred [1, 28, 61, 48, 62, 17, 23, 61, 27, 61, 49, 38, 30, 6, 9, 40, 61, 4, 62, 62, 4, 11, 36, 40, 61, 16, 62, 61, 49, 62, 62, 61, 27, 61, 49, 38, 30, 6, 10, 40, 61, 4, 62, 62, 10, 22, 40, 61, 16, 62, 61, 49, 62, 20, 61, 49, 62, 62]\n",
            "iter 13000\n",
            "loss 0.14002364180982113\n",
            "trg [1, 27, 61, 50, 38, 8, 62, 23, 61, 34, 61, 8, 62, 50, 62, 61, 34, 61, 11, 62, 50, 62, 2]\n",
            "pred [1, 27, 61, 50, 38, 8, 62, 23, 61, 34, 61, 8, 62, 50, 62, 61, 34, 61, 11, 62, 50, 62]\n",
            "iter 14000\n",
            "loss 0.16762478455901145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|  | 4/5 [54:43<13:39, 819.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\tTrain Loss:   0.115 | Train PPL:   1.122\n",
            "\tValid Loss:   0.115 | Valid PPL:   1.122\n",
            "\\Test Loss:   0.150 | Valid PPL:   1.161\n",
            "trg [1, 27, 61, 52, 38, 8, 62, 23, 61, 15, 34, 61, 25, 15, 52, 31, 62, 62, 61, 11, 12, 52, 62, 2]\n",
            "pred [1, 27, 61, 52, 38, 8, 62, 23, 61, 15, 34, 61, 25, 15, 52, 31, 62, 62, 61, 11, 12, 52, 62]\n",
            "iter 1000\n",
            "loss 0.11029723405838013\n",
            "trg [1, 17, 27, 61, 58, 38, 8, 62, 23, 61, 20, 61, 58, 62, 4, 16, 62, 61, 25, 15, 3, 4, 13, 36, 61, 58, 62, 31, 25, 10, 3, 34, 61, 58, 62, 31, 62, 2]\n",
            "pred [1, 17, 27, 61, 58, 38, 8, 62, 23, 61, 20, 61, 58, 62, 4, 16, 62, 61, 25, 15, 3, 4, 13, 36, 61, 58, 62, 31, 25, 10, 3, 34, 61, 58, 62, 31, 62]\n",
            "iter 2000\n",
            "loss 0.1142772065848112\n",
            "trg [1, 27, 61, 43, 38, 15, 40, 61, 3, 62, 62, 46, 40, 61, 20, 61, 43, 62, 28, 61, 25, 9, 3, 43, 31, 62, 62, 2]\n",
            "pred [1, 27, 61, 43, 38, 15, 40, 61, 3, 62, 62, 46, 40, 61, 20, 61, 43, 62, 28, 61, 25, 9, 3, 43, 31, 62, 62]\n",
            "iter 3000\n",
            "loss 0.11335420198738574\n",
            "trg [1, 27, 61, 55, 38, 8, 40, 61, 3, 62, 62, 23, 61, 25, 55, 4, 15, 31, 25, 55, 4, 9, 31, 62, 61, 55, 4, 13, 62, 2]\n",
            "pred [1, 27, 61, 55, 38, 8, 40, 61, 3, 62, 62, 23, 61, 25, 55, 4, 15, 31, 25, 55, 4, 9, 31, 62, 61, 55, 4, 13, 62]\n",
            "iter 4000\n",
            "loss 0.09919538013637066\n",
            "trg [1, 27, 61, 54, 38, 23, 61, 30, 62, 61, 9, 62, 40, 61, 4, 62, 62, 23, 61, 36, 40, 61, 15, 62, 61, 54, 62, 62, 61, 9, 23, 61, 4, 9, 62, 61, 15, 54, 3, 25, 4, 13, 30, 31, 40, 61, 11, 62, 62, 62, 2]\n",
            "pred [1, 27, 61, 54, 38, 23, 61, 30, 62, 61, 9, 62, 40, 61, 4, 62, 62, 23, 61, 36, 40, 61, 15, 62, 61, 54, 62, 62, 61, 9, 23, 61, 4, 9, 62, 61, 15, 54, 3, 25, 4, 13, 30, 31, 40, 61, 11, 62, 62, 62]\n",
            "iter 5000\n",
            "loss 0.0874893056601286\n",
            "trg [1, 23, 61, 27, 61, 54, 38, 10, 62, 15, 16, 25, 34, 61, 25, 15, 54, 31, 62, 23, 61, 45, 62, 61, 45, 54, 62, 33, 61, 25, 7, 31, 62, 3, 34, 61, 25, 10, 54, 31, 62, 23, 61, 45, 62, 61, 45, 54, 62, 33, 61, 25, 12, 54, 31, 62, 31, 62, 61, 27, 61, 54, 38, 8, 62, 11, 62, 2]\n",
            "pred [1, 23, 61, 27, 61, 54, 38, 10, 62, 15, 16, 25, 34, 61, 25, 15, 54, 31, 62, 23, 61, 45, 62, 61, 45, 54, 62, 33, 61, 25, 7, 31, 62, 3, 34, 61, 25, 10, 54, 31, 62, 23, 61, 45, 62, 61, 45, 54, 62, 33, 61, 25, 12, 54, 31, 62, 31, 62, 61, 27, 61, 54, 38, 8, 62, 11, 62, 2]\n",
            "iter 6000\n",
            "loss 0.08311905510723591\n",
            "trg [1, 23, 61, 27, 61, 58, 38, 24, 62, 14, 7, 10, 62, 61, 27, 61, 58, 38, 24, 62, 8, 7, 13, 58, 62, 2]\n",
            "pred [1, 23, 61, 27, 61, 58, 38, 24, 62, 14, 7, 10, 62, 61, 27, 61, 58, 38, 24, 62, 8, 7, 13, 58, 62]\n",
            "iter 7000\n",
            "loss 0.10035817712545395\n",
            "trg [1, 27, 61, 51, 38, 24, 62, 23, 61, 23, 61, 29, 41, 61, 15, 10, 62, 61, 51, 62, 62, 61, 29, 41, 61, 15, 14, 62, 61, 10, 62, 62, 62, 61, 23, 61, 29, 41, 61, 10, 8, 62, 61, 51, 62, 62, 61, 29, 41, 61, 9, 10, 62, 61, 12, 62, 62, 62, 2]\n",
            "pred [1, 27, 61, 51, 38, 24, 62, 23, 61, 23, 61, 29, 41, 61, 15, 10, 62, 61, 51, 62, 62, 61, 29, 41, 61, 15, 14, 62, 61, 10, 62, 62, 62, 61, 23, 61, 29, 41, 61, 10, 8, 62, 61, 51, 62, 62, 61, 29, 41, 61, 9, 10, 62, 61, 12, 62, 62, 62]\n",
            "iter 8000\n",
            "loss 0.08999004036188125\n",
            "trg [1, 27, 61, 58, 38, 4, 9, 62, 23, 61, 58, 40, 61, 9, 62, 3, 8, 58, 40, 61, 13, 62, 3, 13, 58, 40, 61, 9, 62, 3, 10, 58, 3, 16, 62, 61, 58, 3, 10, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 4, 9, 62, 23, 61, 58, 40, 61, 9, 62, 3, 58, 40, 40, 61, 13, 62, 3, 58, 40, 40, 61, 9, 62, 3, 10, 58, 3, 10, 62, 61, 58, 3, 10, 62]\n",
            "iter 9000\n",
            "loss 0.10385899230837822\n",
            "trg [1, 27, 61, 54, 38, 7, 62, 23, 61, 10, 3, 4, 11, 20, 61, 25, 13, 54, 31, 62, 62, 61, 13, 54, 62, 2]\n",
            "pred [1, 27, 61, 54, 38, 7, 62, 23, 61, 10, 3, 4, 11, 20, 61, 25, 13, 54, 31, 62, 62, 61, 13, 54, 62]\n",
            "iter 10000\n",
            "loss 0.09178602494299412\n",
            "trg [1, 27, 61, 53, 38, 30, 6, 12, 62, 23, 61, 33, 40, 61, 15, 62, 61, 53, 62, 3, 22, 40, 61, 9, 62, 61, 53, 62, 62, 61, 10, 62, 2]\n",
            "pred [1, 27, 61, 53, 38, 30, 6, 12, 62, 23, 61, 33, 40, 61, 15, 62, 61, 53, 62, 3, 22, 40, 61, 9, 62, 61, 53, 62, 62, 61, 10, 62]\n",
            "iter 11000\n",
            "loss 0.10298075579106808\n",
            "trg [1, 27, 61, 44, 38, 15, 62, 23, 61, 10, 3, 4, 9, 34, 61, 25, 14, 44, 31, 62, 62, 61, 36, 61, 44, 62, 62, 2]\n",
            "pred [1, 27, 61, 44, 38, 15, 62, 23, 61, 10, 3, 4, 9, 34, 61, 25, 14, 44, 31, 62, 62, 61, 36, 61, 44, 62, 62]\n",
            "iter 12000\n",
            "loss 0.10210935942828656\n",
            "trg [1, 27, 61, 50, 38, 24, 62, 23, 61, 9, 62, 61, 35, 61, 50, 40, 61, 16, 62, 3, 10, 49, 50, 62, 3, 9, 35, 61, 50, 40, 61, 9, 62, 3, 16, 50, 62, 62, 23, 61, 35, 61, 50, 40, 61, 11, 62, 3, 16, 49, 50, 62, 3, 35, 61, 50, 40, 61, 15, 62, 3, 9, 50, 62, 62, 61, 35, 61, 50, 40, 61, 11, 62, 3, 10, 49, 50, 62, 3, 35, 61, 50, 40, 61, 10, 62, 3, 11, 50, 62, 62, 2]\n",
            "pred [1, 27, 61, 50, 38, 24, 62, 23, 61, 9, 62, 61, 35, 61, 50, 40, 61, 16, 62, 3, 10, 60, 50, 62, 3, 9, 35, 61, 50, 40, 61, 9, 62, 3, 16, 50, 62, 23, 61, 35, 35, 61, 50, 40, 61, 11, 62, 3, 16, 50, 62, 62, 61, 35, 61, 50, 40, 61, 11, 62, 3, 16, 50, 62, 62, 61, 35, 61, 50, 40, 61, 11, 62, 3, 10, 50, 50, 62, 3, 35, 61, 50, 40, 61, 11, 62, 3, 11, 50, 62, 62, 2]\n",
            "iter 13000\n",
            "loss 0.0982957672327757\n",
            "trg [1, 27, 61, 42, 38, 12, 62, 23, 61, 22, 61, 25, 10, 42, 31, 62, 9, 6, 9, 10, 6, 42, 62, 61, 34, 61, 25, 9, 42, 31, 62, 10, 6, 9, 16, 6, 42, 62, 2]\n",
            "pred [1, 27, 61, 42, 38, 12, 62, 23, 61, 22, 61, 25, 10, 42, 31, 62, 9, 6, 9, 10, 6, 42, 62, 61, 34, 61, 25, 9, 42, 31, 62, 10, 6, 9, 16, 6, 42, 62]\n",
            "iter 14000\n",
            "loss 0.11042444042861461\n",
            "trg [1, 27, 61, 60, 38, 8, 62, 23, 61, 36, 61, 25, 9, 60, 31, 62, 62, 61, 14, 60, 62, 2]\n",
            "pred [1, 27, 61, 60, 38, 8, 62, 23, 61, 36, 61, 25, 9, 60, 31, 62, 62, 61, 14, 60, 62]\n",
            "iter 15000\n",
            "loss 0.11190210327506066\n",
            "trg [1, 27, 61, 48, 38, 10, 40, 61, 4, 62, 62, 23, 61, 11, 62, 61, 48, 40, 61, 12, 62, 3, 48, 62, 2]\n",
            "pred [1, 27, 61, 48, 38, 10, 40, 61, 4, 62, 62, 23, 61, 11, 62, 61, 48, 40, 61, 12, 62, 3, 48, 62]\n",
            "iter 16000\n",
            "loss 0.09408938482403756\n",
            "trg [1, 27, 61, 53, 38, 30, 6, 16, 62, 36, 40, 61, 9, 62, 61, 53, 62, 3, 20, 40, 61, 16, 62, 61, 53, 62, 2]\n",
            "pred [1, 27, 61, 53, 38, 30, 6, 16, 62, 36, 40, 61, 9, 62, 61, 53, 62, 3, 20, 40, 61, 16, 62, 61, 53, 62]\n",
            "iter 17000\n",
            "loss 0.09735553279519081\n",
            "trg [1, 27, 61, 58, 38, 10, 62, 23, 61, 14, 62, 61, 58, 40, 61, 12, 62, 25, 58, 3, 15, 31, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 10, 62, 23, 61, 14, 62, 61, 58, 40, 61, 12, 62, 25, 58, 3, 15, 31, 62]\n",
            "iter 18000\n",
            "loss 0.09796352975070477\n",
            "trg [1, 27, 61, 58, 38, 13, 62, 23, 61, 14, 3, 34, 61, 58, 62, 62, 61, 20, 40, 61, 16, 62, 61, 58, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 13, 62, 23, 61, 14, 3, 34, 61, 58, 62, 62, 61, 20, 40, 61, 16, 62, 61, 58, 62, 62]\n",
            "iter 19000\n",
            "loss 0.09739006012678146\n",
            "trg [1, 23, 61, 27, 61, 57, 38, 13, 62, 14, 9, 34, 61, 25, 13, 57, 31, 62, 20, 61, 25, 10, 57, 31, 62, 62, 61, 27, 61, 57, 38, 11, 62, 57, 62, 2]\n",
            "pred [1, 23, 61, 27, 61, 57, 38, 13, 62, 14, 9, 34, 61, 25, 13, 57, 31, 62, 20, 61, 25, 10, 57, 31, 62, 62, 61, 27, 61, 57, 38, 11, 62, 11, 57]\n",
            "iter 20000\n",
            "loss 0.09873109437525272\n",
            "trg [1, 27, 61, 57, 38, 15, 40, 61, 3, 62, 62, 4, 13, 16, 22, 61, 57, 62, 2]\n",
            "pred [1, 27, 61, 57, 38, 15, 40, 61, 3, 62, 62, 4, 13, 16, 22, 61, 57, 62]\n",
            "iter 21000\n",
            "loss 0.09053478881716728\n",
            "trg [1, 27, 61, 49, 38, 23, 61, 30, 62, 61, 11, 62, 62, 36, 40, 61, 15, 62, 61, 49, 62, 3, 20, 40, 61, 14, 62, 61, 49, 62, 2]\n",
            "pred [1, 27, 61, 49, 38, 23, 61, 30, 62, 61, 11, 62, 62, 36, 40, 61, 15, 62, 61, 49, 62, 3, 20, 40, 61, 14, 62, 61, 49, 62]\n",
            "iter 22000\n",
            "loss 0.10104599237442016\n",
            "trg [1, 27, 61, 52, 38, 24, 62, 23, 61, 8, 52, 40, 61, 8, 62, 62, 61, 9, 52, 40, 61, 9, 62, 3, 9, 26, 52, 40, 61, 8, 62, 32, 62, 2]\n",
            "pred [1, 27, 61, 52, 38, 24, 62, 23, 61, 8, 52, 40, 61, 8, 62, 62, 61, 9, 52, 40, 61, 9, 62, 3, 9, 26, 52, 40, 61, 8, 62, 32, 62]\n",
            "iter 23000\n",
            "loss 0.08839873097836971\n",
            "trg [1, 27, 61, 48, 38, 15, 62, 23, 61, 36, 61, 48, 62, 3, 9, 62, 61, 48, 62, 2]\n",
            "pred [1, 27, 61, 48, 38, 15, 62, 23, 61, 36, 61, 48, 62, 3, 9, 62, 61, 48, 62]\n",
            "iter 24000\n",
            "loss 0.0966758045554161\n",
            "trg [1, 27, 61, 48, 38, 4, 24, 62, 23, 61, 8, 7, 48, 40, 61, 13, 62, 62, 61, 7, 48, 40, 61, 14, 62, 62, 2]\n",
            "pred [1, 27, 61, 48, 38, 4, 24, 62, 23, 61, 8, 7, 48, 40, 61, 13, 62, 62, 61, 7, 48, 40, 61, 14, 62, 62]\n",
            "iter 25000\n",
            "loss 0.0972116319835186\n",
            "trg [1, 27, 61, 50, 38, 16, 62, 4, 9, 23, 61, 25, 50, 4, 10, 31, 25, 10, 3, 50, 31, 62, 61, 25, 50, 4, 12, 31, 25, 50, 4, 14, 31, 62, 2]\n",
            "pred [1, 27, 61, 50, 38, 16, 62, 4, 9, 23, 61, 25, 50, 4, 10, 31, 25, 10, 3, 50, 31, 62, 61, 25, 50, 4, 12, 31, 25, 50, 4, 14, 31, 62]\n",
            "iter 26000\n",
            "loss 0.10776682458817959\n",
            "trg [1, 4, 10, 27, 61, 42, 38, 4, 24, 62, 28, 61, 26, 42, 40, 61, 9, 62, 3, 9, 32, 62, 2]\n",
            "pred [1, 4, 9, 27, 61, 42, 38, 4, 24, 62, 28, 61, 26, 42, 40, 61, 9, 62, 3, 9, 32, 62]\n",
            "iter 27000\n",
            "loss 0.09391258358955383\n",
            "trg [1, 27, 61, 58, 38, 13, 62, 23, 61, 4, 11, 62, 61, 9, 35, 61, 58, 3, 9, 62, 25, 11, 3, 35, 61, 58, 3, 12, 62, 31, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 13, 62, 23, 61, 4, 11, 62, 61, 9, 35, 61, 58, 3, 9, 62, 25, 11, 3, 35, 61, 58, 3, 12, 62, 31, 62]\n",
            "iter 28000\n",
            "loss 0.09339776694774628\n",
            "trg [1, 27, 61, 59, 38, 12, 40, 61, 3, 62, 62, 23, 61, 4, 13, 21, 61, 59, 62, 36, 40, 61, 8, 62, 61, 59, 62, 62, 61, 25, 10, 3, 10, 59, 34, 61, 59, 62, 31, 20, 40, 61, 8, 62, 61, 59, 62, 62, 2]\n",
            "pred [1, 27, 61, 59, 38, 12, 40, 61, 3, 62, 62, 23, 61, 4, 13, 21, 61, 59, 62, 36, 40, 61, 8, 62, 61, 59, 62, 62, 61, 25, 10, 3, 10, 59, 34, 61, 59, 62, 31, 20, 40, 61, 8, 62, 61, 59, 62, 62]\n",
            "iter 29000\n",
            "loss 0.0982352252304554\n",
            "trg [1, 27, 61, 59, 38, 4, 12, 62, 23, 61, 59, 3, 8, 3, 59, 3, 9, 40, 61, 16, 62, 62, 61, 59, 3, 9, 62, 2]\n",
            "pred [1, 27, 61, 59, 38, 4, 12, 62, 23, 61, 59, 3, 8, 3, 59, 3, 9, 40, 61, 16, 62, 62, 61, 59, 3, 9, 62]\n",
            "iter 30000\n",
            "loss 0.09217213064432145\n",
            "trg [1, 27, 61, 56, 38, 30, 62, 23, 61, 20, 61, 56, 62, 3, 12, 62, 61, 56, 3, 25, 4, 8, 30, 31, 40, 61, 13, 62, 62, 2]\n",
            "pred [1, 27, 61, 56, 38, 30, 62, 23, 61, 20, 61, 56, 62, 3, 12, 62, 61, 56, 3, 25, 4, 8, 30, 31, 40, 61, 13, 62, 62]\n",
            "iter 31000\n",
            "loss 0.09188031919300556\n",
            "trg [1, 27, 61, 57, 38, 15, 62, 8, 3, 36, 61, 57, 62, 2]\n",
            "pred [1, 27, 61, 57, 38, 15, 62, 8, 3, 36, 61, 57, 62]\n",
            "iter 32000\n",
            "loss 0.09276786103844642\n",
            "trg [1, 27, 61, 59, 38, 14, 40, 61, 3, 62, 62, 20, 61, 59, 62, 3, 4, 16, 9, 6, 59, 2]\n",
            "pred [1, 27, 61, 59, 38, 14, 40, 61, 3, 62, 62, 20, 61, 59, 62, 3, 4, 16, 9, 6, 59]\n",
            "iter 33000\n",
            "loss 0.08944822326302529\n",
            "trg [1, 27, 61, 58, 38, 24, 62, 23, 61, 29, 41, 61, 10, 10, 62, 61, 58, 62, 29, 41, 61, 10, 14, 62, 61, 9, 62, 62, 61, 29, 41, 61, 8, 7, 62, 61, 14, 62, 29, 41, 61, 15, 13, 62, 61, 58, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 23, 61, 29, 41, 61, 10, 10, 62, 61, 58, 62, 29, 41, 61, 10, 14, 62, 61, 9, 62, 62, 61, 29, 41, 61, 8, 7, 62, 61, 14, 62, 29, 41, 61, 15, 13, 62, 61, 58, 62, 62]\n",
            "iter 34000\n",
            "loss 0.0906743834912777\n",
            "trg [1, 27, 61, 56, 38, 14, 40, 61, 3, 62, 62, 23, 61, 4, 34, 61, 56, 62, 34, 40, 61, 7, 62, 61, 56, 62, 62, 61, 34, 40, 61, 10, 62, 61, 56, 62, 3, 25, 10, 56, 33, 61, 56, 62, 3, 14, 31, 36, 40, 61, 16, 62, 61, 56, 62, 62, 2]\n",
            "pred [1, 27, 61, 56, 38, 14, 40, 61, 3, 62, 62, 23, 61, 4, 34, 61, 56, 62, 34, 40, 61, 7, 62, 61, 56, 62, 62, 61, 34, 40, 61, 10, 62, 61, 56, 62, 3, 25, 10, 56, 33, 61, 56, 62, 3, 14, 31, 36, 40, 61, 16, 62, 61, 56, 62, 62]\n",
            "iter 35000\n",
            "loss 0.08152826622128487\n",
            "trg [1, 27, 61, 55, 38, 11, 62, 23, 61, 23, 61, 45, 62, 61, 45, 55, 62, 46, 40, 61, 55, 62, 3, 4, 10, 23, 61, 45, 62, 61, 45, 55, 62, 22, 61, 55, 62, 62, 61, 23, 61, 45, 62, 61, 45, 55, 62, 16, 55, 40, 61, 11, 62, 3, 23, 61, 45, 62, 61, 45, 55, 62, 9, 9, 55, 40, 61, 9, 62, 3, 23, 61, 45, 62, 61, 45, 55, 62, 9, 16, 55, 62, 2]\n",
            "pred [1, 27, 61, 55, 38, 11, 62, 23, 61, 23, 61, 45, 62, 61, 45, 55, 62, 46, 40, 61, 55, 62, 3, 4, 10, 23, 61, 45, 62, 61, 45, 55, 62, 22, 61, 55, 62, 62, 61, 23, 61, 45, 62, 61, 45, 55, 62, 16, 55, 40, 61, 11, 62, 3, 23, 61, 9, 62, 61, 45, 55, 62, 9, 9, 55, 40, 61, 9, 62, 3, 23, 61, 45, 62, 61, 45, 55, 62, 9, 55, 55, 40, 61]\n",
            "iter 36000\n",
            "loss 0.0825416524708271\n",
            "trg [1, 27, 61, 50, 38, 10, 40, 61, 4, 62, 62, 23, 61, 25, 50, 4, 14, 31, 25, 50, 3, 7, 31, 62, 61, 25, 50, 4, 8, 31, 25, 50, 3, 9, 31, 62, 2]\n",
            "pred [1, 27, 61, 50, 38, 10, 40, 61, 4, 62, 62, 23, 61, 25, 50, 4, 14, 31, 25, 50, 3, 7, 31, 62, 61, 25, 50, 4, 8, 31, 25, 50, 3, 9, 31, 62]\n",
            "iter 37000\n",
            "loss 0.08807247757911682\n",
            "trg [1, 27, 61, 54, 38, 10, 62, 23, 61, 34, 61, 15, 62, 54, 62, 61, 34, 61, 9, 62, 54, 62, 2]\n",
            "pred [1, 27, 61, 54, 38, 10, 62, 23, 61, 34, 61, 15, 62, 54, 62, 61, 34, 61, 9, 62, 54, 62]\n",
            "iter 38000\n",
            "loss 0.09543020166456699\n",
            "trg [1, 27, 61, 54, 38, 10, 62, 23, 61, 34, 61, 25, 7, 31, 62, 62, 61, 54, 20, 61, 25, 10, 54, 31, 62, 62, 2]\n",
            "pred [1, 27, 61, 54, 38, 10, 62, 23, 61, 34, 61, 25, 7, 31, 62, 62, 61, 54, 20, 61, 25, 10, 54, 31, 62, 62]\n",
            "iter 39000\n",
            "loss 0.0938271626830101\n",
            "trg [1, 46, 40, 61, 27, 61, 59, 38, 7, 40, 61, 3, 62, 62, 11, 59, 28, 61, 59, 62, 62, 2]\n",
            "pred [1, 46, 40, 61, 27, 61, 59, 38, 7, 40, 61, 3, 62, 62, 11, 59, 28, 61, 59, 62, 62]\n",
            "iter 40000\n",
            "loss 0.09573343090713024\n",
            "trg [1, 28, 61, 48, 62, 17, 23, 61, 27, 61, 54, 38, 30, 6, 14, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 54, 62, 34, 61, 54, 62, 62, 61, 27, 61, 54, 38, 30, 6, 16, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 54, 62, 4, 13, 34, 40, 61, 11, 62, 61, 54, 62, 62, 2]\n",
            "pred [1, 28, 61, 48, 62, 17, 23, 61, 27, 61, 54, 38, 30, 6, 14, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 54, 62, 34, 61, 54, 62, 62, 61, 27, 61, 54, 38, 30, 6, 16, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 54, 62, 4, 13, 34, 40, 61, 11, 62, 61, 54, 62, 62, 2]\n",
            "iter 41000\n",
            "loss 0.09547759465873241\n",
            "trg [1, 17, 27, 61, 60, 38, 7, 40, 61, 4, 62, 62, 23, 61, 60, 40, 61, 9, 62, 3, 4, 13, 60, 40, 61, 12, 62, 3, 10, 60, 62, 61, 60, 40, 61, 7, 62, 3, 4, 14, 60, 40, 61, 14, 62, 62, 2]\n",
            "pred [1, 17, 27, 61, 60, 38, 7, 40, 61, 4, 62, 62, 23, 61, 60, 60, 4, 9, 40, 61, 12, 62, 3, 40, 61, 12, 62, 3, 14, 60, 62, 61, 7, 40, 61, 7, 62, 3, 4, 14, 60, 40, 61, 14, 62, 62]\n",
            "iter 42000\n",
            "loss 0.10578641891479493\n",
            "trg [1, 27, 61, 42, 38, 11, 62, 23, 61, 13, 3, 4, 15, 42, 3, 28, 61, 42, 62, 62, 61, 7, 3, 20, 61, 30, 62, 42, 62, 2]\n",
            "pred [1, 27, 61, 42, 38, 11, 62, 23, 61, 13, 3, 4, 15, 42, 3, 28, 61, 42, 62, 62, 61, 7, 3, 20, 61, 30, 62, 42, 62]\n",
            "iter 43000\n",
            "loss 0.10467028819024563\n",
            "trg [1, 27, 61, 52, 38, 12, 62, 9, 23, 61, 34, 61, 25, 10, 52, 31, 62, 62, 61, 12, 52, 62, 23, 61, 15, 62, 61, 36, 61, 25, 14, 52, 31, 62, 62, 2]\n",
            "pred [1, 27, 61, 52, 38, 12, 62, 9, 23, 61, 34, 61, 25, 10, 52, 31, 62, 62, 61, 12, 52, 62, 23, 61, 15, 62, 61, 36, 61, 25, 14, 52, 31, 62, 62]\n",
            "iter 44000\n",
            "loss 0.09654146924614906\n",
            "trg [1, 27, 61, 57, 38, 24, 62, 23, 61, 14, 57, 40, 61, 8, 62, 62, 61, 8, 57, 40, 61, 13, 62, 62, 2]\n",
            "pred [1, 27, 61, 57, 38, 24, 62, 23, 61, 14, 57, 40, 61, 8, 62, 62, 61, 8, 57, 40, 61, 13, 62, 62]\n",
            "iter 45000\n",
            "loss 0.12192379407584668\n",
            "trg [1, 27, 61, 58, 38, 24, 62, 23, 61, 12, 58, 40, 61, 14, 62, 3, 4, 9, 58, 3, 8, 62, 61, 9, 58, 40, 61, 8, 62, 3, 58, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 23, 61, 12, 58, 40, 61, 14, 62, 3, 4, 9, 58, 3, 8, 62, 61, 9, 58, 40, 61, 8, 62, 3, 58, 62]\n",
            "iter 46000\n",
            "loss 0.11683291770517826\n",
            "trg [1, 27, 61, 48, 38, 30, 6, 10, 62, 23, 61, 25, 35, 61, 36, 61, 48, 62, 62, 4, 13, 31, 25, 35, 61, 21, 61, 48, 62, 62, 3, 11, 31, 62, 61, 35, 61, 34, 61, 48, 62, 62, 4, 13, 62, 2]\n",
            "pred [1, 27, 61, 48, 38, 30, 6, 10, 62, 23, 61, 25, 35, 61, 36, 61, 48, 62, 62, 4, 13, 31, 25, 35, 61, 21, 61, 48, 62, 62, 3, 11, 31, 62, 61, 35, 61, 34, 61, 48, 62, 62, 4, 13, 62]\n",
            "iter 47000\n",
            "loss 0.10088094659149646\n",
            "trg [1, 27, 61, 48, 38, 23, 61, 30, 62, 61, 13, 62, 62, 34, 40, 61, 10, 62, 61, 48, 62, 3, 27, 61, 48, 38, 23, 61, 30, 62, 61, 9, 62, 62, 33, 40, 61, 11, 62, 61, 48, 62, 2]\n",
            "pred [1, 27, 61, 48, 38, 23, 61, 30, 62, 61, 13, 62, 62, 34, 40, 61, 10, 62, 61, 48, 62, 3, 27, 61, 48, 38, 30, 61, 30, 62, 61, 9, 62, 62, 48, 40, 61, 11, 62, 61, 48, 62]\n",
            "iter 48000\n",
            "loss 0.10056023932993412\n",
            "trg [1, 27, 61, 44, 38, 11, 62, 23, 61, 44, 4, 8, 62, 61, 44, 25, 44, 4, 16, 31, 25, 44, 40, 61, 11, 62, 3, 9, 44, 31, 62, 2]\n",
            "pred [1, 27, 61, 44, 38, 11, 62, 23, 61, 44, 4, 8, 62, 61, 44, 25, 44, 4, 16, 31, 25, 44, 40, 61, 11, 62, 3, 9, 44, 31, 62]\n",
            "iter 49000\n",
            "loss 0.10775577679276466\n",
            "trg [1, 27, 61, 44, 38, 30, 6, 11, 62, 23, 61, 13, 36, 40, 61, 15, 62, 61, 44, 62, 3, 9, 34, 40, 61, 16, 62, 61, 44, 62, 62, 61, 10, 62, 2]\n",
            "pred [1, 27, 61, 44, 38, 30, 6, 11, 62, 23, 61, 13, 36, 40, 61, 15, 62, 61, 44, 62, 3, 9, 34, 40, 61, 16, 62, 61, 44, 62, 62, 61, 10, 62]\n",
            "iter 50000\n",
            "loss 0.10337313383817673\n",
            "trg [1, 27, 61, 52, 38, 24, 62, 23, 61, 29, 41, 61, 13, 8, 62, 61, 52, 62, 62, 61, 29, 41, 61, 11, 8, 62, 61, 14, 62, 62, 23, 61, 29, 41, 61, 9, 13, 62, 61, 11, 62, 62, 61, 29, 41, 61, 9, 62, 61, 52, 62, 62, 2]\n",
            "pred [1, 27, 61, 52, 38, 24, 62, 23, 61, 29, 41, 61, 13, 8, 62, 61, 52, 62, 62, 61, 29, 41, 61, 11, 8, 62, 61, 14, 62, 62, 23, 61, 29, 41, 61, 9, 13, 62, 61, 11, 62, 62, 61, 29, 41, 61, 9, 62, 61, 52, 62, 62]\n",
            "iter 51000\n",
            "loss 0.10527489222586155\n",
            "trg [1, 13, 6, 13, 27, 61, 59, 38, 12, 62, 23, 61, 23, 61, 34, 61, 25, 9, 59, 31, 62, 62, 61, 9, 59, 62, 36, 61, 25, 10, 59, 31, 62, 62, 61, 23, 61, 34, 61, 25, 13, 59, 31, 62, 62, 61, 12, 59, 62, 62, 2]\n",
            "pred [1, 16, 6, 13, 27, 61, 59, 38, 12, 62, 23, 61, 23, 61, 34, 61, 25, 9, 59, 31, 62, 62, 61, 9, 59, 62, 36, 61, 25, 10, 59, 31, 62, 62, 61, 23, 61, 34, 61, 25, 13, 59, 31, 62, 62, 61, 12, 59, 62, 62]\n",
            "iter 52000\n",
            "loss 0.08229491032660008\n",
            "trg [1, 27, 61, 53, 38, 9, 40, 61, 3, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 53, 62, 25, 9, 3, 4, 10, 33, 40, 61, 7, 62, 61, 53, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 53, 62, 25, 36, 61, 53, 62, 3, 53, 36, 40, 61, 10, 62, 61, 53, 62, 31, 62, 2]\n",
            "pred [1, 27, 61, 53, 38, 9, 40, 61, 3, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 53, 62, 25, 9, 3, 4, 10, 33, 40, 61, 7, 62, 61, 53, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 53, 62, 25, 36, 61, 53, 62, 3, 53, 36, 40, 61, 10, 62, 61, 53, 62, 31, 62]\n",
            "iter 53000\n",
            "loss 0.07966090083122253\n",
            "trg [1, 27, 61, 58, 38, 13, 40, 61, 3, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 58, 62, 25, 8, 3, 4, 10, 36, 40, 61, 8, 62, 61, 58, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 58, 62, 25, 20, 61, 58, 62, 3, 58, 34, 40, 61, 16, 62, 61, 58, 62, 31, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 13, 40, 61, 3, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 58, 62, 25, 8, 3, 4, 10, 36, 40, 61, 8, 62, 61, 58, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 58, 62, 25, 20, 61, 58, 62, 3, 58, 34, 40, 61, 16, 62, 61, 58, 62, 31, 62, 2]\n",
            "iter 54000\n",
            "loss 0.10943369828164577\n",
            "trg [1, 27, 61, 55, 38, 16, 40, 61, 3, 62, 62, 46, 40, 61, 23, 61, 13, 62, 61, 55, 62, 62, 2]\n",
            "pred [1, 27, 61, 55, 38, 16, 40, 61, 3, 62, 62, 46, 40, 61, 23, 61, 13, 62, 61, 55, 62, 62]\n",
            "iter 55000\n",
            "loss 0.07969360202550888\n",
            "trg [1, 27, 61, 49, 38, 11, 62, 23, 61, 13, 62, 61, 28, 61, 49, 62, 3, 11, 62, 2]\n",
            "pred [1, 27, 61, 49, 38, 11, 62, 23, 61, 13, 62, 61, 28, 61, 49, 62, 3, 11, 62]\n",
            "iter 56000\n",
            "loss 0.08731738954782486\n",
            "trg [1, 27, 61, 58, 38, 13, 40, 61, 3, 62, 62, 23, 61, 9, 3, 4, 9, 36, 40, 61, 9, 62, 61, 58, 62, 62, 61, 36, 61, 58, 62, 3, 58, 34, 40, 61, 12, 62, 61, 58, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 13, 40, 61, 3, 62, 62, 23, 61, 9, 3, 4, 9, 36, 40, 61, 9, 62, 61, 58, 62, 62, 61, 36, 61, 58, 62, 3, 58, 34, 40, 61, 12, 62, 61, 58, 62, 62]\n",
            "iter 57000\n",
            "loss 0.11040028870105743\n",
            "trg [1, 27, 61, 54, 38, 30, 6, 9, 62, 23, 61, 9, 20, 40, 61, 13, 62, 61, 54, 62, 3, 4, 10, 22, 40, 61, 10, 62, 61, 54, 62, 62, 61, 9, 62, 2]\n",
            "pred [1, 27, 61, 54, 38, 30, 6, 9, 62, 23, 61, 9, 20, 40, 61, 13, 62, 61, 54, 62, 3, 4, 10, 22, 40, 61, 10, 62, 61, 54, 62, 62, 61, 9, 62]\n",
            "iter 58000\n",
            "loss 0.08889852032065391\n",
            "trg [1, 17, 27, 61, 58, 38, 24, 62, 23, 61, 29, 41, 61, 15, 11, 62, 61, 9, 62, 62, 61, 29, 41, 61, 16, 9, 62, 61, 10, 62, 62, 2]\n",
            "pred [1, 17, 27, 61, 58, 38, 24, 62, 23, 61, 29, 41, 61, 15, 11, 62, 61, 9, 62, 62, 61, 29, 41, 61, 16, 9, 62, 61, 10, 62, 62]\n",
            "iter 59000\n",
            "loss 0.08853842079639435\n",
            "trg [1, 28, 61, 58, 62, 17, 23, 61, 27, 61, 48, 38, 30, 6, 9, 40, 61, 4, 62, 62, 33, 61, 48, 62, 62, 61, 27, 61, 48, 38, 30, 6, 16, 40, 61, 4, 62, 62, 4, 13, 33, 40, 61, 16, 62, 61, 48, 62, 62, 2]\n",
            "pred [1, 28, 61, 58, 62, 17, 23, 61, 27, 61, 48, 38, 30, 6, 9, 40, 61, 4, 62, 62, 33, 61, 48, 62, 62, 61, 27, 61, 48, 38, 30, 6, 16, 40, 61, 4, 62, 62, 4, 13, 33, 40, 61, 16, 62, 61, 48, 62, 62]\n",
            "iter 60000\n",
            "loss 0.07522141225636006\n",
            "trg [1, 27, 61, 51, 38, 9, 62, 23, 61, 16, 62, 61, 35, 61, 58, 62, 3, 10, 62, 2]\n",
            "pred [1, 27, 61, 51, 38, 9, 62, 23, 61, 16, 62, 61, 35, 61, 58, 62, 3, 10, 62]\n",
            "iter 61000\n",
            "loss 0.09322244957089425\n",
            "trg [1, 27, 61, 55, 38, 16, 40, 61, 3, 62, 62, 23, 61, 34, 61, 55, 62, 62, 61, 10, 62, 27, 61, 55, 38, 9, 40, 61, 3, 62, 62, 35, 61, 55, 25, 9, 3, 11, 55, 31, 62, 2]\n",
            "pred [1, 27, 61, 55, 38, 16, 40, 61, 3, 62, 62, 23, 61, 34, 61, 55, 62, 62, 61, 10, 62, 27, 61, 55, 38, 9, 40, 61, 3, 62, 62, 35, 61, 55, 25, 9, 3, 11, 55, 31, 62]\n",
            "iter 62000\n",
            "loss 0.08532462619245053\n",
            "trg [1, 27, 61, 57, 38, 16, 40, 61, 3, 62, 62, 46, 40, 61, 22, 61, 57, 62, 28, 61, 25, 8, 3, 57, 31, 62, 62, 2]\n",
            "pred [1, 27, 61, 57, 38, 16, 40, 61, 3, 62, 62, 46, 40, 61, 22, 61, 57, 62, 28, 61, 25, 8, 3, 57, 31, 62, 62]\n",
            "iter 63000\n",
            "loss 0.0939457307755947\n",
            "trg [1, 23, 61, 27, 61, 52, 38, 11, 62, 11, 10, 25, 15, 36, 40, 61, 15, 62, 61, 25, 9, 52, 31, 62, 3, 33, 40, 61, 12, 62, 61, 25, 9, 52, 31, 62, 31, 62, 61, 15, 62, 2]\n",
            "pred [1, 23, 61, 27, 61, 52, 38, 11, 62, 11, 10, 25, 15, 36, 40, 61, 15, 62, 61, 25, 9, 52, 31, 62, 3, 33, 40, 61, 12, 62, 61, 25, 9, 52, 31, 62, 31, 62, 61, 15, 62]\n",
            "iter 64000\n",
            "loss 0.09216748103499413\n",
            "trg [1, 27, 61, 53, 38, 30, 6, 10, 62, 23, 61, 16, 3, 34, 61, 13, 62, 53, 62, 61, 9, 3, 4, 10, 36, 61, 9, 62, 53, 62, 2]\n",
            "pred [1, 27, 61, 53, 38, 30, 6, 10, 62, 23, 61, 16, 3, 34, 61, 13, 62, 53, 62, 61, 9, 3, 4, 10, 36, 61, 9, 62, 53, 62]\n",
            "iter 65000\n",
            "loss 0.09223070614039898\n",
            "trg [1, 17, 27, 61, 57, 38, 23, 61, 30, 62, 61, 9, 62, 62, 36, 40, 61, 15, 62, 61, 57, 62, 3, 33, 40, 61, 14, 62, 61, 57, 62, 2]\n",
            "pred [1, 17, 27, 61, 57, 38, 23, 61, 30, 62, 61, 9, 62, 62, 36, 40, 61, 15, 62, 61, 57, 62, 3, 33, 40, 61, 14, 62, 61, 57, 62]\n",
            "iter 66000\n",
            "loss 0.0828199927508831\n",
            "trg [1, 27, 61, 56, 38, 24, 62, 23, 61, 13, 19, 9, 56, 40, 61, 10, 62, 3, 4, 56, 62, 61, 8, 19, 15, 56, 40, 61, 8, 62, 62, 2]\n",
            "pred [1, 27, 61, 56, 38, 24, 62, 23, 61, 13, 19, 9, 56, 40, 61, 10, 62, 3, 4, 56, 62, 61, 8, 19, 15, 56, 40, 61, 15, 62, 62]\n",
            "iter 67000\n",
            "loss 0.0809244056046009\n",
            "trg [1, 27, 61, 58, 38, 9, 62, 23, 61, 7, 36, 61, 25, 14, 58, 31, 62, 62, 61, 15, 58, 36, 61, 25, 9, 58, 31, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 9, 62, 23, 61, 7, 36, 61, 25, 14, 58, 31, 62, 62, 61, 15, 58, 36, 61, 25, 9, 58, 31, 62, 62]\n",
            "iter 68000\n",
            "loss 0.10688347280025483\n",
            "trg [1, 27, 61, 54, 38, 9, 40, 61, 3, 62, 62, 23, 61, 4, 33, 61, 54, 62, 34, 40, 61, 9, 62, 61, 54, 62, 62, 61, 34, 40, 61, 9, 62, 61, 54, 62, 3, 25, 16, 54, 36, 61, 54, 62, 3, 15, 31, 36, 40, 61, 8, 62, 61, 54, 62, 62, 2]\n",
            "pred [1, 27, 61, 54, 38, 9, 40, 61, 3, 62, 62, 23, 61, 4, 33, 61, 54, 62, 34, 40, 61, 9, 62, 61, 54, 62, 62, 61, 34, 40, 61, 9, 62, 61, 54, 62, 3, 25, 16, 54, 36, 61, 54, 62, 3, 15, 31, 36, 40, 61, 8, 62, 61, 54, 62, 62]\n",
            "iter 69000\n",
            "loss 0.08701379880309106\n",
            "trg [1, 27, 61, 50, 38, 24, 62, 23, 61, 4, 10, 25, 21, 61, 12, 6, 50, 62, 3, 4, 15, 10, 6, 50, 20, 61, 9, 6, 50, 62, 31, 62, 61, 4, 9, 50, 40, 61, 4, 10, 62, 62, 2]\n",
            "pred [1, 27, 61, 50, 38, 24, 62, 23, 61, 4, 10, 25, 21, 61, 12, 6, 50, 62, 3, 4, 15, 10, 6, 50, 20, 61, 9, 6, 50, 62, 31, 62, 61, 4, 9, 50, 40, 61, 4, 10, 62, 62]\n",
            "iter 1000\n",
            "loss 0.09164909958839416\n",
            "trg [1, 17, 46, 40, 61, 27, 61, 43, 38, 9, 40, 61, 3, 62, 62, 23, 61, 28, 61, 43, 62, 62, 61, 10, 3, 28, 61, 43, 62, 62, 62, 2]\n",
            "pred [1, 46, 40, 61, 27, 27, 61, 43, 38, 9, 40, 61, 3, 62, 62, 23, 61, 28, 61, 43, 62, 62, 61, 10, 28, 61, 43, 62, 62, 62]\n",
            "iter 2000\n",
            "loss 0.1013808910548687\n",
            "trg [1, 27, 61, 43, 38, 14, 40, 61, 3, 62, 62, 21, 61, 43, 62, 3, 4, 13, 12, 6, 43, 2]\n",
            "pred [1, 27, 61, 43, 38, 14, 40, 61, 3, 62, 62, 21, 61, 43, 62, 3, 4, 13, 12, 6, 43]\n",
            "iter 3000\n",
            "loss 0.10083090901374817\n",
            "trg [1, 28, 61, 58, 62, 17, 23, 61, 27, 61, 48, 38, 23, 61, 30, 62, 61, 10, 62, 40, 61, 4, 62, 62, 34, 61, 48, 62, 62, 61, 27, 61, 48, 38, 23, 61, 30, 62, 61, 12, 62, 40, 61, 4, 62, 62, 4, 15, 36, 40, 61, 16, 62, 61, 48, 62, 62, 2]\n",
            "pred [1, 28, 61, 58, 62, 17, 23, 61, 27, 61, 48, 38, 23, 61, 30, 62, 61, 10, 62, 40, 61, 4, 62, 62, 34, 61, 48, 62, 62, 61, 27, 61, 48, 38, 23, 61, 30, 62, 61, 12, 62, 40, 61, 4, 62, 62, 4, 15, 36, 40, 61, 16, 62, 61, 48, 62, 62]\n",
            "iter 4000\n",
            "loss 0.09541386388242244\n",
            "trg [1, 28, 61, 55, 62, 17, 23, 61, 27, 61, 52, 38, 23, 61, 30, 62, 61, 16, 62, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 52, 62, 33, 61, 52, 62, 62, 61, 27, 61, 52, 38, 23, 61, 30, 62, 61, 10, 62, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 52, 62, 4, 9, 33, 40, 61, 16, 62, 61, 52, 62, 62, 2]\n",
            "pred [1, 28, 61, 55, 62, 17, 23, 61, 27, 61, 52, 38, 23, 61, 30, 62, 61, 16, 62, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 52, 62, 33, 61, 52, 62, 62, 61, 27, 61, 52, 38, 23, 61, 30, 62, 61, 10, 62, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 52, 62, 4, 9, 33, 40, 61, 16, 62, 61, 52, 62, 62, 2]\n",
            "iter 5000\n",
            "loss 0.09322257943451405\n",
            "trg [1, 16, 6, 14, 27, 61, 57, 38, 30, 6, 10, 40, 61, 4, 62, 62, 23, 61, 16, 62, 61, 22, 40, 61, 14, 62, 61, 57, 62, 3, 9, 20, 40, 61, 13, 62, 61, 57, 62, 62, 2]\n",
            "pred [1, 11, 6, 14, 27, 61, 57, 38, 30, 6, 10, 40, 61, 4, 62, 62, 23, 61, 16, 62, 61, 22, 40, 61, 14, 62, 61, 57, 62, 3, 9, 20, 40, 61, 13, 62, 61, 57, 62, 62]\n",
            "iter 6000\n",
            "loss 0.09769636578857899\n",
            "trg [1, 27, 61, 57, 38, 16, 40, 61, 3, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 57, 62, 20, 61, 57, 62, 62, 61, 23, 61, 45, 62, 61, 45, 57, 62, 57, 62, 27, 61, 57, 38, 16, 40, 61, 3, 62, 62, 35, 61, 57, 25, 13, 3, 4, 16, 57, 31, 62, 2]\n",
            "pred [1, 27, 61, 57, 38, 16, 40, 61, 3, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 57, 62, 20, 61, 57, 62, 62, 61, 23, 61, 45, 62, 61, 45, 57, 62, 57, 62, 61, 57, 62, 61, 57, 40, 61, 16, 62, 3, 61, 57, 40, 61, 16, 62, 3, 16, 57, 31, 62]\n",
            "iter 7000\n",
            "loss 0.10387896567583084\n",
            "trg [1, 17, 27, 61, 60, 38, 9, 62, 23, 61, 36, 61, 60, 62, 4, 8, 62, 61, 36, 40, 61, 7, 62, 61, 60, 62, 62, 2]\n",
            "pred [1, 17, 27, 61, 60, 38, 9, 62, 23, 61, 36, 61, 60, 62, 4, 8, 62, 61, 36, 40, 61, 7, 62, 61, 60, 62, 62]\n",
            "iter 8000\n",
            "loss 0.09471243314445019\n",
            "trg [1, 27, 61, 52, 38, 8, 62, 23, 61, 23, 61, 45, 62, 61, 45, 52, 62, 25, 52, 28, 61, 52, 62, 3, 4, 14, 52, 3, 12, 31, 62, 61, 23, 61, 45, 62, 61, 45, 52, 62, 52, 28, 52, 40, 61, 15, 62, 62, 2]\n",
            "pred [1, 27, 61, 52, 38, 8, 62, 23, 61, 23, 61, 45, 62, 61, 45, 52, 62, 25, 52, 28, 61, 52, 62, 3, 4, 14, 52, 3, 12, 31, 62, 61, 23, 61, 45, 62, 61, 45, 52, 62, 52, 28, 52, 40, 61, 15, 62, 62]\n",
            "iter 9000\n",
            "loss 0.07715594723820686\n",
            "trg [1, 27, 61, 52, 38, 30, 6, 13, 62, 34, 40, 61, 10, 62, 61, 52, 62, 3, 27, 61, 52, 38, 30, 6, 11, 62, 22, 40, 61, 10, 62, 61, 52, 62, 2]\n",
            "pred [1, 27, 61, 52, 38, 30, 6, 13, 62, 34, 40, 61, 10, 62, 61, 52, 62, 3, 27, 61, 52, 38, 30, 6, 11, 62, 22, 40, 61, 10, 62, 61, 52, 62]\n",
            "iter 10000\n",
            "loss 0.10421263039112091\n",
            "trg [1, 27, 61, 53, 38, 30, 6, 9, 62, 34, 40, 61, 12, 62, 61, 53, 62, 3, 27, 61, 53, 38, 30, 6, 10, 62, 36, 40, 61, 11, 62, 61, 53, 62, 2]\n",
            "pred [1, 27, 61, 53, 38, 30, 6, 9, 62, 34, 40, 61, 12, 62, 61, 53, 62, 3, 27, 61, 53, 38, 30, 6, 10, 62, 36, 40, 61, 11, 62, 61, 53, 62]\n",
            "iter 11000\n",
            "loss 0.091262112185359\n",
            "trg [1, 27, 61, 49, 38, 24, 62, 23, 61, 23, 61, 29, 41, 61, 8, 7, 62, 61, 49, 62, 62, 61, 29, 41, 61, 9, 12, 62, 61, 14, 62, 62, 62, 61, 23, 61, 29, 41, 61, 14, 10, 62, 61, 49, 62, 62, 61, 29, 41, 61, 10, 15, 62, 61, 16, 62, 62, 62, 2]\n",
            "pred [1, 27, 61, 49, 38, 24, 62, 23, 61, 23, 61, 29, 41, 61, 8, 7, 62, 61, 49, 62, 62, 61, 29, 41, 61, 9, 12, 62, 61, 14, 62, 62, 62, 61, 23, 61, 29, 41, 61, 14, 12, 62, 61, 49, 62, 62, 61, 29, 41, 61, 10, 15, 62, 61, 16, 62, 62, 62]\n",
            "iter 12000\n",
            "loss 0.09911621928215027\n",
            "trg [1, 27, 61, 43, 38, 4, 24, 62, 43, 2]\n",
            "pred [1, 27, 61, 43, 38, 4, 24, 62, 43]\n",
            "iter 13000\n",
            "loss 0.09687519237399102\n",
            "trg [1, 27, 61, 58, 38, 30, 6, 12, 62, 23, 61, 10, 36, 40, 61, 9, 62, 61, 58, 62, 3, 9, 20, 40, 61, 10, 62, 61, 58, 62, 62, 61, 9, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 30, 6, 12, 62, 23, 61, 10, 36, 40, 61, 9, 62, 61, 58, 62, 3, 9, 20, 40, 61, 10, 62, 61, 58, 62, 62, 61, 9, 62]\n",
            "iter 14000\n",
            "loss 0.10963445015251637\n",
            "trg [1, 27, 61, 48, 38, 30, 6, 12, 40, 61, 4, 62, 62, 23, 61, 20, 61, 48, 62, 62, 61, 4, 9, 34, 61, 48, 62, 62, 2]\n",
            "pred [1, 27, 61, 48, 38, 30, 6, 12, 40, 61, 4, 62, 62, 23, 61, 20, 61, 48, 62, 62, 61, 4, 9, 34, 61, 48, 62, 62]\n",
            "iter 1000\n",
            "loss 0.1556733477115631\n",
            "trg [1, 17, 27, 61, 58, 38, 30, 6, 16, 40, 61, 4, 62, 62, 23, 61, 36, 40, 61, 12, 62, 61, 58, 62, 62, 61, 23, 61, 4, 15, 62, 61, 11, 58, 3, 25, 4, 12, 30, 31, 40, 61, 11, 62, 62, 62, 2]\n",
            "pred [1, 17, 27, 61, 58, 38, 30, 6, 16, 40, 61, 4, 62, 62, 23, 61, 36, 40, 61, 12, 62, 61, 58, 62, 62, 61, 23, 61, 4, 15, 62, 61, 11, 58, 3, 25, 4, 12, 30, 31, 40, 61, 11, 62, 62, 62]\n",
            "iter 2000\n",
            "loss 0.13338218808174132\n",
            "trg [1, 27, 61, 58, 38, 24, 62, 23, 61, 4, 13, 25, 34, 61, 13, 6, 58, 62, 3, 4, 13, 13, 6, 58, 36, 61, 13, 6, 58, 62, 31, 62, 61, 4, 9, 58, 40, 61, 4, 12, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 23, 61, 4, 13, 25, 34, 61, 13, 6, 58, 62, 3, 4, 13, 13, 6, 58, 36, 61, 13, 6, 58, 62, 31, 62, 61, 4, 9, 58, 40, 61, 4, 12, 62, 62]\n",
            "iter 3000\n",
            "loss 0.12949827283620835\n",
            "trg [1, 27, 61, 51, 38, 8, 40, 61, 3, 62, 62, 23, 61, 4, 14, 33, 61, 51, 62, 20, 40, 61, 10, 62, 61, 51, 62, 62, 61, 25, 9, 3, 9, 51, 33, 61, 51, 62, 31, 20, 40, 61, 11, 62, 61, 51, 62, 62, 2]\n",
            "pred [1, 27, 61, 51, 38, 8, 40, 61, 3, 62, 62, 23, 61, 4, 14, 33, 61, 51, 62, 20, 40, 61, 10, 62, 61, 51, 62, 62, 61, 25, 9, 3, 9, 51, 33, 61, 51, 62, 31, 20, 40, 61, 11, 62, 61, 51, 62, 62]\n",
            "iter 4000\n",
            "loss 0.13010611832141877\n",
            "trg [1, 27, 61, 57, 38, 4, 24, 62, 23, 61, 8, 12, 57, 40, 61, 9, 62, 3, 4, 12, 57, 40, 61, 10, 62, 3, 12, 62, 61, 35, 61, 11, 8, 57, 40, 61, 15, 62, 3, 57, 40, 61, 16, 62, 3, 14, 62, 62, 2]\n",
            "pred [1, 27, 61, 57, 38, 4, 24, 62, 23, 61, 8, 12, 57, 40, 61, 9, 62, 3, 4, 12, 57, 40, 61, 10, 62, 3, 12, 62, 61, 35, 61, 11, 8, 57, 40, 61, 15, 62, 3, 57, 40, 61, 16, 62, 3, 14, 62]\n",
            "iter 5000\n",
            "loss 0.1474121518433094\n",
            "trg [1, 17, 27, 61, 51, 38, 23, 61, 30, 62, 61, 14, 62, 62, 36, 40, 61, 15, 62, 61, 51, 62, 3, 27, 61, 51, 38, 23, 61, 30, 62, 61, 15, 62, 62, 33, 40, 61, 15, 62, 61, 51, 62, 2]\n",
            "pred [1, 17, 27, 61, 51, 38, 23, 61, 30, 62, 61, 14, 62, 62, 36, 40, 61, 15, 62, 61, 51, 62, 3, 27, 61, 51, 38, 23, 61, 30, 62, 61, 15, 62, 62, 33, 40, 61, 15, 62, 61, 51, 62]\n",
            "iter 6000\n",
            "loss 0.12787704087793828\n",
            "trg [1, 27, 61, 57, 38, 10, 62, 23, 61, 4, 11, 23, 61, 57, 40, 61, 16, 62, 3, 15, 57, 4, 8, 62, 61, 12, 8, 25, 57, 40, 61, 9, 62, 3, 10, 57, 31, 62, 62, 61, 57, 4, 9, 62, 2]\n",
            "pred [1, 27, 61, 57, 38, 10, 62, 23, 61, 4, 11, 57, 40, 61, 16, 62, 3, 16, 57, 3, 15, 62, 61, 8, 12, 57, 40, 61, 8, 62, 31, 25, 9, 57, 40, 61, 9, 62, 3, 9, 57, 57, 40, 61, 8, 62, 62]\n",
            "iter 7000\n",
            "loss 0.12613371603190898\n",
            "trg [1, 27, 61, 44, 38, 11, 62, 23, 61, 9, 3, 4, 9, 44, 62, 61, 44, 40, 61, 14, 62, 3, 4, 10, 44, 62, 2]\n",
            "pred [1, 27, 61, 44, 38, 11, 62, 23, 61, 9, 3, 4, 9, 44, 62, 61, 44, 40, 61, 14, 62, 3, 4, 10, 44, 62]\n",
            "iter 8000\n",
            "loss 0.11274570308625698\n",
            "trg [1, 27, 61, 58, 38, 49, 62, 58, 3, 25, 4, 12, 49, 31, 40, 61, 10, 12, 62, 4, 15, 2]\n",
            "pred [1, 27, 61, 58, 38, 49, 62, 58, 3, 25, 4, 12, 49, 31, 40, 61, 10, 12, 62, 4, 15]\n",
            "iter 9000\n",
            "loss 0.15261343203485012\n",
            "trg [1, 27, 61, 60, 38, 7, 40, 61, 3, 62, 62, 46, 40, 61, 28, 60, 40, 61, 23, 61, 9, 62, 61, 28, 61, 60, 62, 62, 62, 62, 2]\n",
            "pred [1, 27, 61, 60, 38, 7, 40, 61, 3, 62, 62, 46, 40, 61, 23, 61, 9, 62, 61, 28, 61, 60, 62, 62, 28, 61, 60, 62, 62]\n",
            "iter 10000\n",
            "loss 0.12148198418319225\n",
            "trg [1, 27, 61, 55, 38, 9, 62, 4, 16, 35, 61, 55, 3, 11, 62, 25, 10, 3, 35, 61, 55, 3, 8, 62, 31, 2]\n",
            "pred [1, 27, 61, 55, 38, 9, 62, 4, 16, 35, 61, 55, 3, 11, 62, 25, 10, 3, 35, 61, 55, 3, 8, 62, 31, 62]\n",
            "iter 11000\n",
            "loss 0.11668673731386661\n",
            "trg [1, 27, 61, 47, 38, 11, 40, 61, 3, 62, 62, 23, 61, 4, 11, 36, 61, 47, 62, 33, 40, 61, 9, 62, 61, 47, 62, 62, 61, 25, 15, 3, 15, 47, 34, 61, 47, 62, 31, 36, 40, 61, 7, 62, 61, 47, 62, 62, 2]\n",
            "pred [1, 27, 61, 47, 38, 11, 40, 61, 3, 62, 62, 23, 61, 4, 11, 36, 61, 47, 62, 33, 40, 61, 9, 62, 61, 47, 62, 62, 61, 25, 15, 3, 15, 47, 34, 61, 47, 62, 31, 36, 40, 61, 7, 62, 61, 47, 62, 62]\n",
            "iter 12000\n",
            "loss 0.11314760416746139\n",
            "trg [1, 27, 61, 57, 38, 9, 62, 23, 61, 46, 40, 61, 12, 57, 62, 4, 8, 62, 61, 46, 40, 61, 57, 62, 4, 9, 62, 2]\n",
            "pred [1, 27, 61, 57, 38, 9, 62, 23, 61, 46, 40, 61, 12, 57, 62, 4, 8, 62, 61, 46, 40, 61, 57, 62, 4, 9, 62]\n",
            "iter 13000\n",
            "loss 0.14029633559286595\n",
            "trg [1, 27, 61, 56, 38, 23, 61, 30, 62, 61, 14, 62, 62, 36, 40, 61, 14, 62, 61, 56, 62, 3, 27, 61, 56, 38, 23, 61, 30, 62, 61, 9, 62, 62, 34, 40, 61, 14, 62, 61, 56, 62, 2]\n",
            "pred [1, 27, 61, 56, 38, 23, 61, 30, 62, 61, 14, 62, 62, 36, 40, 61, 14, 62, 61, 56, 62, 3, 27, 61, 56, 38, 23, 61, 30, 62, 61, 9, 62, 62, 34, 40, 61, 14, 62, 61, 56, 62]\n",
            "iter 14000\n",
            "loss 0.13516489624977113\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 5/5 [1:08:24<00:00, 820.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\tTrain Loss:   0.096 | Train PPL:   1.101\n",
            "\tValid Loss:   0.097 | Valid PPL:   1.102\n",
            "\\Test Loss:   0.131 | Valid PPL:   1.140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part 3.4 Evaluating Expression Generation\n",
        "Code to generate expression using LSTM with attention model."
      ],
      "metadata": {
        "id": "ZguhKtYEtFfX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from copy import deepcopy\n",
        "def get_char_cnt(src):\n",
        "   cnt_chars = {}\n",
        "   for i in range(0, 57):\n",
        "     cnt_chars[i] = 0\n",
        "   possible_chars = []\n",
        "   src_ls = src.tolist()\n",
        "   src_nums = []\n",
        "   for char_list in src_ls:\n",
        "     for one_hot_encoded_char in char_list:\n",
        "        for i in range(57):\n",
        "          if one_hot_encoded_char[i] == 1:\n",
        "            src_nums.append(i)\n",
        "   for num in src_nums:\n",
        "     possible_chars.append(num)\n",
        "     cnt_chars[num] += 1\n",
        "   cnt_chars[1] = 0\n",
        "   return possible_chars,cnt_chars\n",
        "def update_char_cnt(output,possible_chars,cnt_chars,top1):\n",
        "\n",
        "  hidden_chars = {18,39,40,41,61,62}\n",
        "  mxp = -5000\n",
        "  ls_output = output.tolist()\n",
        "  new_cnt_chars = {}\n",
        "  for char, cnt_char in cnt_chars.items():\n",
        "    new_cnt_chars[char] = cnt_char\n",
        "  for i in range(63):\n",
        "    if i in hidden_chars:\n",
        "      if ls_output[0][i] > mxp:\n",
        "        top1 = torch.tensor(i)\n",
        "        mxp = ls_output[0][i]\n",
        "      continue\n",
        "    visible_char_i = full_to_visible_encoding[i]\n",
        "    if visible_char_i in possible_chars and ls_output[0][i] > mxp and (cnt_chars[visible_char_i] > 0):\n",
        "      top1 = torch.tensor(i)\n",
        "      mxp = ls_output[0][i]\n",
        "  if top1.item() not in hidden_chars:\n",
        "    new_cnt_chars[full_to_visible_encoding[top1.item()]] -= 1\n",
        "  cnt_chars[1] = 0\n",
        "  return top1, new_cnt_chars\n",
        "def copy_char_cnt(cnt_chars):\n",
        "  new_cnt_chars = {}\n",
        "  for char, cnt_char in cnt_chars.items():\n",
        "    new_cnt_chars[char] = cnt_char\n",
        "  return new_cnt_chars\n",
        "\n",
        "def update_char_cnt_direct(option, cnt_chars):\n",
        "  new_cnt_chars = deepcopy(cnt_chars)\n",
        "  new_cnt_chars[option] -= 1\n",
        "  return new_cnt_chars\n",
        "def get_sorted_options(output_scores,possible_chars,cnt_chars):\n",
        "   hidden_chars = {18,39,40,41,61,62}\n",
        "   next_options = []\n",
        "   scores = []\n",
        "   for (i,score) in output_scores:\n",
        "     if i in hidden_chars:\n",
        "       next_options.append(i)\n",
        "       scores.append(score)\n",
        "       continue\n",
        "     visible_char_i = full_to_visible_encoding[i]\n",
        "     if visible_char_i in possible_chars and (cnt_chars[visible_char_i] > 0):\n",
        "       next_options.append(i)\n",
        "       scores.append(score)\n",
        "   return next_options,scores"
      ],
      "metadata": {
        "id": "tbNqnzwHbkOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_char_recursive(\n",
        "    max_expression_length,\n",
        "    model,\n",
        "    predicted_expression,\n",
        "    hidden,\n",
        "    cell,\n",
        "    next_input,\n",
        "    encoder_outputs,\n",
        "    possible_chars,\n",
        "    cnt_chars\n",
        "):\n",
        "  # print(predicted_expression)\n",
        "  # print(len(predicted_expression))\n",
        "  # if len(predicted_expression) == 5:\n",
        "  #   return predicted_expression, True\n",
        "  next_input = next_input.unsqueeze(0)\n",
        "  hidden_chars = {18,39,40,41,57,58,59,60,61,62}\n",
        "\n",
        "  # print('next input shape',next_input.shape)\n",
        "  # next_input = torch.tensor(option).float().to(device)\n",
        "  output, hidden, cell = model.decoder(next_input, encoder_outputs, hidden, cell)\n",
        "  top1 = output.argmax(1)\n",
        "  output_scores = [(index,score) for index,score in enumerate(output.tolist()[0])]\n",
        "  sorted_output_scores = sorted(output_scores, key = lambda o: o[1], reverse=True)\n",
        "  next_options,scores = get_sorted_options(sorted_output_scores, possible_chars, cnt_chars)\n",
        "  next_options = next_options[:2]\n",
        "  scores = scores[:2]\n",
        "  if next_options[0] in hidden_chars:\n",
        "    next_options[0],next_options[1] = next_options[1],next_options[0]\n",
        "  # print(next_options)\n",
        "  n = 0\n",
        "  for i,option in enumerate(next_options):\n",
        "\n",
        "    visible_char_option = option\n",
        "    if visible_char_option not in hidden_chars:\n",
        "      visible_char_option = full_to_visible_encoding[option]\n",
        "    if i == 2:\n",
        "      break\n",
        "    all_visible_chars_used = False\n",
        "    next_cnt_chars = deepcopy(cnt_chars)\n",
        "    if visible_char_option not in hidden_chars:\n",
        "      next_cnt_chars = update_char_cnt_direct(visible_char_option, cnt_chars)\n",
        "    # if option == 2 or option == 0:\n",
        "    all_visible_chars_used = all([next_cnt_char == 0 for next_cnt_char in next_cnt_chars.values()])\n",
        "\n",
        "    next_predicted_expression = deepcopy(predicted_expression)\n",
        "    next_predicted_expression.append(option)\n",
        "    if len(next_predicted_expression) == 67:\n",
        "      print('next cnt chars')\n",
        "      print(next_cnt_chars)\n",
        "      print('all visible chars used')\n",
        "      print(all_visible_chars_used)\n",
        "    if len(next_predicted_expression) == max_expression_length or ((visible_char_option == 2 or visible_char_option == 0) and all_visible_chars_used):\n",
        "      return next_predicted_expression, all_visible_chars_used\n",
        "    one_hot_encoded_option = torch.tensor([\n",
        "          1 if i == visible_char_option\n",
        "          else 0\n",
        "          for i in range(63)\n",
        "    ])\n",
        "    next_input = torch.tensor(one_hot_encoded_option).float().to(device)\n",
        "    next_input = next_input.unsqueeze(0)\n",
        "    next_predicted_expression, all_visible_chars_used = add_char_recursive(\n",
        "        max_expression_length,\n",
        "        model,\n",
        "        next_predicted_expression,\n",
        "        hidden,\n",
        "        cell,\n",
        "        next_input,\n",
        "        encoder_outputs,\n",
        "        possible_chars,\n",
        "        next_cnt_chars\n",
        "    )\n",
        "    # if all_visible_chars_used:\n",
        "    # return next_predicted_expression, all_visible_chars_used\n",
        "\n",
        "  return next_predicted_expression, all_visible_chars_used\n",
        "\n",
        "def create_expression_recursive(\n",
        "    input_seq,\n",
        "    max_expression_length,\n",
        "    model,\n",
        "    label_eos_token,\n",
        "    label_sos_token\n",
        "):\n",
        "  possible_chars, cnt_chars = get_char_cnt(input_seq)\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    encoder_outputs, hidden, cell = model.encoder(input_seq)\n",
        "    next_input = label_sos_token\n",
        "    next_input = next_input[None,:]\n",
        "    predicted_expression = [1]\n",
        "    predicted_expression, all_visible_chars_used = add_char_recursive(\n",
        "        max_expression_length,\n",
        "        model,\n",
        "        predicted_expression,\n",
        "        hidden,\n",
        "        cell,\n",
        "        next_input,\n",
        "        encoder_outputs,\n",
        "        possible_chars,\n",
        "        cnt_chars\n",
        "    )\n",
        "    return predicted_expression\n",
        "def create_expression(\n",
        "    input_seq,\n",
        "    max_expression_length,\n",
        "    model,\n",
        "    label_eos_token,\n",
        "    label_sos_token,\n",
        "):\n",
        "  # print(input_seq)\n",
        "  # generate counts for each visible character\n",
        "  possible_chars, cnt_chars = get_char_cnt(input_seq)\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    encoder_outputs, hidden, cell = model.encoder(input_seq)\n",
        "    next_input = label_sos_token\n",
        "    next_input = next_input[None,:]\n",
        "    predicted_expression = [1]\n",
        "    for _ in range(max_expression_length):\n",
        "      next_input = next_input.unsqueeze(0)\n",
        "      # print('next input shape',next_input.shape)\n",
        "      output, hidden, cell = model.decoder(next_input, encoder_outputs, hidden, cell)\n",
        "      top1 = output.argmax(1)\n",
        "      # top1 ,cnt_chars = update_char_cnt(output, possible_chars, cnt_chars, top1)\n",
        "      one_hot_encoded_top1 = torch.tensor([\n",
        "        1 if i == top1.item()\n",
        "        else 0\n",
        "        for i in range(63)\n",
        "      ])\n",
        "      predicted_expression.append(top1.item())\n",
        "      next_input = torch.tensor(one_hot_encoded_top1).float().to(device)\n",
        "      next_input = next_input.unsqueeze(0)\n",
        "      if next_input[0][2] == 1 or next_input[0][0] == 1:\n",
        "        break\n",
        "    return predicted_expression\n",
        "def evaluate_create_expression(model, data_loader):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    current_loss = 0\n",
        "    acc = 0\n",
        "    total_acc = 0\n",
        "    batch_acc = 0\n",
        "    max_acc = -1\n",
        "    min_acc = 101\n",
        "    cnt_100_percent = 0\n",
        "    accs = []\n",
        "    with torch.no_grad():\n",
        "        for j, (src,trg) in enumerate(data_loader):\n",
        "          src = torch.transpose(src,0,1)\n",
        "          src = src.to(device)\n",
        "          trg = torch.tensor(trg).to(device)\n",
        "          trg = torch.transpose(trg,0,1)\n",
        "          decoded_trg = []\n",
        "          trg_ls = trg.tolist()\n",
        "          for ls in trg_ls:\n",
        "            for i,l in enumerate(ls[0]):\n",
        "              if l == 1:\n",
        "                decoded_trg.append(i)\n",
        "                break\n",
        "          # print(len(decoded_trg))\n",
        "          # print(decoded_trg)\n",
        "          label_sos_token = torch.tensor([1 if i == 1 else 0 for i in range(63)]).to(device)\n",
        "          label_eos_token = torch.tensor([1 if i == 2 else 0 for i in range(63)]).to(device)\n",
        "          predicted_expression = create_expression(src,100,model,label_sos_token,label_eos_token)\n",
        "\n",
        "          if len(predicted_expression) < len(decoded_trg) - 1:\n",
        "            while len(predicted_expression) < len(decoded_trg) - 1:\n",
        "              predicted_expression.append(0)\n",
        "            predicted_expression.append(2)\n",
        "          elif len(predicted_expression) < len(decoded_trg):\n",
        "            predicted_expression.append(2)\n",
        "          elif len(predicted_expression) == len(decoded_trg):\n",
        "            predicted_expression[-1] = 2\n",
        "          elif len(predicted_expression) > len(decoded_trg) - 1:\n",
        "            decoded_trg[-1] = 0\n",
        "            while len(predicted_expression) -1 > len(decoded_trg):\n",
        "              decoded_trg.append(0)\n",
        "            decoded_trg.append(2)\n",
        "            predicted_expression[-1]= 2\n",
        "          elif len(predicted_expression) > len(decoded_trg):\n",
        "            decoded_trg[-1] = 0\n",
        "            decoded_trg.append(2)\n",
        "            predicted_expression[-1]= 2\n",
        "          p,t = np.array(predicted_expression),np.array(decoded_trg)\n",
        "          curr_acc = np.mean(p == t) * 100\n",
        "          curr_acc = int(curr_acc)\n",
        "          if curr_acc == 100:\n",
        "            cnt_100_percent+=1\n",
        "          total_acc += curr_acc\n",
        "          max_acc = max(max_acc, curr_acc)\n",
        "          min_acc = min(min_acc,curr_acc)\n",
        "          accs.append(curr_acc)\n",
        "          if j % 20 == 0:\n",
        "            print('iteration')\n",
        "            print(j)\n",
        "            print('predicted expression')\n",
        "            print(predicted_expression)\n",
        "            print('ground truth expression')\n",
        "            print(decoded_trg)\n",
        "            print('current accuracy',curr_acc)\n",
        "            print('current ave accuracy',total_acc // (j+1))\n",
        "            print('min accuracy in batch',min_acc)\n",
        "            print('max accuracy in batch',max_acc)\n",
        "            print('number of perfect predictions',cnt_100_percent)\n",
        "            max_acc = -1\n",
        "            min_acc = 101\n",
        "    return np.array(accs)\n",
        "seq_train_dataloader = torch.utils.data.DataLoader(\n",
        "    seq_train_dataset,\n",
        "    batch_size = 1,\n",
        "    shuffle = False,\n",
        "    collate_fn = collate_fn,\n",
        "    pin_memory = True if torch.cuda.is_available() else False\n",
        ")\n",
        "accs = evaluate_create_expression(lstm_model, seq_train_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WgcYE71WTx9a",
        "outputId": "eef165f5-24e8-4033-b613-5708dc2911b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-80-d6a6a3c68b9f>:153: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  trg = torch.tensor(trg).to(device)\n",
            "<ipython-input-80-d6a6a3c68b9f>:132: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_input = torch.tensor(one_hot_encoded_top1).float().to(device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration\n",
            "0\n",
            "predicted expression\n",
            "[1, 27, 61, 56, 38, 10, 62, 23, 61, 23, 61, 45, 62, 61, 45, 56, 62, 25, 46, 40, 61, 56, 62, 3, 4, 9, 34, 61, 56, 62, 4, 16, 31, 62, 61, 23, 61, 45, 62, 61, 45, 56, 62, 25, 56, 40, 61, 8, 62, 3, 8, 56, 40, 61, 16, 62, 3, 16, 15, 56, 40, 61, 11, 62, 31, 62, 2]\n",
            "ground truth expression\n",
            "[1, 27, 61, 56, 38, 10, 62, 23, 61, 23, 61, 45, 62, 61, 45, 56, 62, 25, 46, 40, 61, 56, 62, 3, 4, 9, 34, 61, 56, 62, 4, 16, 31, 62, 61, 23, 61, 45, 62, 61, 45, 56, 62, 25, 56, 40, 61, 8, 62, 3, 8, 56, 40, 61, 16, 62, 3, 16, 15, 56, 40, 61, 11, 62, 31, 62, 2]\n",
            "current accuracy 100\n",
            "current ave accuracy 100\n",
            "min accuracy in batch 100\n",
            "max accuracy in batch 100\n",
            "number of perfect predictions 1\n",
            "iteration\n",
            "20\n",
            "predicted expression\n",
            "[1, 17, 27, 61, 50, 38, 24, 62, 23, 61, 23, 61, 29, 41, 61, 8, 12, 62, 61, 50, 62, 62, 61, 29, 41, 61, 12, 12, 62, 61, 13, 62, 62, 62, 61, 23, 61, 29, 41, 61, 14, 16, 62, 61, 50, 62, 62, 61, 29, 41, 61, 9, 9, 62, 61, 9, 62, 62, 62, 2]\n",
            "ground truth expression\n",
            "[1, 17, 27, 61, 50, 38, 24, 62, 23, 61, 23, 61, 29, 41, 61, 8, 12, 62, 61, 50, 62, 62, 61, 29, 41, 61, 12, 14, 62, 61, 13, 62, 62, 62, 61, 23, 61, 29, 41, 61, 14, 16, 62, 61, 50, 62, 62, 61, 29, 41, 61, 9, 9, 62, 61, 9, 62, 62, 62, 2]\n",
            "current accuracy 98\n",
            "current ave accuracy 87\n",
            "min accuracy in batch 15\n",
            "max accuracy in batch 100\n",
            "number of perfect predictions 15\n",
            "iteration\n",
            "40\n",
            "predicted expression\n",
            "[1, 27, 61, 53, 38, 16, 62, 23, 61, 28, 61, 53, 62, 62, 61, 28, 61, 53, 62, 25, 28, 61, 53, 62, 3, 10, 31, 62, 2]\n",
            "ground truth expression\n",
            "[1, 27, 61, 53, 38, 16, 62, 23, 61, 28, 61, 53, 62, 62, 61, 28, 61, 53, 62, 25, 28, 61, 53, 62, 3, 10, 31, 62, 2]\n",
            "current accuracy 100\n",
            "current ave accuracy 86\n",
            "min accuracy in batch 16\n",
            "max accuracy in batch 100\n",
            "number of perfect predictions 30\n",
            "iteration\n",
            "60\n",
            "predicted expression\n",
            "[1, 27, 61, 55, 38, 9, 40, 61, 4, 62, 62, 23, 61, 55, 4, 14, 62, 61, 35, 61, 25, 55, 4, 9, 31, 25, 55, 4, 15, 31, 62, 62, 2]\n",
            "ground truth expression\n",
            "[1, 27, 61, 55, 38, 9, 40, 61, 4, 62, 62, 23, 61, 55, 4, 14, 62, 61, 35, 61, 25, 55, 4, 9, 31, 25, 55, 4, 15, 31, 62, 62, 2]\n",
            "current accuracy 100\n",
            "current ave accuracy 88\n",
            "min accuracy in batch 21\n",
            "max accuracy in batch 100\n",
            "number of perfect predictions 45\n",
            "iteration\n",
            "80\n",
            "predicted expression\n",
            "[1, 23, 61, 9, 62, 61, 11, 62, 27, 61, 47, 38, 24, 62, 23, 61, 23, 61, 45, 62, 61, 45, 47, 62, 36, 61, 23, 61, 16, 62, 61, 47, 62, 62, 62, 61, 23, 61, 45, 62, 61, 45, 47, 62, 47, 40, 61, 4, 12, 62, 62, 2]\n",
            "ground truth expression\n",
            "[1, 23, 61, 9, 62, 61, 11, 62, 27, 61, 47, 38, 24, 62, 23, 61, 23, 61, 45, 62, 61, 45, 47, 62, 36, 61, 23, 61, 16, 62, 61, 47, 62, 62, 62, 61, 23, 61, 45, 62, 61, 45, 47, 62, 47, 40, 61, 4, 12, 62, 62, 2]\n",
            "current accuracy 100\n",
            "current ave accuracy 88\n",
            "min accuracy in batch 20\n",
            "max accuracy in batch 100\n",
            "number of perfect predictions 57\n",
            "iteration\n",
            "100\n",
            "predicted expression\n",
            "[1, 27, 61, 58, 38, 10, 40, 61, 3, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 58, 62, 25, 14, 3, 4, 34, 40, 61, 7, 62, 61, 58, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 58, 62, 25, 21, 61, 58, 62, 3, 58, 33, 40, 61, 15, 62, 61, 58, 62, 31, 62, 2]\n",
            "ground truth expression\n",
            "[1, 27, 61, 58, 38, 10, 40, 61, 3, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 58, 62, 25, 14, 3, 4, 34, 40, 61, 7, 62, 61, 58, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 58, 62, 25, 21, 61, 58, 62, 3, 58, 33, 40, 61, 15, 62, 61, 58, 62, 31, 62, 2]\n",
            "current accuracy 100\n",
            "current ave accuracy 88\n",
            "min accuracy in batch 20\n",
            "max accuracy in batch 100\n",
            "number of perfect predictions 71\n",
            "iteration\n",
            "120\n",
            "predicted expression\n",
            "[1, 61, 61, 62, 62, 62, 61, 26, 50, 3, 7, 32, 62, 0, 0, 0, 0, 0, 0, 0, 2]\n",
            "ground truth expression\n",
            "[1, 27, 61, 50, 38, 15, 62, 23, 61, 50, 4, 10, 62, 61, 26, 50, 3, 7, 32, 62, 2]\n",
            "current accuracy 19\n",
            "current ave accuracy 87\n",
            "min accuracy in batch 11\n",
            "max accuracy in batch 100\n",
            "number of perfect predictions 85\n",
            "iteration\n",
            "140\n",
            "predicted expression\n",
            "[1, 23, 61, 27, 61, 53, 38, 9, 40, 61, 3, 62, 62, 14, 7, 13, 28, 53, 40, 61, 8, 62, 62, 61, 27, 61, 53, 38, 11, 40, 61, 3, 62, 62, 35, 61, 59, 62, 62, 2]\n",
            "ground truth expression\n",
            "[1, 23, 61, 27, 61, 53, 38, 9, 40, 61, 3, 62, 62, 14, 7, 13, 28, 53, 40, 61, 8, 62, 62, 61, 27, 61, 53, 38, 11, 40, 61, 3, 62, 62, 35, 61, 59, 62, 62, 2]\n",
            "current accuracy 100\n",
            "current ave accuracy 88\n",
            "min accuracy in batch 26\n",
            "max accuracy in batch 100\n",
            "number of perfect predictions 100\n",
            "iteration\n",
            "160\n",
            "predicted expression\n",
            "[1, 27, 61, 57, 38, 24, 62, 23, 61, 29, 41, 61, 9, 8, 62, 61, 57, 62, 62, 61, 29, 41, 61, 8, 7, 62, 61, 10, 62, 62, 23, 61, 29, 41, 61, 15, 8, 62, 61, 8, 62, 62, 61, 29, 41, 61, 9, 8, 62, 61, 57, 62, 62, 2]\n",
            "ground truth expression\n",
            "[1, 27, 61, 57, 38, 24, 62, 23, 61, 29, 41, 61, 9, 8, 62, 61, 57, 62, 62, 61, 29, 41, 61, 8, 7, 62, 61, 10, 62, 62, 23, 61, 29, 41, 61, 15, 8, 62, 61, 8, 62, 62, 61, 29, 41, 61, 9, 8, 62, 61, 57, 62, 62, 2]\n",
            "current accuracy 100\n",
            "current ave accuracy 88\n",
            "min accuracy in batch 10\n",
            "max accuracy in batch 100\n",
            "number of perfect predictions 117\n",
            "iteration\n",
            "180\n",
            "predicted expression\n",
            "[1, 27, 61, 48, 38, 4, 24, 62, 23, 61, 13, 10, 48, 40, 61, 9, 62, 3, 48, 40, 61, 14, 62, 62, 61, 8, 15, 48, 40, 61, 10, 62, 3, 4, 48, 62, 2]\n",
            "ground truth expression\n",
            "[1, 27, 61, 48, 38, 4, 24, 62, 23, 61, 13, 10, 48, 40, 61, 9, 62, 3, 48, 40, 61, 14, 62, 62, 61, 8, 15, 48, 40, 61, 10, 62, 3, 4, 48, 62, 2]\n",
            "current accuracy 100\n",
            "current ave accuracy 87\n",
            "min accuracy in batch 15\n",
            "max accuracy in batch 100\n",
            "number of perfect predictions 130\n",
            "iteration\n",
            "200\n",
            "predicted expression\n",
            "[1, 40, 61, 10, 62, 62, 61, 58, 40, 61, 11, 62, 3, 4, 10, 58, 62, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2]\n",
            "ground truth expression\n",
            "[1, 27, 61, 58, 38, 16, 40, 61, 3, 62, 62, 23, 61, 10, 62, 61, 58, 40, 61, 11, 62, 3, 4, 10, 58, 62, 2]\n",
            "current accuracy 11\n",
            "current ave accuracy 88\n",
            "min accuracy in batch 11\n",
            "max accuracy in batch 100\n",
            "number of perfect predictions 146\n",
            "iteration\n",
            "220\n",
            "predicted expression\n",
            "[1, 27, 61, 58, 38, 7, 62, 23, 61, 28, 61, 25, 10, 3, 58, 31, 62, 62, 61, 28, 61, 25, 12, 3, 4, 11, 58, 40, 61, 13, 62, 31, 62, 62, 2]\n",
            "ground truth expression\n",
            "[1, 27, 61, 58, 38, 7, 62, 23, 61, 28, 61, 25, 10, 3, 58, 31, 62, 62, 61, 28, 61, 25, 12, 3, 4, 11, 58, 40, 61, 13, 62, 31, 62, 62, 2]\n",
            "current accuracy 100\n",
            "current ave accuracy 89\n",
            "min accuracy in batch 19\n",
            "max accuracy in batch 100\n",
            "number of perfect predictions 162\n",
            "iteration\n",
            "240\n",
            "predicted expression\n",
            "[1, 27, 61, 55, 38, 24, 62, 26, 55, 4, 8, 32, 3, 55, 2]\n",
            "ground truth expression\n",
            "[1, 27, 61, 55, 38, 24, 62, 26, 55, 4, 8, 32, 3, 55, 2]\n",
            "current accuracy 100\n",
            "current ave accuracy 89\n",
            "min accuracy in batch 15\n",
            "max accuracy in batch 100\n",
            "number of perfect predictions 177\n",
            "iteration\n",
            "260\n",
            "predicted expression\n",
            "[1, 17, 27, 61, 44, 38, 10, 62, 23, 61, 8, 34, 61, 44, 62, 34, 61, 44, 62, 62, 61, 34, 61, 44, 62, 62, 2]\n",
            "ground truth expression\n",
            "[1, 17, 27, 61, 44, 38, 10, 62, 23, 61, 8, 34, 61, 44, 62, 34, 61, 44, 62, 62, 61, 34, 61, 44, 62, 62, 2]\n",
            "current accuracy 100\n",
            "current ave accuracy 89\n",
            "min accuracy in batch 9\n",
            "max accuracy in batch 100\n",
            "number of perfect predictions 193\n",
            "iteration\n",
            "280\n",
            "predicted expression\n",
            "[1, 23, 61, 16, 62, 61, 11, 62, 27, 61, 59, 38, 23, 61, 30, 62, 61, 9, 62, 40, 61, 4, 62, 62, 23, 61, 10, 62, 61, 20, 40, 61, 10, 62, 61, 59, 62, 3, 4, 14, 20, 40, 61, 13, 62, 61, 59, 62, 62, 2]\n",
            "ground truth expression\n",
            "[1, 23, 61, 16, 62, 61, 11, 62, 27, 61, 59, 38, 23, 61, 30, 62, 61, 9, 62, 40, 61, 4, 62, 62, 23, 61, 10, 62, 61, 20, 40, 61, 10, 62, 61, 59, 62, 3, 4, 14, 20, 40, 61, 13, 62, 61, 59, 62, 62, 2]\n",
            "current accuracy 100\n",
            "current ave accuracy 88\n",
            "min accuracy in batch 10\n",
            "max accuracy in batch 100\n",
            "number of perfect predictions 205\n",
            "iteration\n",
            "300\n",
            "predicted expression\n",
            "[1, 27, 61, 48, 38, 10, 62, 23, 61, 48, 3, 13, 62, 61, 48, 3, 11, 62, 0, 0, 0, 0, 2]\n",
            "ground truth expression\n",
            "[1, 27, 61, 48, 38, 10, 62, 23, 61, 48, 3, 8, 62, 61, 48, 3, 11, 62, 40, 61, 13, 62, 2]\n",
            "current accuracy 78\n",
            "current ave accuracy 88\n",
            "min accuracy in batch 25\n",
            "max accuracy in batch 100\n",
            "number of perfect predictions 217\n",
            "iteration\n",
            "320\n",
            "predicted expression\n",
            "[1, 27, 61, 58, 38, 7, 40, 61, 3, 62, 62, 23, 61, 25, 58, 4, 8, 31, 25, 58, 4, 8, 31, 62, 61, 25, 58, 3, 7, 31, 25, 58, 3, 10, 31, 62, 2]\n",
            "ground truth expression\n",
            "[1, 27, 61, 58, 38, 7, 40, 61, 3, 62, 62, 23, 61, 25, 58, 4, 8, 31, 25, 58, 4, 8, 31, 62, 61, 25, 58, 3, 7, 31, 25, 58, 3, 10, 31, 62, 2]\n",
            "current accuracy 100\n",
            "current ave accuracy 88\n",
            "min accuracy in batch 15\n",
            "max accuracy in batch 100\n",
            "number of perfect predictions 234\n",
            "iteration\n",
            "340\n",
            "predicted expression\n",
            "[1, 27, 61, 55, 38, 16, 62, 23, 61, 34, 61, 55, 62, 3, 9, 62, 61, 55, 62, 2]\n",
            "ground truth expression\n",
            "[1, 27, 61, 55, 38, 16, 62, 23, 61, 34, 61, 55, 62, 3, 9, 62, 61, 55, 62, 2]\n",
            "current accuracy 100\n",
            "current ave accuracy 88\n",
            "min accuracy in batch 17\n",
            "max accuracy in batch 100\n",
            "number of perfect predictions 251\n",
            "iteration\n",
            "360\n",
            "predicted expression\n",
            "[1, 23, 61, 27, 61, 43, 38, 13, 62, 11, 9, 25, 34, 61, 25, 9, 43, 31, 62, 23, 61, 45, 62, 61, 45, 43, 62, 34, 61, 25, 12, 43, 31, 62, 3, 36, 61, 25, 10, 43, 31, 62, 23, 61, 45, 62, 61, 45, 43, 62, 20, 61, 25, 11, 43, 31, 62, 31, 62, 61, 27, 61, 43, 38, 10, 62, 10, 62, 2]\n",
            "ground truth expression\n",
            "[1, 23, 61, 27, 61, 43, 38, 13, 62, 11, 9, 25, 34, 61, 25, 9, 43, 31, 62, 23, 61, 45, 62, 61, 45, 43, 62, 34, 61, 25, 12, 43, 31, 62, 3, 36, 61, 25, 10, 43, 31, 62, 23, 61, 45, 62, 61, 45, 43, 62, 20, 61, 25, 11, 43, 31, 62, 31, 62, 61, 27, 61, 43, 38, 10, 62, 10, 62, 2]\n",
            "current accuracy 100\n",
            "current ave accuracy 88\n",
            "min accuracy in batch 13\n",
            "max accuracy in batch 100\n",
            "number of perfect predictions 267\n",
            "iteration\n",
            "380\n",
            "predicted expression\n",
            "[1, 27, 61, 57, 38, 12, 40, 61, 3, 62, 62, 46, 40, 61, 20, 61, 57, 62, 28, 61, 25, 8, 3, 57, 31, 62, 62, 2]\n",
            "ground truth expression\n",
            "[1, 27, 61, 57, 38, 12, 40, 61, 3, 62, 62, 46, 40, 61, 20, 61, 57, 62, 28, 61, 25, 8, 3, 57, 31, 62, 62, 2]\n",
            "current accuracy 100\n",
            "current ave accuracy 89\n",
            "min accuracy in batch 54\n",
            "max accuracy in batch 100\n",
            "number of perfect predictions 284\n",
            "iteration\n",
            "400\n",
            "predicted expression\n",
            "[1, 27, 61, 47, 38, 24, 62, 4, 16, 47, 40, 61, 8, 62, 2]\n",
            "ground truth expression\n",
            "[1, 27, 61, 47, 38, 24, 62, 4, 16, 47, 40, 61, 8, 62, 2]\n",
            "current accuracy 100\n",
            "current ave accuracy 89\n",
            "min accuracy in batch 11\n",
            "max accuracy in batch 100\n",
            "number of perfect predictions 298\n",
            "iteration\n",
            "420\n",
            "predicted expression\n",
            "[1, 61, 61, 62, 62, 61, 9, 55, 0, 0, 0, 0, 0, 0, 2]\n",
            "ground truth expression\n",
            "[1, 27, 61, 55, 38, 24, 62, 23, 61, 9, 62, 61, 9, 62, 2]\n",
            "current accuracy 20\n",
            "current ave accuracy 88\n",
            "min accuracy in batch 17\n",
            "max accuracy in batch 100\n",
            "number of perfect predictions 309\n",
            "iteration\n",
            "440\n",
            "predicted expression\n",
            "[1, 27, 61, 47, 38, 24, 62, 26, 47, 4, 15, 32, 3, 47, 2]\n",
            "ground truth expression\n",
            "[1, 27, 61, 47, 38, 24, 62, 26, 47, 4, 15, 32, 3, 47, 2]\n",
            "current accuracy 100\n",
            "current ave accuracy 88\n",
            "min accuracy in batch 15\n",
            "max accuracy in batch 100\n",
            "number of perfect predictions 323\n",
            "iteration\n",
            "460\n",
            "predicted expression\n",
            "[1, 28, 61, 43, 62, 17, 23, 61, 27, 61, 53, 38, 30, 6, 12, 40, 61, 4, 62, 62, 4, 10, 20, 40, 61, 16, 62, 61, 53, 62, 62, 61, 27, 61, 53, 38, 30, 6, 13, 40, 61, 4, 62, 62, 13, 33, 40, 61, 10, 62, 61, 53, 62, 33, 61, 53, 62, 62, 2]\n",
            "ground truth expression\n",
            "[1, 28, 61, 43, 62, 17, 23, 61, 27, 61, 53, 38, 30, 6, 12, 40, 61, 4, 62, 62, 4, 10, 20, 40, 61, 16, 62, 61, 53, 62, 62, 61, 27, 61, 53, 38, 30, 6, 13, 40, 61, 4, 62, 62, 13, 33, 40, 61, 10, 62, 61, 53, 62, 33, 61, 53, 62, 62, 2]\n",
            "current accuracy 100\n",
            "current ave accuracy 88\n",
            "min accuracy in batch 13\n",
            "max accuracy in batch 100\n",
            "number of perfect predictions 335\n",
            "iteration\n",
            "480\n",
            "predicted expression\n",
            "[1, 27, 61, 56, 38, 10, 40, 61, 3, 62, 62, 23, 61, 56, 3, 13, 62, 61, 56, 40, 61, 7, 62, 25, 56, 4, 15, 31, 25, 56, 3, 9, 31, 62, 2]\n",
            "ground truth expression\n",
            "[1, 27, 61, 56, 38, 10, 40, 61, 3, 62, 62, 23, 61, 56, 3, 13, 62, 61, 56, 40, 61, 7, 62, 25, 56, 4, 15, 31, 25, 56, 3, 9, 31, 62, 2]\n",
            "current accuracy 100\n",
            "current ave accuracy 88\n",
            "min accuracy in batch 20\n",
            "max accuracy in batch 100\n",
            "number of perfect predictions 352\n",
            "iteration\n",
            "500\n",
            "predicted expression\n",
            "[1, 27, 61, 50, 38, 24, 62, 23, 61, 14, 50, 40, 61, 9, 62, 3, 50, 40, 61, 12, 62, 4, 10, 62, 61, 8, 50, 40, 61, 10, 62, 3, 10, 50, 40, 61, 16, 62, 62, 2]\n",
            "ground truth expression\n",
            "[1, 27, 61, 50, 38, 24, 62, 23, 61, 14, 50, 40, 61, 9, 62, 3, 50, 40, 61, 12, 62, 4, 10, 62, 61, 8, 50, 40, 61, 10, 62, 3, 10, 50, 40, 61, 16, 62, 62, 2]\n",
            "current accuracy 100\n",
            "current ave accuracy 88\n",
            "min accuracy in batch 9\n",
            "max accuracy in batch 100\n",
            "number of perfect predictions 367\n",
            "iteration\n",
            "520\n",
            "predicted expression\n",
            "[1, 27, 61, 55, 38, 11, 40, 61, 3, 62, 62, 23, 61, 55, 62, 61, 55, 34, 61, 55, 62, 62, 3, 9, 23, 61, 20, 61, 55, 62, 62, 61, 55, 34, 61, 55, 62, 62, 2]\n",
            "ground truth expression\n",
            "[1, 27, 61, 55, 38, 11, 40, 61, 3, 62, 62, 23, 61, 55, 62, 61, 55, 34, 61, 55, 62, 62, 3, 9, 23, 61, 20, 61, 55, 62, 62, 61, 55, 34, 61, 55, 62, 62, 2]\n",
            "current accuracy 100\n",
            "current ave accuracy 88\n",
            "min accuracy in batch 11\n",
            "max accuracy in batch 100\n",
            "number of perfect predictions 383\n",
            "iteration\n",
            "540\n",
            "predicted expression\n",
            "[1, 27, 61, 58, 38, 10, 40, 61, 3, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 58, 62, 25, 14, 3, 7, 34, 40, 61, 11, 62, 61, 58, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 58, 62, 25, 22, 61, 58, 62, 3, 58, 34, 40, 61, 8, 62, 61, 58, 62, 31, 62, 2]\n",
            "ground truth expression\n",
            "[1, 27, 61, 58, 38, 10, 40, 61, 3, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 58, 62, 25, 14, 3, 7, 34, 40, 61, 11, 62, 61, 58, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 58, 62, 25, 22, 61, 58, 62, 3, 58, 34, 40, 61, 8, 62, 61, 58, 62, 31, 62, 2]\n",
            "current accuracy 100\n",
            "current ave accuracy 88\n",
            "min accuracy in batch 16\n",
            "max accuracy in batch 100\n",
            "number of perfect predictions 398\n",
            "iteration\n",
            "560\n",
            "predicted expression\n",
            "[1, 27, 61, 52, 38, 30, 6, 15, 62, 23, 61, 20, 40, 61, 14, 62, 61, 52, 62, 3, 20, 40, 61, 11, 62, 61, 52, 62, 62, 61, 14, 62, 2]\n",
            "ground truth expression\n",
            "[1, 27, 61, 52, 38, 30, 6, 15, 62, 23, 61, 20, 40, 61, 14, 62, 61, 52, 62, 3, 20, 40, 61, 11, 62, 61, 52, 62, 62, 61, 14, 62, 2]\n",
            "current accuracy 100\n",
            "current ave accuracy 88\n",
            "min accuracy in batch 14\n",
            "max accuracy in batch 100\n",
            "number of perfect predictions 413\n",
            "iteration\n",
            "580\n",
            "predicted expression\n",
            "[1, 23, 61, 27, 61, 58, 38, 11, 62, 11, 13, 25, 34, 61, 25, 11, 58, 31, 62, 23, 61, 45, 62, 61, 45, 58, 62, 34, 61, 25, 9, 58, 31, 62, 3, 34, 61, 25, 13, 58, 31, 62, 23, 61, 45, 62, 61, 45, 58, 62, 20, 61, 25, 9, 58, 31, 62, 31, 62, 61, 27, 61, 58, 38, 13, 62, 14, 62, 2]\n",
            "ground truth expression\n",
            "[1, 23, 61, 27, 61, 58, 38, 11, 62, 11, 13, 25, 34, 61, 25, 11, 58, 31, 62, 23, 61, 45, 62, 61, 45, 58, 62, 34, 61, 25, 9, 58, 31, 62, 3, 34, 61, 25, 13, 58, 31, 62, 23, 61, 45, 62, 61, 45, 58, 62, 20, 61, 25, 9, 58, 31, 62, 31, 62, 61, 27, 61, 58, 38, 13, 62, 14, 62, 2]\n",
            "current accuracy 100\n",
            "current ave accuracy 88\n",
            "min accuracy in batch 20\n",
            "max accuracy in batch 100\n",
            "number of perfect predictions 426\n",
            "iteration\n",
            "600\n",
            "predicted expression\n",
            "[1, 27, 61, 58, 38, 11, 40, 61, 3, 62, 62, 20, 61, 58, 62, 35, 61, 23, 61, 58, 25, 8, 3, 4, 9, 58, 31, 62, 61, 58, 40, 61, 9, 62, 62, 62, 2]\n",
            "ground truth expression\n",
            "[1, 27, 61, 58, 38, 11, 40, 61, 3, 62, 62, 20, 61, 58, 62, 35, 61, 23, 61, 58, 25, 8, 3, 4, 58, 31, 62, 61, 58, 40, 61, 9, 62, 62, 62, 0, 2]\n",
            "current accuracy 72\n",
            "current ave accuracy 88\n",
            "min accuracy in batch 8\n",
            "max accuracy in batch 100\n",
            "number of perfect predictions 439\n",
            "iteration\n",
            "620\n",
            "predicted expression\n",
            "[1, 27, 61, 49, 38, 15, 62, 23, 61, 20, 61, 49, 62, 3, 15, 62, 61, 49, 62, 2]\n",
            "ground truth expression\n",
            "[1, 27, 61, 49, 38, 15, 62, 23, 61, 20, 61, 49, 62, 3, 15, 62, 61, 49, 62, 2]\n",
            "current accuracy 100\n",
            "current ave accuracy 88\n",
            "min accuracy in batch 23\n",
            "max accuracy in batch 100\n",
            "number of perfect predictions 455\n",
            "iteration\n",
            "640\n",
            "predicted expression\n",
            "[1, 27, 61, 49, 38, 10, 62, 23, 61, 10, 34, 61, 25, 14, 49, 31, 62, 62, 61, 49, 36, 61, 25, 11, 49, 31, 62, 62, 2]\n",
            "ground truth expression\n",
            "[1, 27, 61, 49, 38, 10, 62, 23, 61, 10, 34, 61, 25, 14, 49, 31, 62, 62, 61, 49, 36, 61, 25, 11, 49, 31, 62, 62, 2]\n",
            "current accuracy 100\n",
            "current ave accuracy 88\n",
            "min accuracy in batch 25\n",
            "max accuracy in batch 100\n",
            "number of perfect predictions 464\n",
            "iteration\n",
            "660\n",
            "predicted expression\n",
            "[1, 27, 61, 60, 38, 16, 40, 61, 3, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 60, 62, 25, 12, 3, 4, 9, 36, 40, 61, 7, 62, 61, 60, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 60, 62, 25, 36, 61, 60, 62, 3, 60, 20, 40, 61, 12, 62, 61, 60, 62, 31, 62, 2]\n",
            "ground truth expression\n",
            "[1, 27, 61, 60, 38, 16, 40, 61, 3, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 60, 62, 25, 12, 3, 4, 9, 36, 40, 61, 7, 62, 61, 60, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 60, 62, 25, 36, 61, 60, 62, 3, 60, 20, 40, 61, 12, 62, 61, 60, 62, 31, 62, 2]\n",
            "current accuracy 100\n",
            "current ave accuracy 88\n",
            "min accuracy in batch 22\n",
            "max accuracy in batch 100\n",
            "number of perfect predictions 478\n",
            "iteration\n",
            "680\n",
            "predicted expression\n",
            "[1, 27, 61, 47, 38, 23, 61, 30, 62, 61, 14, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 47, 62, 25, 20, 61, 47, 62, 3, 4, 15, 34, 61, 47, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 47, 62, 25, 47, 3, 4, 12, 23, 61, 30, 62, 61, 9, 62, 31, 62, 2]\n",
            "ground truth expression\n",
            "[1, 27, 61, 47, 38, 23, 61, 30, 62, 61, 14, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 47, 62, 25, 20, 61, 47, 62, 3, 4, 15, 34, 61, 47, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 47, 62, 25, 47, 3, 4, 12, 23, 61, 30, 62, 61, 9, 62, 31, 62, 2]\n",
            "current accuracy 100\n",
            "current ave accuracy 88\n",
            "min accuracy in batch 9\n",
            "max accuracy in batch 100\n",
            "number of perfect predictions 493\n",
            "iteration\n",
            "700\n",
            "predicted expression\n",
            "[1, 17, 23, 61, 27, 61, 44, 38, 30, 6, 9, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 44, 62, 33, 61, 44, 62, 62, 61, 27, 61, 44, 38, 30, 6, 10, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 44, 62, 4, 13, 36, 40, 61, 15, 62, 61, 44, 62, 62, 2]\n",
            "ground truth expression\n",
            "[1, 17, 23, 61, 27, 61, 44, 38, 30, 6, 9, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 44, 62, 33, 61, 44, 62, 62, 61, 27, 61, 44, 38, 30, 6, 10, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 44, 62, 4, 13, 36, 40, 61, 15, 62, 61, 44, 62, 62, 2]\n",
            "current accuracy 100\n",
            "current ave accuracy 87\n",
            "min accuracy in batch 15\n",
            "max accuracy in batch 100\n",
            "number of perfect predictions 507\n",
            "iteration\n",
            "720\n",
            "predicted expression\n",
            "[1, 27, 61, 52, 38, 23, 61, 30, 62, 61, 14, 62, 62, 23, 61, 22, 61, 52, 62, 3, 4, 10, 21, 61, 52, 62, 62, 61, 52, 3, 4, 10, 23, 61, 30, 62, 61, 16, 62, 62, 2]\n",
            "ground truth expression\n",
            "[1, 27, 61, 52, 38, 23, 61, 30, 62, 61, 14, 62, 62, 23, 61, 22, 61, 52, 62, 3, 4, 10, 21, 61, 52, 62, 62, 61, 52, 3, 4, 10, 23, 61, 30, 62, 61, 16, 62, 62, 2]\n",
            "current accuracy 100\n",
            "current ave accuracy 88\n",
            "min accuracy in batch 50\n",
            "max accuracy in batch 100\n",
            "number of perfect predictions 521\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-d6a6a3c68b9f>\u001b[0m in \u001b[0;36m<cell line: 217>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0mpin_memory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m )\n\u001b[0;32m--> 217\u001b[0;31m \u001b[0maccs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_create_expression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_train_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-80-d6a6a3c68b9f>\u001b[0m in \u001b[0;36mevaluate_create_expression\u001b[0;34m(model, data_loader)\u001b[0m\n\u001b[1;32m    164\u001b[0m           \u001b[0mlabel_sos_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m63\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m           \u001b[0mlabel_eos_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m63\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m           \u001b[0mpredicted_expression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_expression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel_sos_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel_eos_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_expression\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoded_trg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-80-d6a6a3c68b9f>\u001b[0m in \u001b[0;36mcreate_expression\u001b[0;34m(input_seq, max_expression_length, model, label_eos_token, label_sos_token)\u001b[0m\n\u001b[1;32m    124\u001b[0m       \u001b[0mtop1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m       \u001b[0;31m# top1 ,cnt_chars = update_char_cnt(output, possible_chars, cnt_chars, top1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m       one_hot_encoded_top1 = torch.tensor([\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtop1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-80-d6a6a3c68b9f>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    125\u001b[0m       \u001b[0;31m# top1 ,cnt_chars = update_char_cnt(output, possible_chars, cnt_chars, top1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m       one_hot_encoded_top1 = torch.tensor([\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtop1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m63\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 4: CRNN End-to-End Equation Generation"
      ],
      "metadata": {
        "id": "6sHTHQObIAEV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from PIL import Image\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils import rnn\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import io\n",
        "import os"
      ],
      "metadata": {
        "id": "Q48Dcjz_Pm8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def upload_state_dict_to_drive(file_name):\n",
        "  file_metadata = {\"name\": file_name}\n",
        "  chunksize = 4000\n",
        "  media = MediaFileUpload(file_name, mimetype=\"application/zip\", resumable=True)\n",
        "  uploaded_file = drive_service.files().create(body=file_metadata, media_body=media, fields='id').execute()\n",
        "def save_state_dict(model, file_name):\n",
        "  torch.save(model.state_dict(), file_name)"
      ],
      "metadata": {
        "id": "YQK53AcWb3jS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sequence_inputs(input_json_file):\n",
        "    \"\"\"\n",
        "    for each image, create a file listing the coordinates of bounding boxes of latex chars of the image\n",
        "    \"\"\"\n",
        "    data = []\n",
        "    with open(f\"{input_json_file}\", 'r') as f:\n",
        "        data = json.load(f)\n",
        "    data = list(data)\n",
        "    data.sort(key = lambda x: x[\"uuid\"])\n",
        "    sequence_input_dict = {}\n",
        "    for d in data:\n",
        "        # get output file name\n",
        "        file_name = f\"{d['uuid']}.jpg\"\n",
        "        # extract coordinates from each item in json array\n",
        "        xmins = d[\"image_data\"][\"xmins\"]\n",
        "        ymins = d[\"image_data\"][\"ymins\"]\n",
        "        xmaxs = d[\"image_data\"][\"xmaxs\"]\n",
        "        ymaxs = d[\"image_data\"][\"ymaxs\"]\n",
        "        latex_char_labels = encode_char_list(d[\"image_data\"][\"visible_latex_chars\"],visible_char_encoding)\n",
        "        # make list of bounding box coordinates for each LaTeX character\n",
        "        sequence_input_dict[file_name] = [[latex_char,xmin,ymin,xmax,ymax]\n",
        "                             for latex_char,xmin,ymin,xmax,ymax in zip(latex_char_labels,xmins, ymins, xmaxs, ymaxs)]\n",
        "    return sequence_input_dict\n",
        "def create_sequence_outputs(input_json_file):\n",
        "    \"\"\"\n",
        "    for each image, create a file listing the coordinates of bounding boxes of latex chars of the image\n",
        "    \"\"\"\n",
        "    data = []\n",
        "    with open(f\"{input_json_file}\", 'r') as f:\n",
        "        data = json.load(f)\n",
        "    data = list(data)\n",
        "    data.sort(key = lambda x: x[\"uuid\"])\n",
        "    sequence_label_dict = {}\n",
        "    for d in data:\n",
        "        # get output file name\n",
        "        file_name = f\"{d['uuid']}.jpg\"\n",
        "        # extract coordinates from each item in json array\n",
        "        latex_char_labels = encode_char_list(d[\"image_data\"][\"full_latex_chars\"],full_char_encoding)\n",
        "        # make list of bounding box coordinates for each LaTeX character\n",
        "        sequence_label_dict[file_name] = latex_char_labels\n",
        "    return sequence_label_dict\n",
        "def sort_inputs_by_position(encoded_inputs):\n",
        "  # coord_tuples = []\n",
        "  # for i in range(len(input_labels)):\n",
        "  #   coord_tuples.append((input_labels[i],encoded_positions[i][0],encoded_positions[i][1]))\n",
        "  encoded_inputs.sort(key = lambda x: (x[54],x[55],x[56],x[57]))"
      ],
      "metadata": {
        "id": "vRU4IpuQb6-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_start_end_tokens(encoded_labels):\n",
        "  # append one hot encoded sos and eos tokens\n",
        "  # label_sos_token = [0,1,0,0.....]\n",
        "  # label_eos_token = [0,0,1,0.....]\n",
        "  label_sos_token = [1 if i == 1\n",
        "                      else 0\n",
        "                      for i in range(63)]\n",
        "  label_eos_token = [1 if i == 2\n",
        "                      else 0\n",
        "                      for i in range(63)]\n",
        "  encoded_labels.insert(0,label_sos_token)\n",
        "  encoded_labels.append(label_eos_token)\n",
        "  return encoded_labels"
      ],
      "metadata": {
        "id": "8WGz1-REOLdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CRNNDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset object for a single batch in the dataset\n",
        "    \"\"\"\n",
        "    def __init__(self, batch_number, starting_index = 0, length = 800):\n",
        "        self.batch_dir = f\"raw_train_data/batch_{str(batch_number)}/background_images\"\n",
        "        self.file_names = sorted([filename\n",
        "                                  for dirname, _, filenames in os.walk(self.batch_dir)\n",
        "                                  for i,filename in enumerate(filenames)\n",
        "                                  if i - starting_index < length\n",
        "                                  and i >= starting_index])\n",
        "        self.no_of_files = len(self.file_names)\n",
        "\n",
        "        training_label_file_name = f\"raw_train_data/batch_{str(batch_number)}/JSON/kaggle_data_{str(batch_number)}.json\"\n",
        "\n",
        "        self.sequence_label_dict = create_sequence_outputs(training_label_file_name)\n",
        "        self.char_set,self.char_dict = create_full_char_labels(training_label_file_name)\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        each item is a tuple of (image: Tensor, target:dict:{boxes:list[list[int]],labels:list[int]} )\n",
        "        \"\"\"\n",
        "        file_name = self.file_names[idx]\n",
        "        image = Image.open(f\"{self.batch_dir}/{file_name}\") # open colour image\n",
        "        binary_image = convert_image_to_binary(image, thresh = 127) # convert colour image to black and white image\n",
        "        # preprocessing for the binary_image object\n",
        "        process = transforms.Compose([\n",
        "                                transforms.PILToTensor(), # convert it to a tensor\n",
        "                                transforms.Resize((640,640),antialias = True) # convert it to 600 x 600\n",
        "                                ])\n",
        "\n",
        "        # apply preprocessing to the binary_image\n",
        "        final_image = process(binary_image).float()\n",
        "        # final_image = final_image.to(device)\n",
        "        encoded_labels = []\n",
        "        for label in self.sequence_label_dict[file_name]:\n",
        "          # one hot encode each label, starting from i = 2, so we can use i = 0 as sos token and i = 1 as eos token\n",
        "          one_hot_encoding = [ 1\n",
        "                              if label + 3 == i and i >= 3\n",
        "                              else 0\n",
        "                              for i in range(63)]\n",
        "          encoded_labels.append(one_hot_encoding)\n",
        "        # create target object for training\n",
        "        target = encoded_labels\n",
        "        # return final_image,target\n",
        "        item = {\n",
        "            \"image\":final_image,\n",
        "            \"target\":target\n",
        "        }\n",
        "        return item\n",
        "    def __len__(self):\n",
        "        return self.no_of_files"
      ],
      "metadata": {
        "id": "KoBWC7wg9sQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install einops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJBkUv7_FnvJ",
        "outputId": "c890a1ef-499f-42b7-d168-1a1d0b909325"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting einops\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_trg_with_pred(trg,pred,print_output = False):\n",
        "\n",
        "  if print_output is False:\n",
        "    return\n",
        "  trg_copy = trg.transpose(0,1)\n",
        "  decoded_trg = []\n",
        "  trg_ls = trg_copy.tolist()\n",
        "  for ls in trg_ls[0]:\n",
        "    for i,l in enumerate(ls):\n",
        "      if l == 1.0:\n",
        "        decoded_trg.append(i)\n",
        "        break\n",
        "  decoded_trg = [i for i in decoded_trg if i != 0]\n",
        "  pred = [i for i in pred if i != 0]\n",
        "  print('trg',decoded_trg)\n",
        "  print('pred',pred)"
      ],
      "metadata": {
        "id": "Gf2QzQ8aIf0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from einops import rearrange, repeat\n",
        "from einops.layers.torch import Rearrange\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.cnn = nn.Sequential(\n",
        "          nn.Conv2d(1, 64,kernel_size = 4, stride = 2, padding = 1),\n",
        "          nn.BatchNorm2d(64),\n",
        "          nn.ReLU(),\n",
        "          nn.MaxPool2d((2,2)),\n",
        "          nn.Conv2d(64, 128, kernel_size = 4, stride = 2, padding = 1),\n",
        "          nn.BatchNorm2d(128),\n",
        "          nn.ReLU(),\n",
        "          nn.MaxPool2d((2,2)),\n",
        "          nn.Conv2d(128, 256, kernel_size = 4, stride = 2, padding = 1),\n",
        "          nn.BatchNorm2d(256),\n",
        "          nn.ReLU(),\n",
        "          nn.MaxPool2d((2,2)),\n",
        "          nn.Conv2d(256, 512, kernel_size = 4, stride = 2, padding = 1),\n",
        "          nn.BatchNorm2d(512),\n",
        "          nn.ReLU(),\n",
        "          nn.MaxPool2d((2,2)),\n",
        "          Rearrange('b c h w -> (h w) b c')\n",
        "        )\n",
        "        self.rnn = nn.LSTM(input_dim, hidden_dim, n_layers, dropout=dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src):\n",
        "        # src = [src length, batch size, input_dim]\n",
        "        self.dropout(src.float())\n",
        "\n",
        "        # print('src shape',src.shape)\n",
        "        src = self.cnn(src)\n",
        "        # print('src shape after conv',src.shape)\n",
        "        output, (hidden, cell) = self.rnn(src)\n",
        "        # print('outputs shape',output.shape)\n",
        "        # print('hidden shape',hidden.shape)\n",
        "        # print('cell shape', cell.shape)\n",
        "        # outputs = [src length, batch size, hidden dim * n directions]\n",
        "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
        "        # cell = [n layers * n directions, batch size, hidden dim]\n",
        "        # outputs are always from the top hidden layer\n",
        "        return hidden, cell\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, hidden_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        self.output_dim = output_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.rnn = nn.LSTM(output_dim, hidden_dim, n_layers, dropout=dropout)\n",
        "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input, hidden, cell):\n",
        "        # input = [batch size]\n",
        "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
        "        # cell = [n layers * n directions, batch size, hidden dim]\n",
        "        # n directions in the decoder will both always be 1, therefore:\n",
        "        # hidden = [n layers, batch size, hidden dim]\n",
        "        # context = [n layers, batch size, hidden dim]\n",
        "        # input = [1, batch size]\n",
        "        # embedded = self.dropout(self.embedding(input))\n",
        "        # embedded = [1, batch size, embedding dim]\n",
        "        # input = input[None,:,:]\n",
        "        self.dropout(input.float())\n",
        "        output, (hidden, cell) = self.rnn(input.float(), (hidden, cell))\n",
        "        # output = [seq length, batch size, hidden dim * n directions]\n",
        "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
        "        # cell = [n layers * n directions, batch size, hidden dim]\n",
        "        # seq length and n directions will always be 1 in this decoder, therefore:\n",
        "        # output = [1, batch size, hidden dim]\n",
        "        # hidden = [n layers, batch size, hidden dim]\n",
        "        # cell = [n layers, batch size, hidden dim]\n",
        "        prediction = self.fc_out(output.squeeze(0))\n",
        "        # prediction = [batch size, output dim]\n",
        "        return prediction, hidden, cell\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "        assert (\n",
        "            encoder.hidden_dim == decoder.hidden_dim\n",
        "        ), \"Hidden dimensions of encoder and decoder must be equal!\"\n",
        "        assert (\n",
        "            encoder.n_layers == decoder.n_layers\n",
        "        ), \"Encoder and decoder must have equal number of layers!\"\n",
        "\n",
        "    def forward(self, src, trg, print_output = False, teacher_forcing_ratio = 0):\n",
        "        # src = [src length, batch size]\n",
        "        # trg = [trg length, batch size]\n",
        "        # teacher_forcing_ratio is probability to use teacher forcing\n",
        "        # e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
        "        batch_size = trg.shape[1]\n",
        "        trg_length = trg.shape[0]\n",
        "        # tensor to store decoder outputs\n",
        "        outputs = torch.zeros(trg_length, batch_size, self.decoder.output_dim).to(self.device)\n",
        "        # last hidden state of the encoder is used as the initial hidden state of the decoder\n",
        "        hidden, cell = self.encoder(src)\n",
        "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
        "        # cell = [n layers * n directions, batch size, hidden dim]\n",
        "        # first input to the decoder is the <sos> tokens\n",
        "        input = trg[0,:]\n",
        "        input = input[None,:]\n",
        "        # input = [batch size]\n",
        "        pred = [[1 for i in range(10)]]\n",
        "        for t in range(1, trg_length):\n",
        "            # insert input token embedding, previous hidden and previous cell states\n",
        "            # receive output tensor (predictions) and new hidden and cell states\n",
        "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
        "            # output = [batch size, output dim]\n",
        "            # hidden = [n layers, batch size, hidden dim]\n",
        "            # cell = [n layers, batch size, hidden dim]\n",
        "            # place predictions in a tensor holding predictions for each token\n",
        "            outputs[t] = output\n",
        "            # decide if we are going to use teacher forcing or not\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            # get the highest predicted token from our predictions\n",
        "            top1 = output.argmax(1)\n",
        "            top1_vals = top1.tolist()\n",
        "            one_hot_encoded_top1 = torch.tensor([\n",
        "                [\n",
        "                  1 if i == val\n",
        "                  else 0\n",
        "                  for i in range(self.decoder.output_dim)\n",
        "              ] for val in top1_vals]\n",
        "            )\n",
        "            # if teacher forcing, use actual next token as next input\n",
        "            # if not, use predicted token\n",
        "            pred.append(top1_vals)\n",
        "            input = trg[t] if teacher_force else one_hot_encoded_top1\n",
        "            encoded_input = []\n",
        "            input = torch.tensor(input).float().to(device)\n",
        "            input = input[None,:]\n",
        "            # input = [batch size]\n",
        "        # print('pred',pred)\n",
        "        pred_0 = []\n",
        "        for i in range(len(pred)):\n",
        "          pred_0.append(pred[i][0])\n",
        "        compare_trg_with_pred(trg,pred_0,print_output)\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "byosivR0_Oji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# number of channels of convolution output\n",
        "input_dim = 512\n",
        "# 60 full latex char labels + 1 sos token + 1 eos token + 1 pad token= 63 total vocab size\n",
        "output_dim = 63\n",
        "# size of hidden state vector\n",
        "hidden_dim = 512\n",
        "# number of LSTM layers to produce hidden feature state\n",
        "n_layers = 2\n",
        "# dropout for regularization\n",
        "encoder_dropout = 0.2\n",
        "decoder_dropout = 0.2\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "encoder = Encoder(\n",
        "    input_dim,\n",
        "    hidden_dim,\n",
        "    n_layers,\n",
        "    encoder_dropout,\n",
        ")\n",
        "\n",
        "decoder = Decoder(\n",
        "    output_dim,\n",
        "    hidden_dim,\n",
        "    n_layers,\n",
        "    decoder_dropout,\n",
        ")\n",
        "\n",
        "model = Seq2Seq(encoder, decoder, device).to(device)\n",
        "# state_dict = torch.load(f\"crnn_params_batch_2_conv_512_lstm_layers_1_with_pad_epoch_4\")\n",
        "# model.load_state_dict(state_dict)"
      ],
      "metadata": {
        "id": "N35ju_ITEhU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "criterion = torch.nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "IdfomnvvzWoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_trg(batch_trg, max_trg_length, encoded_pad_char):\n",
        "  new_batch_trg = []\n",
        "  for trg in batch_trg:\n",
        "    new_trg = trg\n",
        "    while len(new_trg) < max_trg_length:\n",
        "      new_trg.append(encoded_pad_char)\n",
        "    new_trg = add_start_end_tokens(new_trg)\n",
        "    new_batch_trg.append(new_trg)\n",
        "  return new_batch_trg\n",
        "def collate_fn(batch):\n",
        "  encoded_pad_char = [1 if i == 0\n",
        "                   else 0\n",
        "                   for i in range(63)]\n",
        "  batch_src = [item[\"image\"] for item in batch]\n",
        "  batch_trg = [item[\"target\"] for item in batch]\n",
        "  max_trg_length = len(max(batch_trg, key = lambda t: len(t)))\n",
        "  batch_trg = pad_trg(batch_trg, max_trg_length, encoded_pad_char)\n",
        "\n",
        "  batch_src = torch.stack(batch_src,dim=0)\n",
        "  batch_trg = torch.tensor(batch_trg)\n",
        "\n",
        "  return batch_src,batch_trg\n",
        "# def collate_fn(batch):\n",
        "#   return batch\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "I1AhghudPiCX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crnn_train_dataset = CRNNDataset(batch_number = 2, starting_index = 0, length = 10000)\n",
        "crnn_valid_dataset = CRNNDataset(batch_number = 3, starting_index = 0, length = 2000)\n",
        "crnn_test_dataset = CRNNDataset(batch_number = 4, starting_index = 0, length = 2000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vdw3gaOxGKj3",
        "outputId": "fcfa307c-8733-4ec2-c0c3-25e603694444"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "create_char_labels 10000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 10000/10000 [00:00<00:00, 83057.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "create_char_labels 10000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 10000/10000 [00:00<00:00, 173164.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "create_char_labels 10000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 10000/10000 [00:00<00:00, 118460.74it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "crnn_train_dl = torch.utils.data.DataLoader(\n",
        "    crnn_train_dataset,\n",
        "    batch_size = 20,\n",
        "    shuffle = True,\n",
        "    collate_fn = collate_fn,\n",
        "    pin_memory = True if torch.cuda.is_available() else False\n",
        ")\n",
        "crnn_valid_dl = torch.utils.data.DataLoader(\n",
        "    crnn_valid_dataset,\n",
        "    batch_size = 20,\n",
        "    shuffle = True,\n",
        "    collate_fn = collate_fn,\n",
        "    pin_memory = True if torch.cuda.is_available() else False\n",
        ")\n",
        "crnn_test_dl = torch.utils.data.DataLoader(\n",
        "    crnn_test_dataset,\n",
        "    batch_size = 20,\n",
        "    shuffle = True,\n",
        "    collate_fn = collate_fn,\n",
        "    pin_memory = True if torch.cuda.is_available() else False\n",
        ")"
      ],
      "metadata": {
        "id": "zA0hbTyBco6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
        "model.apply(init_weights)"
      ],
      "metadata": {
        "id": "ERtvdxS8F9Gf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d16013cb-bd1a-4f38-c737-87db4f7bf45c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (cnn): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU()\n",
              "      (3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "      (4): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "      (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (6): ReLU()\n",
              "      (7): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "      (8): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "      (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (10): ReLU()\n",
              "      (11): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "      (12): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "      (13): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (14): ReLU()\n",
              "      (15): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "      (16): Rearrange('b c h w -> (h w) b c')\n",
              "    )\n",
              "    (rnn): LSTM(512, 512, num_layers=2, dropout=0.2)\n",
              "    (dropout): Dropout(p=0.2, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (rnn): LSTM(63, 512, num_layers=2, dropout=0.2)\n",
              "    (fc_out): Linear(in_features=512, out_features=63, bias=True)\n",
              "    (dropout): Dropout(p=0.2, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### Trtrging to add eos tokens ###\n",
        "def crnn_train_fn(\n",
        "    model, data_loader, optimizer, criterion, clip, teacher_forcing_ratio, device\n",
        "):\n",
        "  model.train()\n",
        "  model.to(device)\n",
        "  epoch_loss = 0\n",
        "  batch_loss = 0\n",
        "  current_loss = 0\n",
        "  for i, (src,trg) in enumerate(data_loader):\n",
        "    optimizer.zero_grad()\n",
        "    src,trg = src.to(device),trg.to(device)\n",
        "    # print(\"src shape, trg shape\", src.shape, trg.shape)\n",
        "    # src = [src length, batch size, input_dim]\n",
        "    # trg = [trg length, batch size, output_dim]\n",
        "    print_output = False\n",
        "    if i % 20 == 0 and i > 0:\n",
        "      print_output = True\n",
        "    trg = torch.transpose(trg,0,1)\n",
        "    output = model(src.float(), trg.float(), print_output, teacher_forcing_ratio)\n",
        "    # output = [trg length, batch size, output_dim]\n",
        "    output_dim = output.shape[-1]\n",
        "    output = output[1:]\n",
        "    # output = [(trg length - 1) * batch size, output_dim]\n",
        "    trg = trg[1:]\n",
        "    trg, output = trg.transpose(1,2), output.transpose(1,2)\n",
        "    # print(output.shape,trg.shape)\n",
        "    # trg = [(trg length - 1) * batch size]\n",
        "    loss = criterion(output.float(), trg.float())\n",
        "    # trg = [(trg length - 1) * batch size]\n",
        "    batch_loss += loss.item()\n",
        "    if print_output:\n",
        "      current_loss += batch_loss\n",
        "      print('iter',i)\n",
        "      print('batch loss',loss.item())\n",
        "      print('20 batch loss',batch_loss/20)\n",
        "      # print('current loss', current_loss /(20))\n",
        "      batch_loss = 0\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "    optimizer.step()\n",
        "    epoch_loss += loss.item()\n",
        "  return epoch_loss / len(data_loader)"
      ],
      "metadata": {
        "id": "OK3VtPiuF3lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def crnn_evaluate_fn(model, data_loader, criterion, teacher_forcing_ratio, device):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    batch_loss = 0\n",
        "    current_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for i, (src,trg)  in enumerate(data_loader):\n",
        "          src,trg = src.to(device),trg.to(device)\n",
        "          # print(\"src shape, trg shape\", src.shape, trg.shape)\n",
        "          # src = [src length, batch size, input_dim]\n",
        "          # trg = [trg length, batch size, output_dim]\n",
        "          print_output = False\n",
        "          if i % 20 == 0 and i > 0:\n",
        "            print_output = True\n",
        "          trg = torch.transpose(trg,0,1)\n",
        "          output = model(src.float(), trg.float(), print_output, teacher_forcing_ratio)\n",
        "          # output = [trg length, batch size, output_dim]\n",
        "          output = output[1:]\n",
        "          # output = [(trg length - 1) * batch size, output_dim]\n",
        "          trg = trg[1:]\n",
        "          trg, output = trg.transpose(1,2), output.transpose(1,2)\n",
        "          # trg = [(trg length - 1) * batch size]\n",
        "          loss = criterion(output.float(), trg.float())\n",
        "          # trg = [(trg length - 1) * batch size]\n",
        "          batch_loss += loss.item()\n",
        "          current_loss += loss.item()\n",
        "          if print_output:\n",
        "            print('iter',i)\n",
        "            print('batch loss',loss.item())\n",
        "            print('20 batch loss',batch_loss/20)\n",
        "            # print('current loss', current_loss /(5*i))\n",
        "            batch_loss = 0\n",
        "          epoch_loss += loss.item()\n",
        "    return epoch_loss / len(data_loader)"
      ],
      "metadata": {
        "id": "7SALKzz1GBJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "n_epochs = 10\n",
        "clip = 1.0\n",
        "teacher_forcing_ratio = 1.0\n",
        "\n",
        "best_valid_loss = float(\"inf\")\n",
        "for epoch in tqdm(range(1,n_epochs)):\n",
        "    train_loss = crnn_train_fn(\n",
        "        model,\n",
        "        crnn_train_dl,\n",
        "        optimizer,\n",
        "        criterion,\n",
        "        clip,\n",
        "        teacher_forcing_ratio = teacher_forcing_ratio,\n",
        "        device = device,\n",
        "    )\n",
        "\n",
        "    # save_state_dict(model,f\"crnn_params_batch_2_conv_512_lstm_layers_2_with_pad_epoch_{epoch}\")\n",
        "    # upload_state_dict_to_drive(f\"crnn_params_batch_2_conv_512_lstm_layers_2_with_pad_epoch_{epoch}\")\n",
        "\n",
        "    valid_loss = crnn_evaluate_fn(\n",
        "        model,\n",
        "        crnn_valid_dl,\n",
        "        criterion,\n",
        "        teacher_forcing_ratio = teacher_forcing_ratio,\n",
        "        device = device\n",
        "    )\n",
        "    test_loss = crnn_evaluate_fn(\n",
        "        model,\n",
        "        crnn_test_dl,\n",
        "        criterion,\n",
        "        teacher_forcing_ratio = 0,\n",
        "        device = device\n",
        "    )\n",
        "    print('\\n')\n",
        "    print(f\"\\tTrain Loss: {train_loss:7.3f} | Train PPL: {np.exp(train_loss):7.3f}\")\n",
        "    print(f\"\\tValid Loss: {valid_loss:7.3f} | Valid PPL: {np.exp(valid_loss):7.3f}\")\n",
        "    print(f\"\\tTest Loss: {test_loss:7.3f} | Test PPL: {np.exp(test_loss):7.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfsyTD_eGFcj",
        "outputId": "48da3bed-82ae-469f-b2cc-41735105d0ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/9 [00:00<?, ?it/s]<ipython-input-22-7777a0250bb4>:144: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  input = torch.tensor(input).float().to(device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trg [1, 27, 61, 52, 38, 24, 62, 23, 61, 4, 15, 25, 36, 61, 23, 61, 15, 62, 61, 52, 62, 62, 3, 4, 15, 23, 61, 16, 62, 61, 52, 62, 36, 61, 23, 61, 9, 62, 61, 52, 62, 62, 31, 62, 61, 4, 13, 52, 40, 61, 4, 10, 62, 62, 2]\n",
            "pred [1, 27, 61, 61, 38, 38, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 62, 62, 62, 62, 62, 61, 61, 61, 61, 61, 61, 61, 62, 61, 62, 62, 62, 62, 61]\n",
            "iter 20\n",
            "batch loss 1.614637017250061\n",
            "20 batch loss 2.3017165184021\n",
            "trg [1, 17, 27, 61, 57, 38, 24, 62, 23, 61, 13, 62, 61, 14, 62, 2]\n",
            "pred [1, 27, 61, 61, 38, 38, 62, 61, 61, 61, 61, 61, 61, 61, 62, 61, 61, 61]\n",
            "iter 40\n",
            "batch loss 1.7223601341247559\n",
            "20 batch loss 1.7315911412239076\n",
            "trg [1, 27, 61, 57, 38, 30, 6, 9, 62, 23, 61, 34, 40, 61, 12, 62, 61, 57, 62, 3, 34, 40, 61, 9, 62, 61, 57, 62, 62, 61, 16, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 38, 62, 62, 61, 61, 61, 61, 61, 61, 62, 62, 62, 62, 62, 61, 61, 61, 61, 62, 62, 62, 62, 62, 62, 61]\n",
            "iter 60\n",
            "batch loss 1.4944674968719482\n",
            "20 batch loss 1.6489934146404266\n",
            "trg [1, 27, 61, 48, 38, 23, 61, 30, 62, 61, 15, 62, 62, 23, 61, 20, 40, 61, 11, 62, 61, 48, 62, 3, 36, 40, 61, 12, 62, 61, 48, 62, 62, 61, 14, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 62, 62, 62, 62, 62, 61, 61, 61, 61, 61, 61, 62, 62, 62, 62, 62, 62, 61, 61, 61, 62, 62, 62, 62, 62, 62, 61, 61, 61]\n",
            "iter 80\n",
            "batch loss 1.4519460201263428\n",
            "20 batch loss 1.575281023979187\n",
            "trg [1, 27, 61, 53, 38, 30, 6, 13, 40, 61, 4, 62, 62, 34, 61, 53, 62, 3, 4, 13, 36, 61, 53, 62, 2]\n",
            "pred [1, 27, 61, 27, 38, 38, 62, 62, 62, 61, 62, 62, 62, 61, 61, 62, 62, 61, 61, 62, 61, 61, 61, 62, 61]\n",
            "iter 100\n",
            "batch loss 1.3458342552185059\n",
            "20 batch loss 1.4189969539642333\n",
            "trg [1, 27, 61, 57, 38, 23, 61, 30, 62, 61, 9, 62, 62, 23, 61, 15, 34, 40, 61, 12, 62, 61, 57, 62, 3, 10, 33, 40, 61, 12, 62, 61, 57, 62, 62, 61, 12, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 30, 61, 30, 62, 61, 62, 62, 62, 61, 61, 61, 62, 61, 61, 9, 62, 61, 58, 62, 62, 4, 62, 61, 61, 9, 62, 61, 58, 62, 62, 62]\n",
            "iter 120\n",
            "batch loss 1.0255545377731323\n",
            "20 batch loss 1.3665287375450135\n",
            "trg [1, 27, 61, 48, 38, 16, 62, 23, 61, 48, 4, 15, 62, 61, 48, 4, 16, 40, 61, 8, 62, 3, 4, 11, 25, 48, 4, 12, 31, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 23, 61, 9, 62, 62, 62, 61, 4, 62, 62, 62, 61, 9, 62, 62, 4, 62, 62, 62, 31, 62, 62, 62]\n",
            "iter 140\n",
            "batch loss 1.2181557416915894\n",
            "20 batch loss 1.173796758055687\n",
            "trg [1, 17, 23, 61, 27, 61, 57, 38, 15, 62, 23, 61, 45, 62, 61, 45, 57, 62, 11, 8, 22, 61, 25, 11, 57, 31, 62, 36, 61, 25, 13, 57, 31, 62, 62, 61, 27, 61, 57, 38, 14, 62, 23, 61, 45, 62, 61, 45, 57, 62, 9, 57, 62, 2]\n",
            "pred [1, 27, 61, 61, 27, 61, 30, 38, 30, 62, 23, 61, 9, 62, 61, 45, 62, 62, 62, 25, 62, 61, 25, 62, 31, 31, 62, 62, 61, 45, 62, 62, 31, 62, 62, 61, 29, 61, 45, 38, 62, 62, 23, 61, 45, 62, 61, 45, 62, 62, 62, 25, 62]\n",
            "iter 160\n",
            "batch loss 1.0423810482025146\n",
            "20 batch loss 1.0641751438379288\n",
            "trg [1, 27, 61, 44, 38, 24, 62, 23, 61, 10, 19, 11, 44, 62, 61, 8, 19, 10, 44, 3, 9, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 23, 61, 4, 62, 61, 62, 62, 61, 4, 62, 3, 62, 62, 62, 62]\n",
            "iter 180\n",
            "batch loss 0.9814010262489319\n",
            "20 batch loss 1.0443368136882782\n",
            "trg [1, 27, 61, 44, 38, 24, 62, 23, 61, 23, 61, 29, 41, 61, 10, 10, 62, 61, 44, 62, 62, 61, 29, 41, 61, 8, 12, 62, 61, 9, 62, 62, 62, 61, 23, 61, 29, 41, 61, 8, 7, 62, 61, 44, 62, 62, 61, 29, 41, 61, 15, 10, 62, 61, 9, 62, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 30, 62, 23, 61, 23, 61, 45, 61, 61, 45, 9, 62, 61, 57, 62, 62, 61, 29, 41, 61, 9, 62, 62, 61, 58, 62, 62, 29, 61, 29, 41, 61, 8, 9, 62, 61, 58, 62, 62, 29, 41, 61, 9, 9, 62, 61, 58, 62, 62]\n",
            "iter 200\n",
            "batch loss 1.10892915725708\n",
            "20 batch loss 1.011680194735527\n",
            "trg [1, 27, 61, 55, 38, 10, 40, 61, 4, 62, 62, 23, 61, 55, 25, 55, 4, 12, 31, 62, 61, 26, 55, 32, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 61, 3, 62, 62, 23, 61, 4, 62, 4, 40, 4, 62, 3, 61, 25, 40, 3, 62]\n",
            "iter 220\n",
            "batch loss 0.8191308379173279\n",
            "20 batch loss 0.932316455245018\n",
            "trg [1, 27, 61, 42, 38, 24, 62, 23, 61, 29, 41, 61, 14, 10, 62, 61, 42, 62, 62, 61, 29, 41, 61, 9, 7, 62, 61, 12, 62, 62, 23, 61, 29, 41, 61, 15, 9, 62, 61, 14, 62, 62, 61, 29, 41, 61, 14, 8, 62, 61, 42, 62, 62, 2]\n",
            "pred [1, 27, 61, 48, 38, 23, 62, 23, 61, 23, 41, 61, 9, 11, 62, 61, 58, 62, 62, 61, 29, 41, 61, 9, 9, 62, 61, 9, 62, 62, 61, 29, 41, 61, 9, 11, 62, 61, 58, 62, 62, 61, 29, 41, 61, 8, 9, 62, 61, 9, 62, 62, 62]\n",
            "iter 240\n",
            "batch loss 0.8683245778083801\n",
            "20 batch loss 0.889974394440651\n",
            "trg [1, 27, 61, 57, 38, 23, 61, 30, 62, 61, 12, 62, 40, 61, 4, 62, 62, 20, 61, 57, 62, 3, 4, 14, 34, 61, 57, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 23, 61, 30, 62, 61, 9, 62, 62, 61, 4, 62, 62, 23, 61, 58, 62, 3, 4, 10, 36, 61, 58, 62, 62]\n",
            "iter 260\n",
            "batch loss 0.8104230165481567\n",
            "20 batch loss 0.8061914473772049\n",
            "trg [1, 27, 61, 59, 38, 15, 62, 23, 61, 11, 34, 61, 25, 12, 59, 31, 62, 62, 61, 9, 59, 34, 61, 25, 15, 59, 31, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 9, 62, 23, 61, 45, 62, 61, 25, 10, 31, 31, 62, 62, 61, 25, 62, 62, 61, 25, 9, 31, 31, 62, 31, 61]\n",
            "iter 280\n",
            "batch loss 0.85903400182724\n",
            "20 batch loss 0.8202083468437195\n",
            "trg [1, 27, 61, 42, 38, 4, 14, 62, 23, 61, 12, 42, 40, 61, 8, 62, 3, 4, 42, 3, 16, 4, 11, 62, 61, 42, 3, 9, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 24, 62, 23, 61, 4, 62, 40, 61, 9, 62, 3, 4, 9, 62, 62, 62, 9, 62, 61, 9, 62, 4, 62]\n",
            "iter 300\n",
            "batch loss 0.6969024538993835\n",
            "20 batch loss 0.790343526005745\n",
            "trg [1, 27, 61, 58, 38, 4, 9, 40, 61, 4, 62, 62, 23, 61, 4, 58, 40, 61, 10, 62, 3, 16, 58, 40, 61, 12, 62, 3, 4, 9, 58, 62, 61, 4, 58, 40, 61, 7, 62, 3, 4, 9, 58, 40, 61, 12, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 24, 62, 61, 3, 62, 62, 23, 61, 4, 10, 36, 61, 9, 62, 3, 4, 40, 40, 61, 9, 62, 3, 9, 9, 36, 40, 9, 9, 3, 61, 9, 62, 3, 4, 9, 34, 40, 61, 9, 62, 3]\n",
            "iter 320\n",
            "batch loss 0.684281051158905\n",
            "20 batch loss 0.7375524312257766\n",
            "trg [1, 27, 61, 47, 38, 30, 6, 16, 62, 23, 61, 34, 40, 61, 10, 62, 61, 47, 62, 3, 33, 40, 61, 11, 62, 61, 47, 62, 62, 61, 16, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 30, 6, 9, 62, 23, 61, 36, 40, 61, 9, 62, 61, 58, 62, 3, 34, 40, 61, 9, 62, 61, 57, 62, 62, 61, 9, 62]\n",
            "iter 340\n",
            "batch loss 0.5550280213356018\n",
            "20 batch loss 0.6784877613186836\n",
            "trg [1, 27, 61, 49, 38, 10, 40, 61, 4, 62, 62, 23, 61, 49, 40, 61, 12, 62, 3, 4, 10, 49, 3, 11, 9, 62, 61, 49, 4, 8, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 61, 3, 62, 62, 23, 61, 23, 62, 61, 9, 62, 3, 4, 9, 20, 62, 62, 62, 62, 61, 58, 40, 9, 62]\n",
            "iter 360\n",
            "batch loss 0.6510514616966248\n",
            "20 batch loss 0.6953621238470078\n",
            "trg [1, 27, 61, 54, 38, 10, 62, 15, 34, 61, 54, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 4, 62, 23, 3, 61, 58, 62, 3]\n",
            "iter 380\n",
            "batch loss 0.5774784684181213\n",
            "20 batch loss 0.6996615320444107\n",
            "trg [1, 27, 61, 49, 38, 16, 62, 10, 3, 4, 14, 28, 49, 40, 61, 16, 62, 2]\n",
            "pred [1, 27, 61, 55, 38, 4, 40, 23, 3, 4, 9, 34, 61, 61, 9, 62, 3]\n",
            "iter 400\n",
            "batch loss 0.6400946974754333\n",
            "20 batch loss 0.6647847771644593\n",
            "trg [1, 27, 61, 56, 38, 13, 40, 61, 3, 62, 62, 23, 61, 4, 34, 61, 56, 62, 20, 40, 61, 14, 62, 61, 56, 62, 62, 61, 36, 40, 61, 11, 62, 61, 56, 62, 3, 25, 56, 34, 61, 56, 62, 3, 15, 31, 34, 40, 61, 15, 62, 61, 56, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 23, 40, 61, 3, 62, 62, 23, 61, 4, 9, 61, 59, 62, 36, 40, 61, 9, 62, 61, 59, 62, 62, 61, 34, 40, 61, 10, 62, 61, 58, 62, 3, 25, 9, 34, 61, 59, 62, 3, 9, 31, 20, 40, 61, 10, 62, 61, 59, 62, 62]\n",
            "iter 420\n",
            "batch loss 0.7411361336708069\n",
            "20 batch loss 0.6746635466814042\n",
            "trg [1, 27, 61, 52, 38, 14, 62, 23, 61, 52, 25, 52, 3, 13, 31, 62, 61, 52, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 23, 61, 46, 40, 58, 40, 4, 31, 62, 61, 58, 62]\n",
            "iter 440\n",
            "batch loss 0.7459000945091248\n",
            "20 batch loss 0.6627453029155731\n",
            "trg [1, 27, 61, 58, 38, 30, 62, 23, 61, 36, 40, 61, 10, 62, 61, 58, 62, 3, 10, 20, 61, 58, 62, 3, 12, 62, 61, 34, 61, 58, 62, 3, 16, 62, 2]\n",
            "pred [1, 27, 61, 48, 38, 23, 6, 23, 61, 23, 61, 61, 9, 62, 61, 58, 62, 3, 20, 36, 40, 25, 62, 62, 4, 62, 61, 23, 61, 25, 62, 3, 4, 31]\n",
            "iter 460\n",
            "batch loss 0.7217135429382324\n",
            "20 batch loss 0.6996088027954102\n",
            "trg [1, 27, 61, 59, 38, 23, 61, 30, 62, 61, 10, 62, 62, 23, 61, 15, 36, 61, 59, 62, 3, 4, 11, 20, 61, 59, 62, 62, 61, 9, 59, 3, 4, 13, 23, 61, 30, 62, 61, 15, 62, 62, 2]\n",
            "pred [1, 27, 61, 54, 38, 24, 61, 30, 62, 61, 9, 62, 62, 23, 61, 36, 34, 61, 57, 62, 3, 4, 10, 36, 61, 59, 62, 62, 61, 9, 3, 3, 4, 9, 23, 61, 30, 62, 61, 9, 62, 62]\n",
            "iter 480\n",
            "batch loss 0.7439578771591187\n",
            "20 batch loss 0.6644328653812408\n",
            "trg [1, 27, 61, 60, 38, 30, 6, 11, 62, 23, 61, 16, 62, 61, 20, 61, 60, 62, 3, 16, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 6, 15, 40, 23, 61, 34, 3, 61, 4, 61, 25, 62, 62, 4, 62, 61]\n",
            "iter 20\n",
            "batch loss 0.6472615003585815\n",
            "20 batch loss 0.7100388079881668\n",
            "trg [1, 27, 61, 52, 38, 30, 62, 23, 61, 25, 20, 61, 52, 62, 3, 16, 31, 25, 36, 61, 52, 62, 3, 9, 31, 62, 61, 34, 61, 52, 62, 3, 16, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 6, 23, 61, 34, 34, 61, 25, 62, 3, 4, 31, 25, 35, 61, 58, 62, 3, 4, 31, 25, 61, 35, 61, 58, 62, 3, 4, 62]\n",
            "iter 40\n",
            "batch loss 0.6299653649330139\n",
            "20 batch loss 0.6780015408992768\n",
            "trg [1, 27, 61, 51, 38, 4, 24, 62, 23, 61, 9, 62, 61, 51, 40, 61, 12, 10, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 24, 62, 23, 61, 9, 62, 61, 9, 40, 61, 9, 62, 62, 62]\n",
            "iter 60\n",
            "batch loss 0.664256751537323\n",
            "20 batch loss 0.6814146280288697\n",
            "trg [1, 27, 61, 58, 38, 4, 13, 62, 8, 25, 58, 4, 15, 31, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 24, 62, 23, 58, 58, 40, 9, 31, 25]\n",
            "iter 80\n",
            "batch loss 0.6619148850440979\n",
            "20 batch loss 0.6660811513662338\n",
            "trg [1, 27, 61, 56, 38, 4, 24, 62, 23, 61, 12, 62, 61, 56, 40, 61, 9, 62, 62, 2]\n",
            "pred [1, 27, 61, 59, 38, 24, 62, 23, 61, 29, 41, 61, 9, 9, 62, 61, 57, 62, 62, 61, 29, 41, 61, 8, 8, 62, 61, 9, 62, 62, 23, 61, 29, 41, 61, 9, 8, 62, 61, 9, 62, 62, 61, 29, 41, 61, 9, 9, 62, 61, 58, 62, 62]\n",
            "iter 20\n",
            "batch loss 4.791479110717773\n",
            "20 batch loss 5.486452829837799\n",
            "trg [1, 27, 61, 58, 38, 30, 6, 11, 62, 33, 40, 61, 12, 62, 61, 58, 62, 3, 36, 40, 61, 13, 62, 61, 58, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 30, 6, 9, 40, 61, 4, 62, 62, 36, 61, 58, 62, 3, 4, 9, 20, 61, 58, 62]\n",
            "iter 40\n",
            "batch loss 6.006986141204834\n",
            "20 batch loss 5.856331753730774\n",
            "trg [1, 27, 61, 58, 38, 30, 6, 11, 62, 20, 40, 61, 9, 62, 61, 58, 62, 3, 27, 61, 58, 38, 30, 6, 11, 62, 36, 40, 61, 10, 62, 61, 58, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 30, 6, 15, 40, 61, 4, 62, 62, 23, 61, 34, 61, 25, 9, 48, 31, 62, 62, 61, 34, 61, 25, 9, 48, 31, 62, 62]\n",
            "iter 60\n",
            "batch loss 7.2008843421936035\n",
            "20 batch loss 6.061420726776123\n",
            "trg [1, 23, 61, 27, 61, 58, 38, 14, 62, 13, 12, 25, 4, 14, 20, 40, 61, 9, 62, 61, 25, 10, 58, 31, 62, 3, 34, 40, 61, 12, 62, 61, 25, 12, 58, 31, 62, 31, 62, 61, 10, 62, 2]\n",
            "pred [1, 23, 61, 27, 61, 58, 38, 10, 62, 25, 9, 25, 58, 3, 4, 9, 31, 31, 62, 61, 25, 9, 58, 31, 62, 23, 61, 45, 62, 61, 45, 58, 62, 34, 61, 25, 9, 48, 31, 62, 31, 62, 61, 27, 61, 58, 38, 9, 62, 23, 61, 45, 62, 61, 45, 58, 62, 9, 62]\n",
            "iter 80\n",
            "batch loss 6.1521077156066895\n",
            "20 batch loss 5.943034195899964\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|         | 1/9 [07:01<56:11, 421.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\tTrain Loss:   1.016 | Train PPL:   2.761\n",
            "\tValid Loss:   0.674 | Valid PPL:   1.962\n",
            "\tTest Loss:   5.825 | Test PPL: 338.571\n",
            "trg [1, 27, 61, 47, 38, 8, 62, 23, 61, 12, 3, 4, 13, 34, 61, 47, 62, 62, 61, 47, 22, 61, 47, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 9, 62, 23, 61, 23, 62, 4, 9, 34, 61, 25, 62, 62, 61, 9, 40, 61, 58, 62, 62]\n",
            "iter 20\n",
            "batch loss 0.5604763031005859\n",
            "20 batch loss 0.6787390619516372\n",
            "trg [1, 27, 61, 59, 38, 4, 8, 40, 61, 3, 62, 62, 23, 61, 59, 40, 61, 15, 62, 3, 4, 14, 59, 40, 61, 9, 62, 3, 11, 59, 62, 61, 59, 40, 61, 14, 62, 3, 4, 9, 59, 40, 61, 15, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 9, 24, 62, 61, 3, 62, 62, 23, 61, 23, 40, 61, 10, 62, 3, 4, 10, 20, 40, 61, 9, 62, 62, 4, 57, 40, 4, 3, 61, 9, 62, 3, 4, 10, 59, 40, 61, 9, 62, 62]\n",
            "iter 40\n",
            "batch loss 0.6644503474235535\n",
            "20 batch loss 0.6742243781685829\n",
            "trg [1, 27, 61, 59, 38, 15, 62, 23, 61, 10, 62, 61, 36, 61, 25, 16, 59, 31, 62, 62, 21, 61, 25, 9, 59, 31, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 23, 61, 9, 62, 61, 35, 61, 58, 9, 54, 31, 62, 62, 61, 61, 9, 9, 59, 31, 62, 62]\n",
            "iter 60\n",
            "batch loss 0.6799575686454773\n",
            "20 batch loss 0.6296182796359062\n",
            "trg [1, 27, 61, 59, 38, 10, 62, 4, 59, 40, 61, 13, 62, 3, 59, 40, 61, 12, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 4, 40, 23, 9, 40, 61, 8, 62, 3, 4, 40, 61, 9, 62, 3]\n",
            "iter 80\n",
            "batch loss 0.5983275175094604\n",
            "20 batch loss 0.6121047154068947\n",
            "trg [1, 27, 61, 57, 38, 23, 61, 30, 62, 61, 9, 62, 62, 23, 61, 9, 20, 40, 61, 9, 62, 61, 57, 62, 3, 4, 9, 33, 40, 61, 14, 62, 61, 57, 62, 62, 61, 9, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 23, 61, 30, 62, 61, 9, 62, 62, 23, 61, 9, 36, 40, 61, 10, 62, 61, 58, 62, 3, 4, 10, 36, 40, 61, 9, 62, 61, 58, 62, 62, 61, 10, 62]\n",
            "iter 100\n",
            "batch loss 0.7172567248344421\n",
            "20 batch loss 0.6522640466690064\n",
            "trg [1, 27, 61, 48, 38, 24, 62, 23, 61, 10, 62, 61, 48, 40, 61, 9, 62, 62, 23, 61, 9, 62, 61, 48, 62, 3, 13, 23, 61, 14, 62, 61, 48, 40, 61, 4, 12, 62, 62, 20, 61, 23, 61, 15, 62, 61, 48, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 23, 61, 9, 62, 61, 35, 40, 61, 9, 62, 62, 4, 61, 9, 62, 61, 35, 62, 3, 4, 23, 61, 9, 62, 61, 58, 62, 61, 4, 9, 62, 62, 23, 61, 59, 61, 9, 62, 61, 58, 62, 62]\n",
            "iter 120\n",
            "batch loss 0.6141188740730286\n",
            "20 batch loss 0.6197005629539489\n",
            "trg [1, 27, 61, 58, 38, 12, 62, 23, 61, 13, 62, 61, 58, 3, 12, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 23, 61, 58, 3, 61, 58, 3, 9, 62]\n",
            "iter 140\n",
            "batch loss 0.5427590012550354\n",
            "20 batch loss 0.5794127836823464\n",
            "trg [1, 27, 61, 44, 38, 9, 40, 61, 3, 62, 62, 23, 61, 23, 61, 11, 62, 61, 44, 62, 62, 61, 4, 9, 36, 61, 44, 62, 20, 61, 44, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 40, 61, 3, 62, 62, 23, 61, 23, 61, 9, 62, 61, 37, 62, 62, 61, 4, 9, 34, 61, 48, 62, 34, 61, 48, 62, 62]\n",
            "iter 160\n",
            "batch loss 0.5638781785964966\n",
            "20 batch loss 0.5802760720252991\n",
            "trg [1, 27, 61, 48, 38, 4, 24, 62, 23, 61, 11, 62, 61, 48, 40, 61, 13, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 24, 62, 23, 61, 9, 62, 61, 9, 62, 61, 9, 62, 62]\n",
            "iter 180\n",
            "batch loss 0.7081685662269592\n",
            "20 batch loss 0.5973132729530335\n",
            "trg [1, 27, 61, 59, 38, 11, 40, 61, 3, 62, 62, 23, 61, 12, 6, 59, 62, 61, 4, 13, 34, 61, 59, 62, 36, 61, 59, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 9, 62, 61, 3, 62, 62, 23, 61, 23, 6, 57, 62, 61, 4, 9, 36, 61, 59, 62, 36, 61, 59, 62, 62]\n",
            "iter 200\n",
            "batch loss 0.6143370270729065\n",
            "20 batch loss 0.5805235341191292\n",
            "trg [1, 27, 61, 54, 38, 30, 6, 16, 62, 23, 61, 36, 61, 54, 62, 3, 4, 16, 36, 61, 54, 62, 62, 61, 54, 3, 4, 13, 30, 6, 11, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 6, 9, 62, 23, 61, 34, 61, 60, 62, 3, 4, 9, 36, 61, 60, 62, 62, 61, 9, 3, 4, 15, 23, 6, 9, 62]\n",
            "iter 220\n",
            "batch loss 0.5268246531486511\n",
            "20 batch loss 0.5788123637437821\n",
            "trg [1, 27, 61, 47, 38, 13, 40, 61, 3, 62, 62, 47, 3, 34, 47, 40, 61, 47, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 40, 61, 3, 62, 62, 4, 40, 9, 61, 40, 61, 9, 62]\n",
            "iter 240\n",
            "batch loss 0.593044102191925\n",
            "20 batch loss 0.5658711448311806\n",
            "trg [1, 27, 61, 47, 38, 37, 62, 23, 61, 47, 40, 61, 10, 62, 3, 4, 13, 37, 47, 3, 37, 40, 61, 11, 62, 62, 61, 47, 3, 4, 10, 37, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 23, 61, 23, 3, 61, 9, 62, 3, 4, 9, 54, 3, 40, 4, 40, 61, 9, 62, 62, 54, 40, 4, 9, 54, 62]\n",
            "iter 260\n",
            "batch loss 0.502626895904541\n",
            "20 batch loss 0.5408777624368668\n",
            "trg [1, 27, 61, 48, 38, 7, 40, 61, 3, 62, 62, 4, 23, 61, 23, 61, 45, 62, 61, 45, 48, 62, 34, 40, 61, 16, 62, 61, 48, 62, 62, 61, 23, 61, 45, 62, 61, 45, 48, 62, 48, 34, 61, 48, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 9, 62, 61, 3, 62, 62, 23, 9, 61, 23, 61, 45, 62, 61, 45, 58, 62, 25, 61, 61, 9, 62, 61, 58, 62, 62, 61, 23, 61, 45, 62, 61, 45, 48, 62, 48, 48, 61, 48, 62, 62]\n",
            "iter 280\n",
            "batch loss 0.6146182417869568\n",
            "20 batch loss 0.5563183724880219\n",
            "trg [1, 46, 40, 61, 27, 61, 55, 38, 15, 40, 61, 3, 62, 62, 23, 61, 23, 61, 9, 62, 61, 55, 3, 12, 62, 62, 61, 21, 61, 55, 62, 62, 62, 2]\n",
            "pred [1, 28, 40, 61, 27, 61, 48, 38, 24, 62, 61, 3, 62, 62, 23, 61, 23, 61, 45, 62, 61, 55, 62, 62, 62, 62, 61, 23, 61, 55, 62, 62, 61]\n",
            "iter 300\n",
            "batch loss 0.7442926168441772\n",
            "20 batch loss 0.5768522962927818\n",
            "trg [1, 27, 61, 43, 38, 12, 62, 23, 61, 23, 61, 45, 62, 61, 45, 43, 62, 25, 43, 28, 61, 43, 62, 3, 4, 10, 43, 3, 13, 31, 62, 61, 23, 61, 45, 62, 61, 45, 43, 62, 43, 28, 43, 40, 61, 11, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 23, 61, 23, 61, 45, 62, 61, 45, 47, 62, 25, 9, 3, 61, 25, 62, 3, 4, 14, 23, 40, 20, 31, 62, 61, 23, 61, 45, 62, 61, 45, 54, 62, 25, 40, 61, 40, 61, 9, 62, 3]\n",
            "iter 320\n",
            "batch loss 0.6382309794425964\n",
            "20 batch loss 0.5559102281928062\n",
            "trg [1, 27, 61, 51, 38, 9, 62, 23, 61, 36, 61, 10, 62, 51, 62, 61, 33, 61, 11, 62, 51, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 30, 40, 23, 61, 25, 61, 25, 62, 3, 62, 61, 36, 40, 54, 62, 62, 62]\n",
            "iter 340\n",
            "batch loss 0.5226326584815979\n",
            "20 batch loss 0.5178057134151459\n",
            "trg [1, 27, 61, 59, 38, 30, 6, 11, 62, 23, 61, 14, 34, 40, 61, 10, 62, 61, 59, 62, 3, 4, 10, 36, 40, 61, 15, 62, 61, 59, 62, 62, 61, 10, 62, 2]\n",
            "pred [1, 27, 61, 57, 38, 30, 6, 9, 62, 23, 61, 34, 34, 40, 61, 9, 62, 61, 59, 62, 3, 4, 9, 36, 40, 61, 9, 62, 61, 59, 62, 62, 61, 9, 62]\n",
            "iter 360\n",
            "batch loss 0.5203892588615417\n",
            "20 batch loss 0.5444905892014503\n",
            "trg [1, 27, 61, 48, 38, 4, 24, 62, 26, 48, 3, 7, 32, 3, 48, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 24, 62, 28, 57, 4, 8, 32, 3, 48]\n",
            "iter 380\n",
            "batch loss 0.572555422782898\n",
            "20 batch loss 0.5578173279762269\n",
            "trg [1, 27, 61, 48, 38, 30, 6, 10, 62, 23, 61, 36, 40, 61, 11, 62, 61, 48, 62, 3, 22, 40, 61, 9, 62, 61, 48, 62, 62, 61, 9, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 30, 6, 9, 62, 23, 61, 36, 40, 61, 9, 62, 61, 48, 62, 3, 20, 40, 61, 9, 62, 61, 48, 62, 62, 61, 9, 62]\n",
            "iter 400\n",
            "batch loss 0.593512773513794\n",
            "20 batch loss 0.5429539009928703\n",
            "trg [1, 27, 61, 37, 38, 4, 24, 62, 23, 61, 9, 62, 61, 9, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 24, 62, 23, 61, 9, 62, 61, 9, 62]\n",
            "iter 420\n",
            "batch loss 0.5679044723510742\n",
            "20 batch loss 0.5332573607563973\n",
            "trg [1, 27, 61, 54, 38, 11, 40, 61, 3, 62, 62, 23, 61, 16, 62, 61, 35, 61, 58, 62, 62, 3, 10, 23, 61, 16, 62, 61, 34, 61, 54, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 9, 40, 61, 3, 62, 62, 23, 61, 23, 6, 61, 35, 61, 58, 62, 62, 3, 4, 23, 61, 9, 62, 61, 34, 61, 58, 62, 62]\n",
            "iter 440\n",
            "batch loss 0.4799913167953491\n",
            "20 batch loss 0.5156396850943565\n",
            "trg [1, 27, 61, 58, 38, 24, 62, 4, 9, 58, 40, 61, 11, 62, 2]\n",
            "pred [1, 27, 61, 54, 38, 4, 62, 23, 9, 4, 40, 61, 8, 62]\n",
            "iter 460\n",
            "batch loss 0.5019916296005249\n",
            "20 batch loss 0.5275847911834717\n",
            "trg [1, 27, 61, 53, 38, 16, 40, 61, 3, 62, 62, 4, 11, 23, 61, 15, 36, 61, 53, 62, 36, 61, 53, 62, 62, 61, 34, 61, 53, 62, 3, 4, 9, 53, 33, 61, 53, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 9, 62, 61, 3, 62, 62, 23, 16, 23, 61, 23, 36, 61, 58, 62, 34, 61, 42, 62, 62, 61, 34, 61, 60, 62, 3, 4, 9, 42, 34, 61, 42, 62, 62]\n",
            "iter 480\n",
            "batch loss 0.46366289258003235\n",
            "20 batch loss 0.5194132909178734\n",
            "trg [1, 27, 61, 53, 38, 8, 40, 61, 3, 62, 62, 53, 40, 61, 36, 61, 53, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 4, 40, 61, 3, 62, 62, 46, 40, 61, 28, 61, 25, 62, 62]\n",
            "iter 20\n",
            "batch loss 0.5381605625152588\n",
            "20 batch loss 0.598308365046978\n",
            "trg [1, 27, 61, 37, 38, 24, 62, 23, 61, 23, 61, 45, 62, 61, 45, 37, 62, 28, 61, 37, 40, 61, 8, 7, 7, 62, 62, 62, 61, 23, 61, 45, 62, 61, 45, 37, 62, 35, 61, 58, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 23, 61, 29, 61, 45, 62, 61, 45, 59, 62, 25, 61, 25, 62, 61, 9, 62, 62, 62, 62, 61, 61, 23, 61, 45, 62, 61, 45, 37, 62, 25, 61, 59, 62, 62]\n",
            "iter 40\n",
            "batch loss 0.5047045946121216\n",
            "20 batch loss 0.5515382677316666\n",
            "trg [1, 17, 23, 61, 27, 61, 55, 38, 30, 6, 10, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 55, 62, 20, 61, 55, 62, 62, 61, 27, 61, 55, 38, 30, 6, 10, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 55, 62, 4, 16, 20, 40, 61, 10, 62, 61, 55, 62, 62, 2]\n",
            "pred [1, 23, 23, 61, 27, 61, 58, 38, 23, 6, 9, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 57, 62, 34, 61, 57, 62, 62, 61, 27, 61, 55, 38, 23, 6, 10, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 57, 62, 4, 9, 20, 40, 61, 9, 62, 61, 55, 62, 62, 2]\n",
            "iter 60\n",
            "batch loss 0.5817840695381165\n",
            "20 batch loss 0.5887441962957383\n",
            "trg [1, 27, 61, 44, 38, 4, 24, 62, 13, 44, 40, 61, 16, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 4, 24, 62, 23, 40, 61, 8, 62]\n",
            "iter 80\n",
            "batch loss 0.621985912322998\n",
            "20 batch loss 0.5672110065817833\n",
            "trg [1, 27, 61, 55, 38, 24, 62, 23, 61, 35, 61, 55, 40, 61, 12, 62, 4, 12, 62, 62, 61, 35, 61, 9, 55, 40, 61, 9, 62, 3, 4, 10, 55, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 23, 61, 23, 61, 45, 62, 61, 45, 58, 62, 25, 15, 58, 40, 61, 9, 62, 3, 4, 9, 58, 40, 61, 9, 62, 3, 4, 10, 58, 3, 4, 10, 23, 61, 9, 62, 61, 58, 62, 62, 61, 23, 61, 45, 62, 61, 45, 58, 62, 25, 58, 40, 61, 9, 62, 3]\n",
            "iter 20\n",
            "batch loss 5.393291473388672\n",
            "20 batch loss 5.069431304931641\n",
            "trg [1, 27, 61, 48, 38, 16, 40, 61, 3, 62, 62, 34, 61, 48, 62, 35, 61, 23, 61, 10, 3, 10, 48, 62, 61, 48, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 23, 61, 30, 62, 61, 9, 62, 62, 23, 61, 20, 61, 58, 62, 3, 4, 10, 20, 61, 58, 62, 62, 61, 58, 3, 4, 9, 23, 61, 30, 62, 61, 9, 62, 62]\n",
            "iter 40\n",
            "batch loss 4.9428887367248535\n",
            "20 batch loss 4.718344604969024\n",
            "trg [1, 27, 61, 58, 38, 24, 62, 35, 18, 10, 39, 61, 58, 40, 61, 8, 62, 3, 15, 58, 3, 14, 62, 3, 4, 15, 58, 2]\n",
            "pred [1, 27, 61, 58, 38, 9, 40, 61, 3, 62, 62, 23, 61, 58, 62, 61, 35, 61, 58, 62, 62, 3, 9, 23, 61, 9, 62, 61, 34, 61, 58, 62, 62]\n",
            "iter 60\n",
            "batch loss 4.012058734893799\n",
            "20 batch loss 4.999341356754303\n",
            "trg [1, 27, 61, 55, 38, 16, 40, 61, 3, 62, 62, 23, 61, 10, 3, 4, 15, 36, 40, 61, 10, 62, 61, 55, 62, 62, 61, 34, 61, 55, 62, 3, 55, 34, 40, 61, 10, 62, 61, 55, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 9, 40, 61, 3, 62, 62, 23, 61, 4, 15, 34, 61, 58, 62, 34, 40, 61, 8, 62, 61, 58, 62, 62, 61, 20, 40, 61, 8, 62, 61, 58, 62, 3, 25, 9, 58, 34, 61, 58, 62, 3, 9, 31, 36, 40, 61, 9, 62, 61, 58, 62, 62, 2, 2]\n",
            "iter 80\n",
            "batch loss 4.69589376449585\n",
            "20 batch loss 4.847835433483124\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|       | 2/9 [12:10<41:26, 355.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\tTrain Loss:   0.573 | Train PPL:   1.773\n",
            "\tValid Loss:   0.569 | Valid PPL:   1.766\n",
            "\tTest Loss:   4.850 | Test PPL: 127.734\n",
            "trg [1, 27, 61, 54, 38, 23, 61, 30, 62, 61, 10, 62, 62, 33, 40, 61, 16, 62, 61, 54, 62, 3, 20, 40, 61, 9, 62, 61, 54, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 23, 61, 30, 62, 61, 9, 62, 62, 23, 40, 61, 10, 62, 61, 54, 62, 3, 34, 40, 61, 11, 62, 61, 54, 62]\n",
            "iter 20\n",
            "batch loss 0.493679016828537\n",
            "20 batch loss 0.5053339600563049\n",
            "trg [1, 28, 61, 53, 62, 17, 23, 61, 27, 61, 54, 38, 13, 40, 61, 3, 62, 62, 23, 61, 45, 62, 61, 45, 54, 62, 26, 28, 61, 54, 62, 32, 62, 61, 27, 61, 54, 38, 13, 40, 61, 3, 62, 62, 23, 61, 45, 62, 61, 45, 54, 62, 11, 6, 54, 62, 2]\n",
            "pred [1, 28, 61, 57, 62, 17, 23, 61, 27, 61, 58, 38, 23, 40, 61, 3, 62, 62, 23, 61, 45, 62, 61, 45, 54, 62, 26, 28, 61, 54, 62, 32, 62, 61, 27, 61, 54, 38, 9, 40, 61, 3, 62, 62, 23, 61, 45, 62, 61, 45, 54, 62, 23, 6, 54, 62]\n",
            "iter 40\n",
            "batch loss 0.4641617238521576\n",
            "20 batch loss 0.5008790761232376\n",
            "trg [1, 27, 61, 48, 38, 30, 6, 9, 62, 35, 61, 34, 61, 48, 62, 62, 3, 14, 2]\n",
            "pred [1, 27, 61, 48, 38, 30, 6, 9, 62, 20, 40, 34, 40, 48, 62, 62, 3, 9]\n",
            "iter 60\n",
            "batch loss 0.5491836667060852\n",
            "20 batch loss 0.47486986219882965\n",
            "trg [1, 23, 61, 27, 61, 58, 38, 9, 62, 8, 11, 25, 14, 20, 40, 61, 12, 62, 61, 25, 9, 58, 31, 62, 3, 20, 40, 61, 10, 62, 61, 25, 9, 58, 31, 62, 31, 62, 61, 12, 62, 2]\n",
            "pred [1, 23, 61, 27, 61, 48, 38, 9, 62, 9, 9, 25, 34, 34, 40, 61, 14, 62, 61, 25, 9, 58, 31, 62, 3, 36, 40, 61, 9, 62, 61, 25, 9, 58, 31, 62, 31, 62, 61, 9, 62]\n",
            "iter 80\n",
            "batch loss 0.4015001952648163\n",
            "20 batch loss 0.4646031379699707\n",
            "trg [1, 27, 61, 58, 38, 23, 61, 30, 62, 61, 9, 62, 62, 23, 61, 11, 3, 20, 61, 9, 62, 58, 62, 61, 11, 3, 4, 15, 34, 61, 10, 62, 58, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 9, 61, 30, 62, 61, 9, 62, 62, 23, 61, 34, 3, 4, 61, 58, 62, 58, 62, 61, 4, 3, 4, 9, 34, 61, 58, 62, 62, 62]\n",
            "iter 100\n",
            "batch loss 0.3915506601333618\n",
            "20 batch loss 0.4972477898001671\n",
            "trg [1, 17, 27, 61, 47, 38, 23, 61, 30, 62, 61, 13, 62, 62, 23, 61, 20, 40, 61, 9, 62, 61, 47, 62, 3, 34, 40, 61, 15, 62, 61, 47, 62, 62, 61, 11, 62, 2]\n",
            "pred [1, 17, 27, 61, 58, 38, 23, 61, 30, 62, 61, 9, 62, 62, 23, 61, 34, 40, 61, 9, 62, 61, 47, 62, 3, 22, 40, 61, 9, 62, 61, 47, 62, 62, 61, 9, 62]\n",
            "iter 120\n",
            "batch loss 0.46344834566116333\n",
            "20 batch loss 0.4674989923834801\n",
            "trg [1, 27, 61, 50, 38, 30, 6, 15, 62, 20, 40, 61, 10, 62, 61, 50, 62, 3, 34, 40, 61, 9, 62, 61, 50, 62, 2]\n",
            "pred [1, 27, 61, 57, 38, 30, 6, 9, 62, 20, 40, 61, 9, 62, 61, 48, 62, 3, 20, 40, 61, 9, 62, 61, 50, 62]\n",
            "iter 140\n",
            "batch loss 0.5577805042266846\n",
            "20 batch loss 0.49766500294208527\n",
            "trg [1, 27, 61, 52, 38, 12, 40, 61, 3, 62, 62, 34, 61, 52, 62, 3, 4, 9, 15, 6, 52, 2]\n",
            "pred [1, 27, 61, 58, 38, 23, 40, 61, 3, 62, 62, 46, 40, 60, 62, 3, 4, 9, 23, 6, 42]\n",
            "iter 160\n",
            "batch loss 0.43341824412345886\n",
            "20 batch loss 0.47440454214811323\n",
            "trg [1, 27, 61, 59, 38, 9, 62, 23, 61, 59, 3, 15, 62, 61, 59, 4, 8, 40, 61, 8, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 23, 61, 23, 40, 25, 62, 61, 59, 40, 10, 62, 61, 9, 62, 62]\n",
            "iter 180\n",
            "batch loss 0.39727210998535156\n",
            "20 batch loss 0.460654716193676\n",
            "trg [1, 27, 61, 59, 38, 30, 6, 11, 62, 23, 61, 14, 34, 61, 59, 62, 3, 4, 13, 20, 61, 59, 62, 62, 61, 11, 59, 3, 4, 15, 30, 6, 16, 62, 2]\n",
            "pred [1, 17, 61, 48, 38, 30, 6, 14, 62, 23, 61, 34, 36, 61, 59, 62, 3, 4, 10, 36, 61, 59, 62, 62, 61, 59, 59, 3, 4, 9, 23, 6, 9, 62]\n",
            "iter 200\n",
            "batch loss 0.49215665459632874\n",
            "20 batch loss 0.4716010481119156\n",
            "trg [1, 27, 61, 54, 38, 9, 62, 23, 61, 54, 4, 9, 62, 61, 35, 61, 58, 62, 4, 15, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 23, 61, 54, 4, 9, 62, 61, 26, 61, 54, 4, 4, 9, 62]\n",
            "iter 220\n",
            "batch loss 0.4087041914463043\n",
            "20 batch loss 0.4721528798341751\n",
            "trg [1, 27, 61, 47, 38, 4, 8, 40, 61, 3, 62, 62, 35, 61, 47, 3, 9, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 24, 62, 61, 3, 62, 62, 47, 61, 47, 4, 8, 62, 3]\n",
            "iter 240\n",
            "batch loss 0.4521397650241852\n",
            "20 batch loss 0.47555051445961\n",
            "trg [1, 27, 61, 37, 38, 30, 62, 23, 61, 4, 23, 61, 45, 62, 61, 45, 37, 62, 36, 61, 37, 62, 62, 61, 23, 61, 45, 62, 61, 45, 37, 62, 25, 8, 37, 3, 4, 9, 30, 31, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 9, 62, 23, 61, 4, 34, 61, 45, 62, 61, 45, 37, 62, 34, 61, 37, 62, 62, 61, 23, 61, 45, 62, 61, 45, 37, 62, 37, 37, 37, 3, 4, 9, 30, 31, 62]\n",
            "iter 260\n",
            "batch loss 0.5366806387901306\n",
            "20 batch loss 0.4666930928826332\n",
            "trg [1, 28, 61, 57, 62, 17, 23, 61, 27, 61, 44, 38, 30, 6, 13, 40, 61, 4, 62, 62, 21, 61, 44, 62, 62, 61, 27, 61, 44, 38, 30, 6, 16, 40, 61, 4, 62, 62, 4, 16, 36, 40, 61, 14, 62, 61, 44, 62, 62, 2]\n",
            "pred [1, 28, 61, 58, 62, 17, 23, 61, 27, 61, 58, 38, 23, 6, 9, 40, 61, 4, 62, 62, 23, 61, 44, 62, 62, 61, 27, 61, 44, 38, 23, 6, 9, 40, 61, 4, 62, 62, 4, 10, 34, 40, 61, 10, 62, 61, 44, 62, 62]\n",
            "iter 280\n",
            "batch loss 0.4989171326160431\n",
            "20 batch loss 0.4639862850308418\n",
            "trg [1, 27, 61, 58, 38, 10, 40, 61, 4, 62, 62, 23, 61, 15, 62, 61, 35, 61, 58, 25, 58, 3, 8, 31, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 9, 62, 61, 4, 62, 62, 23, 61, 58, 62, 61, 58, 61, 58, 62, 58, 3, 9, 31, 62, 62]\n",
            "iter 300\n",
            "batch loss 0.46875157952308655\n",
            "20 batch loss 0.4302483469247818\n",
            "trg [1, 27, 61, 58, 38, 13, 62, 23, 61, 23, 61, 36, 61, 25, 12, 58, 31, 62, 62, 61, 36, 61, 25, 16, 58, 31, 62, 62, 62, 61, 58, 62, 2]\n",
            "pred [1, 27, 61, 59, 38, 24, 62, 23, 61, 36, 61, 45, 61, 25, 9, 58, 31, 62, 62, 61, 58, 61, 25, 9, 58, 31, 62, 62, 62, 61, 58, 62]\n",
            "iter 320\n",
            "batch loss 0.4713154733181\n",
            "20 batch loss 0.43032313585281373\n",
            "trg [1, 27, 61, 42, 38, 10, 62, 23, 61, 23, 61, 15, 20, 61, 25, 10, 42, 31, 62, 62, 61, 16, 42, 62, 20, 61, 25, 15, 42, 31, 62, 62, 61, 23, 61, 14, 36, 61, 25, 12, 42, 31, 62, 62, 61, 13, 42, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 23, 61, 23, 61, 29, 34, 61, 25, 9, 42, 31, 62, 62, 61, 42, 42, 62, 20, 61, 25, 9, 42, 31, 62, 62, 61, 23, 61, 25, 34, 61, 25, 16, 42, 31, 62, 62, 61, 42, 42, 62, 62]\n",
            "iter 340\n",
            "batch loss 0.46748462319374084\n",
            "20 batch loss 0.4431453451514244\n",
            "trg [1, 27, 61, 37, 38, 24, 62, 23, 61, 36, 61, 37, 62, 62, 61, 46, 40, 61, 37, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 23, 61, 4, 61, 37, 62, 62, 61, 37, 40, 61, 37, 62, 62]\n",
            "iter 360\n",
            "batch loss 0.3487786650657654\n",
            "20 batch loss 0.4373854324221611\n",
            "trg [1, 27, 61, 53, 38, 4, 24, 62, 23, 61, 9, 62, 61, 14, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 4, 24, 62, 23, 61, 9, 62, 61, 46, 62]\n",
            "iter 380\n",
            "batch loss 0.43451449275016785\n",
            "20 batch loss 0.44148973375558853\n",
            "trg [1, 27, 61, 56, 38, 30, 6, 11, 62, 23, 61, 9, 34, 40, 61, 16, 62, 61, 56, 62, 3, 12, 22, 40, 61, 13, 62, 61, 56, 62, 62, 61, 10, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 30, 6, 9, 62, 23, 61, 20, 20, 40, 61, 9, 62, 61, 56, 62, 3, 4, 34, 40, 61, 9, 62, 61, 56, 62, 62, 61, 9, 62]\n",
            "iter 400\n",
            "batch loss 0.4793831706047058\n",
            "20 batch loss 0.4342831790447235\n",
            "trg [1, 4, 14, 27, 61, 37, 38, 4, 24, 62, 28, 61, 26, 37, 40, 61, 9, 62, 3, 11, 32, 62, 2]\n",
            "pred [1, 17, 9, 27, 61, 58, 38, 4, 24, 62, 28, 61, 26, 37, 40, 61, 9, 62, 3, 9, 32, 62]\n",
            "iter 420\n",
            "batch loss 0.46393340826034546\n",
            "20 batch loss 0.42587649673223493\n",
            "trg [1, 27, 61, 48, 38, 13, 62, 23, 61, 20, 61, 25, 9, 48, 31, 62, 36, 61, 25, 9, 48, 31, 62, 10, 6, 13, 9, 6, 48, 62, 61, 20, 61, 25, 10, 48, 31, 62, 9, 6, 13, 10, 6, 48, 62, 2]\n",
            "pred [1, 27, 61, 57, 38, 24, 62, 23, 61, 25, 61, 48, 9, 48, 31, 62, 36, 61, 25, 9, 48, 31, 62, 23, 6, 9, 9, 6, 48, 62, 61, 34, 61, 25, 9, 48, 31, 62, 23, 6, 9, 9, 6, 48, 62]\n",
            "iter 440\n",
            "batch loss 0.43135127425193787\n",
            "20 batch loss 0.4427483767271042\n",
            "trg [1, 27, 61, 58, 38, 9, 40, 61, 4, 62, 62, 23, 61, 58, 62, 61, 26, 58, 3, 14, 32, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 4, 62, 61, 4, 62, 62, 23, 61, 58, 4, 61, 26, 58, 4, 9, 32, 62]\n",
            "iter 460\n",
            "batch loss 0.40753239393234253\n",
            "20 batch loss 0.4254908159375191\n",
            "trg [1, 27, 61, 48, 38, 30, 62, 23, 61, 4, 23, 61, 45, 62, 61, 45, 48, 62, 34, 61, 48, 62, 62, 61, 23, 61, 45, 62, 61, 45, 48, 62, 25, 9, 48, 3, 4, 11, 30, 31, 62, 2]\n",
            "pred [1, 27, 61, 59, 38, 24, 62, 23, 61, 4, 9, 61, 45, 62, 61, 45, 48, 62, 25, 61, 48, 62, 62, 61, 23, 61, 45, 62, 61, 45, 48, 62, 25, 13, 48, 3, 4, 16, 30, 31, 62]\n",
            "iter 480\n",
            "batch loss 0.4551599323749542\n",
            "20 batch loss 0.4402467146515846\n",
            "trg [1, 27, 61, 59, 38, 4, 24, 62, 23, 61, 13, 12, 62, 61, 10, 12, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 24, 62, 23, 61, 59, 59, 59, 61, 59, 62, 59]\n",
            "iter 20\n",
            "batch loss 0.5813328623771667\n",
            "20 batch loss 0.5487279027700425\n",
            "trg [1, 27, 61, 44, 38, 23, 61, 30, 62, 61, 12, 62, 62, 23, 61, 34, 61, 44, 62, 3, 4, 14, 22, 61, 44, 62, 62, 61, 44, 3, 4, 11, 23, 61, 30, 62, 61, 15, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 61, 30, 62, 61, 9, 62, 62, 23, 61, 10, 61, 44, 62, 3, 4, 10, 20, 61, 44, 62, 62, 61, 44, 3, 4, 9, 23, 61, 30, 62, 61, 9, 62, 62]\n",
            "iter 40\n",
            "batch loss 0.5473831295967102\n",
            "20 batch loss 0.5145357221364975\n",
            "trg [1, 27, 61, 44, 38, 14, 40, 61, 3, 62, 62, 23, 61, 25, 44, 4, 8, 31, 35, 61, 44, 40, 61, 15, 62, 4, 11, 62, 62, 61, 25, 44, 4, 8, 31, 25, 44, 3, 15, 31, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 61, 3, 62, 62, 23, 61, 4, 44, 4, 9, 31, 25, 61, 44, 3, 61, 9, 62, 3, 9, 62, 61, 61, 35, 44, 4, 9, 31, 25, 44, 3, 9, 31, 62]\n",
            "iter 60\n",
            "batch loss 0.6357962489128113\n",
            "20 batch loss 0.5305079698562623\n",
            "trg [1, 27, 61, 58, 38, 15, 62, 23, 61, 46, 40, 61, 58, 62, 3, 20, 61, 58, 62, 62, 61, 9, 8, 58, 40, 61, 8, 62, 3, 14, 10, 58, 3, 16, 10, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 23, 61, 23, 40, 61, 58, 62, 3, 4, 61, 58, 62, 62, 61, 9, 19, 58, 40, 61, 9, 62, 3, 9, 58, 58, 62, 9, 62, 62]\n",
            "iter 80\n",
            "batch loss 0.4768393635749817\n",
            "20 batch loss 0.5214877560734749\n",
            "trg [1, 27, 61, 54, 38, 10, 62, 23, 61, 23, 61, 12, 62, 61, 13, 3, 54, 62, 3, 4, 9, 23, 61, 14, 62, 61, 13, 62, 62, 61, 54, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 4, 24, 62, 23, 61, 9, 58, 40, 61, 9, 62, 3, 4, 9, 58, 40, 61, 9, 62, 3, 4, 10, 58, 62, 61, 4, 10, 58, 40, 61, 9, 62, 3, 4, 10, 58, 40, 61, 8, 62, 62]\n",
            "iter 20\n",
            "batch loss 5.379283428192139\n",
            "20 batch loss 6.320251727104187\n",
            "trg [1, 27, 61, 57, 38, 23, 61, 30, 62, 61, 12, 62, 62, 33, 40, 61, 9, 62, 61, 57, 62, 3, 36, 40, 61, 15, 62, 61, 57, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 23, 61, 30, 62, 61, 10, 62, 40, 61, 4, 62, 62, 36, 61, 58, 62, 3, 4, 10, 20, 61, 58, 62]\n",
            "iter 40\n",
            "batch loss 6.407397747039795\n",
            "20 batch loss 5.747027564048767\n",
            "trg [1, 27, 61, 49, 38, 8, 40, 61, 4, 62, 62, 23, 61, 26, 49, 4, 8, 32, 62, 61, 49, 40, 61, 9, 62, 3, 4, 11, 49, 3, 11, 8, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 4, 24, 62, 23, 61, 58, 40, 61, 9, 62, 3, 4, 9, 58, 3, 9, 62, 61, 35, 61, 58, 40, 61, 9, 62, 3, 4, 9, 58, 62, 62]\n",
            "iter 60\n",
            "batch loss 5.1901116371154785\n",
            "20 batch loss 5.845358395576477\n",
            "trg [1, 17, 23, 61, 27, 61, 58, 38, 23, 61, 30, 62, 61, 9, 62, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 58, 62, 20, 61, 58, 62, 62, 61, 27, 61, 58, 38, 23, 61, 30, 62, 61, 10, 62, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 58, 62, 4, 11, 36, 40, 61, 16, 62, 61, 58, 62, 62, 2]\n",
            "pred [1, 17, 23, 61, 27, 61, 58, 38, 30, 6, 9, 40, 61, 4, 62, 62, 20, 61, 58, 62, 62, 61, 27, 61, 58, 38, 30, 6, 9, 40, 61, 4, 62, 62, 4, 9, 20, 40, 61, 9, 62, 61, 58, 62, 62]\n",
            "iter 80\n",
            "batch loss 4.9979658126831055\n",
            "20 batch loss 6.001433205604553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|      | 3/9 [17:10<33:01, 330.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\tTrain Loss:   0.458 | Train PPL:   1.582\n",
            "\tValid Loss:   0.519 | Valid PPL:   1.681\n",
            "\tTest Loss:   5.929 | Test PPL: 375.713\n",
            "trg [1, 27, 61, 58, 38, 9, 40, 61, 3, 62, 62, 20, 61, 58, 62, 3, 7, 23, 61, 16, 62, 61, 58, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 23, 40, 61, 3, 62, 62, 58, 61, 58, 62, 3, 4, 23, 61, 15, 62, 61, 58, 62]\n",
            "iter 20\n",
            "batch loss 0.4137965440750122\n",
            "20 batch loss 0.41773948520421983\n",
            "trg [1, 27, 61, 58, 38, 24, 62, 23, 61, 10, 12, 58, 40, 61, 7, 62, 62, 61, 15, 26, 58, 40, 61, 8, 62, 32, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 23, 61, 58, 58, 58, 40, 61, 9, 62, 62, 61, 8, 26, 58, 40, 61, 10, 62, 32, 62]\n",
            "iter 40\n",
            "batch loss 0.4144754707813263\n",
            "20 batch loss 0.40635797530412676\n",
            "trg [1, 27, 61, 54, 38, 24, 62, 23, 61, 23, 61, 29, 41, 61, 11, 10, 62, 61, 54, 62, 62, 61, 29, 41, 61, 10, 8, 62, 61, 11, 62, 62, 62, 61, 23, 61, 29, 41, 61, 13, 16, 62, 61, 54, 62, 62, 61, 29, 41, 61, 15, 11, 62, 61, 13, 62, 62, 62, 2]\n",
            "pred [1, 27, 61, 59, 38, 24, 62, 23, 61, 23, 61, 29, 41, 61, 9, 7, 62, 61, 54, 62, 62, 61, 29, 41, 61, 8, 7, 62, 61, 9, 62, 62, 62, 61, 23, 61, 29, 41, 61, 8, 9, 62, 61, 54, 62, 62, 61, 29, 41, 61, 9, 9, 62, 61, 10, 62, 62, 62]\n",
            "iter 60\n",
            "batch loss 0.37779924273490906\n",
            "20 batch loss 0.4266848713159561\n",
            "trg [1, 27, 61, 60, 38, 12, 62, 23, 61, 34, 60, 40, 61, 10, 62, 62, 61, 60, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 9, 62, 23, 61, 60, 61, 25, 61, 25, 62, 62, 61, 60, 62]\n",
            "iter 80\n",
            "batch loss 0.4778342843055725\n",
            "20 batch loss 0.40742075741291045\n",
            "trg [1, 27, 61, 48, 38, 9, 40, 61, 3, 62, 62, 23, 61, 12, 6, 48, 62, 61, 4, 9, 22, 61, 48, 62, 34, 61, 48, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 9, 40, 61, 3, 62, 62, 23, 61, 23, 6, 48, 62, 61, 4, 9, 36, 61, 48, 62, 34, 61, 48, 62, 62]\n",
            "iter 100\n",
            "batch loss 0.40008723735809326\n",
            "20 batch loss 0.4111489444971085\n",
            "trg [1, 27, 61, 60, 38, 23, 61, 30, 62, 61, 13, 62, 40, 61, 4, 62, 62, 36, 61, 60, 62, 3, 4, 10, 36, 61, 60, 62, 2]\n",
            "pred [1, 27, 61, 37, 38, 23, 61, 30, 62, 61, 9, 62, 40, 61, 4, 62, 62, 34, 61, 60, 62, 3, 4, 9, 34, 61, 60, 62]\n",
            "iter 120\n",
            "batch loss 0.37361517548561096\n",
            "20 batch loss 0.41216118931770324\n",
            "trg [1, 28, 61, 47, 62, 17, 23, 61, 27, 61, 58, 38, 30, 6, 11, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 58, 62, 34, 61, 58, 62, 62, 61, 27, 61, 58, 38, 30, 6, 12, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 58, 62, 4, 9, 34, 40, 61, 12, 62, 61, 58, 62, 62, 2]\n",
            "pred [1, 28, 61, 58, 62, 17, 23, 61, 27, 61, 47, 38, 23, 6, 10, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 58, 62, 36, 61, 58, 62, 62, 61, 27, 61, 58, 38, 30, 6, 10, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 58, 62, 4, 11, 34, 40, 61, 9, 62, 61, 58, 62, 62, 2]\n",
            "iter 140\n",
            "batch loss 0.35968178510665894\n",
            "20 batch loss 0.4166003465652466\n",
            "trg [1, 17, 27, 61, 57, 38, 24, 62, 23, 61, 11, 57, 40, 61, 14, 62, 62, 61, 8, 26, 57, 40, 61, 10, 62, 32, 62, 2]\n",
            "pred [1, 17, 27, 61, 58, 38, 4, 62, 23, 61, 57, 62, 40, 61, 9, 62, 62, 61, 9, 26, 57, 40, 61, 9, 62, 32, 62]\n",
            "iter 160\n",
            "batch loss 0.36424002051353455\n",
            "20 batch loss 0.4055528983473778\n",
            "trg [1, 27, 61, 51, 38, 24, 62, 23, 61, 8, 51, 40, 61, 9, 62, 62, 61, 9, 26, 51, 40, 61, 13, 62, 32, 62, 2]\n",
            "pred [1, 27, 61, 48, 38, 24, 62, 23, 61, 51, 51, 40, 61, 9, 62, 62, 61, 8, 26, 51, 40, 61, 9, 62, 32, 62]\n",
            "iter 180\n",
            "batch loss 0.45136523246765137\n",
            "20 batch loss 0.40830984264612197\n",
            "trg [1, 27, 61, 47, 38, 24, 62, 23, 61, 23, 61, 29, 41, 61, 16, 10, 62, 61, 47, 62, 62, 61, 29, 41, 61, 15, 16, 62, 61, 8, 62, 62, 62, 61, 23, 61, 29, 41, 61, 8, 8, 62, 61, 47, 62, 62, 61, 29, 41, 61, 8, 14, 62, 61, 14, 62, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 23, 61, 23, 61, 29, 41, 61, 8, 62, 62, 61, 47, 62, 62, 61, 29, 41, 61, 8, 7, 62, 61, 8, 62, 62, 62, 61, 23, 61, 29, 41, 61, 8, 7, 62, 61, 47, 62, 62, 61, 29, 41, 61, 8, 9, 62, 61, 8, 62, 62, 62]\n",
            "iter 200\n",
            "batch loss 0.4125223457813263\n",
            "20 batch loss 0.43231329321861267\n",
            "trg [1, 27, 61, 49, 38, 8, 40, 61, 4, 62, 62, 4, 15, 25, 49, 3, 7, 31, 2]\n",
            "pred [1, 27, 61, 58, 38, 9, 62, 61, 3, 62, 62, 4, 8, 25, 49, 4, 8, 31]\n",
            "iter 220\n",
            "batch loss 0.39539843797683716\n",
            "20 batch loss 0.4173585459589958\n",
            "trg [1, 23, 61, 27, 61, 44, 38, 11, 62, 23, 61, 45, 62, 61, 45, 44, 62, 12, 8, 33, 61, 25, 16, 44, 31, 62, 20, 61, 25, 15, 44, 31, 62, 62, 61, 27, 61, 44, 38, 14, 62, 23, 61, 45, 62, 61, 45, 44, 62, 12, 44, 62, 2]\n",
            "pred [1, 23, 61, 27, 61, 58, 38, 9, 62, 23, 61, 45, 62, 61, 45, 44, 62, 9, 8, 34, 61, 25, 44, 44, 31, 62, 34, 61, 25, 44, 44, 31, 62, 62, 61, 27, 61, 44, 38, 9, 62, 23, 61, 45, 62, 61, 45, 44, 62, 44, 44, 62]\n",
            "iter 240\n",
            "batch loss 0.5033286213874817\n",
            "20 batch loss 0.4199033349752426\n",
            "trg [1, 27, 61, 49, 38, 30, 6, 11, 62, 23, 61, 36, 61, 49, 62, 62, 61, 12, 49, 3, 4, 16, 30, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 30, 6, 9, 40, 23, 61, 9, 61, 43, 62, 62, 61, 9, 43, 3, 4, 9, 30, 62]\n",
            "iter 260\n",
            "batch loss 0.3570709526538849\n",
            "20 batch loss 0.39965198934078217\n",
            "trg [1, 27, 61, 55, 38, 15, 62, 16, 23, 61, 34, 61, 25, 13, 55, 31, 62, 62, 61, 9, 55, 62, 23, 61, 15, 62, 61, 33, 61, 25, 14, 55, 31, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 23, 23, 61, 34, 61, 25, 10, 55, 31, 62, 62, 61, 10, 55, 62, 23, 61, 12, 62, 61, 55, 61, 25, 10, 55, 31, 62, 62, 62]\n",
            "iter 280\n",
            "batch loss 0.4752185344696045\n",
            "20 batch loss 0.41038861870765686\n",
            "trg [1, 27, 61, 59, 38, 16, 62, 28, 61, 23, 61, 7, 25, 35, 61, 59, 40, 61, 8, 62, 4, 16, 11, 62, 4, 10, 31, 62, 61, 7, 4, 9, 13, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 23, 61, 59, 61, 59, 62, 59, 61, 59, 40, 61, 9, 62, 3, 9, 59, 62, 62, 9, 31, 62, 61, 59, 4, 9, 59, 62]\n",
            "iter 300\n",
            "batch loss 0.4763365089893341\n",
            "20 batch loss 0.42617284059524535\n",
            "trg [1, 27, 61, 54, 38, 13, 62, 54, 23, 61, 10, 62, 61, 36, 61, 54, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 9, 40, 23, 23, 61, 9, 62, 61, 35, 61, 54, 62, 62]\n",
            "iter 320\n",
            "batch loss 0.4702766537666321\n",
            "20 batch loss 0.4178983554244041\n",
            "trg [1, 27, 61, 47, 38, 13, 62, 34, 40, 61, 23, 61, 11, 62, 61, 47, 40, 61, 11, 62, 62, 62, 47, 2]\n",
            "pred [1, 27, 61, 58, 38, 9, 40, 47, 61, 61, 9, 61, 9, 62, 61, 47, 62, 61, 9, 62, 62, 62, 47, 62]\n",
            "iter 340\n",
            "batch loss 0.34797656536102295\n",
            "20 batch loss 0.4278990805149078\n",
            "trg [1, 27, 61, 42, 38, 10, 40, 61, 3, 62, 62, 34, 40, 61, 33, 61, 25, 42, 31, 62, 62, 25, 42, 31, 2]\n",
            "pred [1, 27, 61, 55, 38, 23, 40, 61, 3, 62, 62, 34, 40, 61, 36, 61, 25, 42, 31, 62, 62, 25, 42, 31]\n",
            "iter 360\n",
            "batch loss 0.37279069423675537\n",
            "20 batch loss 0.40048481374979017\n",
            "trg [1, 27, 61, 48, 38, 10, 40, 61, 3, 62, 62, 21, 61, 48, 62, 3, 4, 16, 23, 61, 16, 62, 61, 48, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 23, 40, 61, 3, 62, 62, 4, 61, 48, 62, 3, 4, 9, 23, 61, 9, 62, 61, 48, 62]\n",
            "iter 380\n",
            "batch loss 0.3488656282424927\n",
            "20 batch loss 0.4191314846277237\n",
            "trg [1, 27, 61, 55, 38, 24, 62, 23, 61, 7, 62, 61, 55, 3, 35, 61, 55, 40, 61, 9, 62, 3, 4, 15, 55, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 4, 62, 23, 61, 55, 62, 61, 35, 40, 9, 61, 55, 40, 61, 9, 62, 3, 4, 9, 55, 62, 62]\n",
            "iter 400\n",
            "batch loss 0.42432841658592224\n",
            "20 batch loss 0.3968732446432114\n",
            "trg [1, 27, 61, 59, 38, 24, 62, 23, 61, 14, 59, 40, 61, 11, 62, 3, 59, 34, 61, 59, 62, 62, 61, 59, 40, 61, 13, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 23, 61, 59, 59, 40, 61, 8, 62, 3, 59, 3, 61, 59, 62, 62, 61, 59, 40, 61, 9, 62, 62]\n",
            "iter 420\n",
            "batch loss 0.4237346053123474\n",
            "20 batch loss 0.40974743515253065\n",
            "trg [1, 27, 61, 48, 38, 9, 40, 61, 3, 62, 62, 4, 16, 23, 61, 9, 34, 61, 48, 62, 34, 61, 48, 62, 62, 61, 36, 61, 48, 62, 3, 4, 14, 48, 34, 61, 48, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 8, 40, 61, 3, 62, 62, 23, 9, 23, 61, 9, 34, 61, 48, 62, 36, 61, 48, 62, 62, 61, 34, 61, 48, 62, 3, 4, 9, 48, 34, 61, 48, 62, 62]\n",
            "iter 440\n",
            "batch loss 0.3976103365421295\n",
            "20 batch loss 0.41078524142503736\n",
            "trg [1, 23, 61, 12, 62, 61, 15, 62, 27, 61, 56, 38, 23, 61, 30, 62, 61, 9, 62, 40, 61, 4, 62, 62, 23, 61, 10, 62, 61, 20, 40, 61, 14, 62, 61, 56, 62, 3, 4, 16, 20, 40, 61, 10, 62, 61, 56, 62, 62, 2]\n",
            "pred [1, 23, 61, 9, 62, 61, 9, 62, 27, 61, 58, 38, 23, 61, 30, 62, 61, 9, 62, 40, 61, 4, 62, 62, 23, 61, 9, 62, 61, 36, 40, 61, 9, 62, 61, 56, 62, 3, 4, 10, 36, 40, 61, 9, 62, 61, 56, 62, 62]\n",
            "iter 460\n",
            "batch loss 0.4909310042858124\n",
            "20 batch loss 0.3998622909188271\n",
            "trg [1, 27, 61, 52, 38, 15, 62, 23, 61, 13, 62, 61, 52, 3, 10, 62, 3, 10, 23, 61, 15, 62, 61, 52, 40, 61, 10, 62, 3, 4, 15, 52, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 9, 62, 23, 61, 34, 3, 61, 52, 3, 9, 62, 25, 23, 23, 61, 9, 62, 61, 52, 25, 61, 9, 62, 3, 4, 9, 52, 62]\n",
            "iter 480\n",
            "batch loss 0.4038626253604889\n",
            "20 batch loss 0.39758002907037737\n",
            "trg [1, 27, 61, 48, 38, 30, 6, 16, 62, 23, 61, 34, 40, 61, 9, 62, 61, 48, 62, 3, 20, 40, 61, 16, 62, 61, 48, 62, 62, 61, 9, 62, 2]\n",
            "pred [1, 27, 61, 57, 38, 30, 6, 9, 62, 23, 61, 36, 40, 61, 10, 62, 61, 48, 62, 3, 34, 40, 61, 9, 62, 61, 48, 62, 62, 61, 9, 62]\n",
            "iter 20\n",
            "batch loss 0.44917553663253784\n",
            "20 batch loss 0.5253788664937019\n",
            "trg [1, 27, 61, 57, 38, 23, 61, 30, 62, 61, 16, 62, 40, 61, 4, 62, 62, 23, 61, 20, 61, 57, 62, 62, 61, 36, 61, 57, 62, 62, 3, 4, 13, 23, 61, 9, 62, 61, 20, 61, 57, 62, 62, 2]\n",
            "pred [1, 27, 61, 57, 38, 30, 61, 30, 62, 61, 9, 62, 62, 61, 4, 62, 62, 23, 61, 34, 61, 57, 62, 62, 61, 34, 61, 57, 62, 62, 3, 4, 10, 23, 61, 9, 62, 61, 34, 61, 57, 62, 62]\n",
            "iter 40\n",
            "batch loss 0.6429004073143005\n",
            "20 batch loss 0.47387160956859586\n",
            "trg [1, 27, 61, 43, 38, 4, 9, 62, 43, 40, 61, 7, 62, 3, 4, 9, 43, 40, 61, 9, 62, 3, 43, 40, 61, 9, 62, 3, 4, 43, 40, 61, 9, 62, 3, 43, 40, 61, 9, 62, 3, 4, 9, 43, 3, 7, 2]\n",
            "pred [1, 27, 61, 57, 38, 30, 24, 40, 40, 25, 61, 9, 62, 3, 7, 9, 43, 40, 61, 8, 62, 3, 43, 4, 61, 8, 62, 3, 4, 9, 40, 61, 9, 62, 3, 4, 40, 61, 8, 62, 3, 4, 43, 43, 40, 15, 31]\n",
            "iter 60\n",
            "batch loss 0.4701522886753082\n",
            "20 batch loss 0.5078392401337624\n",
            "trg [1, 27, 61, 58, 38, 24, 62, 23, 61, 29, 41, 61, 16, 15, 62, 61, 10, 62, 62, 61, 29, 41, 61, 8, 10, 62, 61, 13, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 23, 61, 8, 41, 61, 16, 9, 62, 61, 58, 62, 62, 61, 29, 41, 61, 8, 9, 62, 61, 8, 62, 62, 23]\n",
            "iter 80\n",
            "batch loss 0.6160497665405273\n",
            "20 batch loss 0.4992374539375305\n",
            "trg [1, 17, 27, 61, 57, 38, 16, 40, 61, 3, 62, 62, 23, 61, 4, 34, 61, 57, 62, 33, 40, 61, 14, 62, 61, 57, 62, 62, 61, 25, 10, 3, 11, 57, 36, 61, 57, 62, 31, 34, 40, 61, 14, 62, 61, 57, 62, 62, 2]\n",
            "pred [1, 17, 27, 61, 58, 38, 9, 40, 61, 3, 62, 62, 23, 61, 4, 9, 36, 61, 58, 62, 36, 40, 61, 8, 62, 61, 58, 62, 62, 61, 20, 40, 61, 8, 62, 61, 58, 62, 3, 25, 9, 58, 36, 61, 58, 62, 3, 8, 31, 33, 40, 61, 8, 62, 61, 58, 62, 62]\n",
            "iter 20\n",
            "batch loss 4.448150634765625\n",
            "20 batch loss 5.214747714996338\n",
            "trg [1, 27, 61, 52, 38, 16, 62, 23, 61, 46, 40, 61, 52, 62, 3, 46, 40, 61, 4, 10, 52, 62, 4, 9, 62, 61, 52, 34, 61, 52, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 9, 62, 23, 61, 58, 40, 61, 8, 62, 3, 4, 9, 58, 3, 8, 62, 61, 58, 40, 61, 8, 62, 62]\n",
            "iter 40\n",
            "batch loss 3.7362701892852783\n",
            "20 batch loss 5.078349363803864\n",
            "trg [1, 27, 61, 57, 38, 23, 61, 30, 62, 61, 10, 62, 62, 34, 40, 61, 16, 62, 61, 57, 62, 3, 27, 61, 57, 38, 23, 61, 30, 62, 61, 12, 62, 62, 22, 40, 61, 11, 62, 61, 57, 62, 2]\n",
            "pred [1, 27, 61, 57, 38, 23, 61, 30, 62, 61, 9, 62, 40, 61, 4, 62, 62, 36, 61, 57, 62, 3, 4, 9, 36, 61, 57, 62]\n",
            "iter 60\n",
            "batch loss 5.6255035400390625\n",
            "20 batch loss 5.720311999320984\n",
            "trg [1, 27, 61, 58, 38, 15, 62, 23, 61, 11, 40, 61, 58, 62, 4, 16, 62, 61, 8, 40, 61, 58, 62, 3, 7, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 4, 24, 62, 23, 61, 8, 58, 40, 61, 8, 62, 3, 9, 62, 61, 8, 26, 58, 40, 61, 8, 62, 32, 62]\n",
            "iter 80\n",
            "batch loss 3.9000368118286133\n",
            "20 batch loss 5.0520086765289305\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|     | 4/9 [22:09<26:29, 317.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\tTrain Loss:   0.411 | Train PPL:   1.508\n",
            "\tValid Loss:   0.500 | Valid PPL:   1.649\n",
            "\tTest Loss:   5.210 | Test PPL: 183.104\n",
            "trg [1, 27, 61, 54, 38, 4, 24, 62, 23, 61, 10, 54, 40, 61, 10, 62, 3, 10, 62, 61, 10, 26, 54, 40, 61, 12, 62, 32, 62, 2]\n",
            "pred [1, 27, 61, 59, 38, 24, 24, 62, 23, 61, 54, 54, 40, 61, 8, 62, 3, 4, 62, 61, 35, 26, 54, 40, 61, 9, 62, 32, 62]\n",
            "iter 20\n",
            "batch loss 0.4289206266403198\n",
            "20 batch loss 0.3861353829503059\n",
            "trg [1, 27, 61, 54, 38, 24, 62, 23, 61, 46, 40, 61, 54, 62, 62, 61, 28, 61, 54, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 23, 61, 9, 40, 61, 54, 62, 62, 61, 46, 61, 54, 62, 62]\n",
            "iter 40\n",
            "batch loss 0.3126627206802368\n",
            "20 batch loss 0.3727542653679848\n",
            "trg [1, 27, 61, 58, 38, 24, 62, 23, 61, 12, 11, 28, 61, 58, 62, 15, 6, 58, 62, 61, 23, 61, 12, 62, 61, 16, 35, 61, 58, 62, 62, 62, 23, 61, 11, 35, 61, 58, 62, 62, 61, 9, 35, 61, 58, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 23, 61, 23, 58, 58, 61, 58, 62, 23, 6, 58, 62, 61, 23, 61, 9, 62, 61, 58, 35, 61, 58, 62, 62, 62, 23, 61, 9, 35, 61, 58, 62, 62, 61, 9, 35, 61, 58, 62, 62]\n",
            "iter 60\n",
            "batch loss 0.2928108870983124\n",
            "20 batch loss 0.3751240745186806\n",
            "trg [1, 27, 61, 58, 38, 24, 62, 23, 61, 12, 11, 58, 40, 61, 11, 62, 62, 61, 8, 26, 58, 40, 61, 16, 62, 32, 62, 2]\n",
            "pred [1, 27, 61, 59, 38, 24, 62, 23, 61, 9, 58, 58, 40, 61, 9, 62, 62, 61, 8, 26, 58, 40, 61, 8, 62, 32, 62]\n",
            "iter 80\n",
            "batch loss 0.41380617022514343\n",
            "20 batch loss 0.38694016486406324\n",
            "trg [1, 28, 61, 59, 62, 17, 23, 61, 27, 61, 58, 38, 23, 61, 30, 62, 61, 12, 62, 40, 61, 4, 62, 62, 20, 61, 58, 62, 62, 61, 27, 61, 58, 38, 23, 61, 30, 62, 61, 9, 62, 40, 61, 4, 62, 62, 4, 9, 34, 40, 61, 10, 62, 61, 58, 62, 62, 2]\n",
            "pred [1, 28, 61, 57, 62, 17, 23, 61, 27, 61, 58, 38, 23, 61, 30, 62, 61, 10, 62, 40, 61, 4, 62, 62, 34, 61, 58, 62, 62, 61, 27, 61, 58, 38, 23, 61, 30, 62, 61, 12, 62, 40, 61, 4, 62, 62, 4, 9, 33, 40, 61, 9, 62, 61, 58, 62, 62]\n",
            "iter 100\n",
            "batch loss 0.4014550447463989\n",
            "20 batch loss 0.38841056972742083\n",
            "trg [1, 27, 61, 51, 38, 10, 40, 61, 3, 62, 62, 36, 40, 61, 34, 61, 25, 51, 31, 62, 62, 25, 51, 31, 2]\n",
            "pred [1, 27, 61, 58, 38, 23, 40, 61, 3, 62, 62, 34, 40, 61, 36, 61, 25, 51, 31, 62, 62, 25, 51, 31]\n",
            "iter 120\n",
            "batch loss 0.3166501224040985\n",
            "20 batch loss 0.36751593798398974\n",
            "trg [1, 17, 27, 61, 50, 38, 8, 40, 61, 3, 62, 62, 46, 40, 61, 28, 61, 25, 11, 3, 50, 40, 61, 21, 61, 50, 62, 62, 31, 62, 62, 2]\n",
            "pred [1, 17, 27, 61, 58, 38, 8, 40, 61, 3, 62, 62, 50, 40, 61, 28, 61, 25, 9, 3, 50, 40, 61, 36, 61, 50, 62, 62, 31, 62, 62]\n",
            "iter 140\n",
            "batch loss 0.36021414399147034\n",
            "20 batch loss 0.400173020362854\n",
            "trg [1, 27, 61, 58, 38, 10, 62, 23, 61, 35, 61, 10, 3, 9, 58, 62, 3, 10, 35, 61, 16, 3, 58, 62, 62, 61, 58, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 23, 61, 35, 61, 58, 58, 58, 58, 62, 3, 9, 62, 61, 58, 3, 58, 62, 62, 61, 58, 62]\n",
            "iter 160\n",
            "batch loss 0.3579607605934143\n",
            "20 batch loss 0.37672657817602156\n",
            "trg [1, 27, 61, 49, 38, 11, 40, 61, 3, 62, 62, 34, 61, 49, 62, 3, 4, 15, 23, 61, 14, 62, 61, 49, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 9, 40, 61, 3, 62, 62, 4, 61, 49, 62, 3, 4, 9, 23, 61, 9, 62, 61, 49, 62]\n",
            "iter 180\n",
            "batch loss 0.4220156967639923\n",
            "20 batch loss 0.3943869054317474\n",
            "trg [1, 27, 61, 55, 38, 12, 62, 9, 2]\n",
            "pred [1, 27, 61, 59, 38, 24, 62, 55]\n",
            "iter 200\n",
            "batch loss 0.34903520345687866\n",
            "20 batch loss 0.39448727667331696\n",
            "trg [1, 27, 61, 58, 38, 30, 6, 10, 40, 61, 4, 62, 62, 36, 61, 58, 62, 3, 4, 11, 34, 61, 58, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 30, 6, 9, 62, 61, 4, 62, 62, 34, 61, 58, 62, 3, 4, 9, 34, 61, 58, 62]\n",
            "iter 220\n",
            "batch loss 0.4036954641342163\n",
            "20 batch loss 0.3979593351483345\n",
            "trg [1, 23, 61, 27, 61, 56, 38, 11, 62, 23, 61, 45, 62, 61, 45, 56, 62, 9, 10, 20, 61, 25, 14, 56, 31, 62, 34, 61, 25, 12, 56, 31, 62, 62, 61, 27, 61, 56, 38, 9, 62, 23, 61, 45, 62, 61, 45, 56, 62, 11, 56, 62, 2]\n",
            "pred [1, 23, 61, 27, 61, 58, 38, 9, 62, 23, 61, 45, 62, 61, 45, 56, 62, 9, 8, 34, 61, 25, 56, 56, 31, 62, 20, 61, 25, 9, 56, 31, 62, 62, 61, 27, 61, 56, 38, 9, 62, 23, 61, 45, 62, 61, 45, 56, 62, 56, 56, 62]\n",
            "iter 240\n",
            "batch loss 0.3974773585796356\n",
            "20 batch loss 0.39547422230243684\n",
            "trg [1, 27, 61, 58, 38, 30, 6, 11, 62, 23, 61, 36, 40, 61, 9, 62, 61, 58, 62, 3, 20, 40, 61, 16, 62, 61, 58, 62, 62, 61, 10, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 30, 6, 9, 62, 23, 61, 20, 40, 61, 9, 62, 61, 58, 62, 3, 20, 40, 61, 9, 62, 61, 58, 62, 62, 61, 9, 62]\n",
            "iter 260\n",
            "batch loss 0.363365113735199\n",
            "20 batch loss 0.36630687564611436\n",
            "trg [1, 27, 61, 53, 38, 7, 62, 23, 61, 23, 61, 11, 34, 61, 25, 9, 53, 31, 62, 62, 61, 15, 53, 62, 62, 61, 23, 61, 16, 34, 61, 25, 10, 53, 31, 62, 62, 61, 10, 53, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 23, 61, 23, 61, 9, 34, 61, 25, 9, 53, 31, 62, 62, 61, 9, 53, 62, 62, 61, 23, 61, 9, 34, 61, 25, 7, 53, 31, 62, 62, 61, 9, 53, 62, 62]\n",
            "iter 280\n",
            "batch loss 0.5060329437255859\n",
            "20 batch loss 0.39153958261013033\n",
            "trg [1, 27, 61, 56, 38, 24, 62, 25, 56, 3, 4, 11, 35, 61, 56, 40, 61, 7, 62, 3, 4, 56, 62, 31, 23, 61, 56, 3, 35, 61, 56, 40, 61, 8, 62, 3, 4, 9, 56, 62, 62, 61, 56, 3, 35, 61, 56, 40, 61, 8, 62, 3, 7, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 23, 56, 40, 9, 9, 23, 61, 56, 40, 61, 9, 62, 3, 4, 56, 3, 3, 61, 56, 4, 56, 61, 56, 3, 61, 9, 62, 3, 56, 9, 56, 56, 62, 61, 56, 3, 4, 61, 56, 40, 61, 9, 62, 3, 4, 56, 56]\n",
            "iter 300\n",
            "batch loss 0.49306851625442505\n",
            "20 batch loss 0.40569167733192446\n",
            "trg [1, 27, 61, 55, 38, 9, 62, 23, 61, 13, 62, 61, 55, 3, 11, 62, 25, 23, 61, 16, 62, 61, 15, 35, 61, 55, 3, 15, 62, 62, 3, 4, 10, 23, 61, 35, 61, 55, 3, 13, 62, 62, 61, 14, 35, 61, 55, 3, 14, 62, 62, 31, 2]\n",
            "pred [1, 27, 61, 59, 38, 24, 62, 23, 61, 23, 62, 61, 35, 3, 9, 62, 25, 23, 61, 9, 62, 61, 35, 35, 61, 49, 3, 9, 62, 62, 3, 4, 10, 23, 61, 35, 61, 49, 3, 9, 62, 62, 61, 10, 35, 61, 49, 3, 9, 62, 62, 31]\n",
            "iter 320\n",
            "batch loss 0.48866355419158936\n",
            "20 batch loss 0.38651011884212494\n",
            "trg [1, 23, 61, 27, 61, 48, 38, 14, 62, 23, 61, 45, 62, 61, 45, 48, 62, 13, 8, 36, 61, 25, 12, 48, 31, 62, 20, 61, 25, 15, 48, 31, 62, 62, 61, 27, 61, 48, 38, 10, 62, 23, 61, 45, 62, 61, 45, 48, 62, 11, 48, 62, 2]\n",
            "pred [1, 23, 61, 27, 61, 58, 38, 8, 62, 23, 61, 45, 62, 61, 45, 48, 62, 8, 8, 34, 61, 25, 10, 48, 31, 62, 36, 61, 25, 9, 48, 31, 62, 62, 61, 27, 61, 48, 38, 8, 62, 23, 61, 45, 62, 61, 45, 48, 62, 48, 48, 62]\n",
            "iter 340\n",
            "batch loss 0.4602709412574768\n",
            "20 batch loss 0.39067401438951493\n",
            "trg [1, 23, 61, 27, 61, 55, 38, 13, 62, 23, 61, 45, 62, 61, 45, 55, 62, 13, 9, 36, 61, 25, 12, 55, 31, 62, 36, 61, 25, 9, 55, 31, 62, 62, 61, 27, 61, 55, 38, 10, 62, 23, 61, 45, 62, 61, 45, 55, 62, 9, 55, 62, 2]\n",
            "pred [1, 23, 61, 27, 61, 58, 38, 8, 62, 23, 61, 45, 62, 61, 45, 55, 62, 10, 8, 34, 61, 25, 9, 55, 31, 62, 36, 61, 25, 55, 55, 31, 62, 62, 61, 27, 61, 55, 38, 8, 62, 23, 61, 45, 62, 61, 45, 55, 62, 55, 55, 62]\n",
            "iter 360\n",
            "batch loss 0.36055341362953186\n",
            "20 batch loss 0.4088157132267952\n",
            "trg [1, 27, 61, 48, 38, 24, 62, 23, 61, 14, 48, 40, 61, 7, 62, 3, 10, 62, 61, 35, 61, 16, 48, 40, 61, 8, 62, 3, 11, 48, 3, 9, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 23, 61, 23, 48, 40, 61, 9, 62, 3, 4, 48, 61, 35, 61, 9, 48, 40, 61, 9, 62, 3, 48, 48, 40, 11, 62, 62]\n",
            "iter 380\n",
            "batch loss 0.33356332778930664\n",
            "20 batch loss 0.36101441383361815\n",
            "trg [1, 27, 61, 51, 38, 9, 40, 61, 3, 62, 62, 23, 61, 23, 61, 13, 62, 61, 51, 62, 62, 61, 4, 15, 34, 61, 51, 62, 34, 61, 51, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 9, 40, 61, 3, 62, 62, 23, 61, 23, 61, 10, 62, 61, 51, 62, 62, 61, 4, 9, 22, 61, 51, 62, 20, 61, 51, 62, 62]\n",
            "iter 400\n",
            "batch loss 0.44969648122787476\n",
            "20 batch loss 0.3877269595861435\n",
            "trg [1, 27, 61, 55, 38, 11, 40, 61, 3, 62, 62, 22, 61, 55, 62, 3, 4, 13, 23, 61, 14, 62, 61, 55, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 9, 40, 61, 3, 62, 62, 4, 61, 55, 62, 3, 4, 9, 23, 61, 9, 62, 61, 55, 62]\n",
            "iter 420\n",
            "batch loss 0.40159016847610474\n",
            "20 batch loss 0.40390373915433886\n",
            "trg [1, 27, 61, 42, 38, 10, 40, 61, 3, 62, 62, 23, 61, 10, 3, 9, 42, 62, 61, 42, 62, 23, 61, 42, 62, 61, 42, 3, 42, 28, 61, 42, 62, 4, 16, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 30, 40, 61, 3, 62, 62, 4, 61, 4, 6, 4, 42, 62, 61, 42, 62, 23, 61, 42, 62, 61, 42, 3, 42, 28, 61, 42, 62, 4, 15, 62]\n",
            "iter 440\n",
            "batch loss 0.37016597390174866\n",
            "20 batch loss 0.3731069162487984\n",
            "trg [1, 27, 61, 59, 38, 30, 6, 13, 62, 23, 61, 10, 34, 40, 61, 14, 62, 61, 59, 62, 3, 4, 12, 36, 40, 61, 14, 62, 61, 59, 62, 62, 61, 11, 62, 2]\n",
            "pred [1, 27, 61, 59, 38, 23, 6, 9, 62, 23, 61, 9, 20, 40, 61, 9, 62, 61, 59, 62, 3, 4, 10, 36, 40, 61, 9, 62, 61, 59, 62, 62, 61, 10, 62]\n",
            "iter 460\n",
            "batch loss 0.39954981207847595\n",
            "20 batch loss 0.3741611286997795\n",
            "trg [1, 17, 27, 61, 47, 38, 24, 62, 23, 61, 4, 15, 25, 34, 61, 9, 6, 47, 62, 3, 4, 15, 9, 6, 47, 36, 61, 10, 6, 47, 62, 31, 62, 61, 4, 9, 47, 40, 61, 4, 12, 62, 62, 2]\n",
            "pred [1, 23, 27, 61, 59, 38, 24, 62, 23, 61, 4, 9, 25, 34, 61, 23, 6, 47, 62, 3, 4, 9, 9, 6, 47, 34, 61, 9, 6, 47, 62, 31, 62, 61, 4, 9, 47, 40, 61, 4, 9, 62, 62]\n",
            "iter 480\n",
            "batch loss 0.4038122296333313\n",
            "20 batch loss 0.3747205585241318\n",
            "trg [1, 17, 27, 61, 60, 38, 8, 40, 61, 3, 62, 62, 4, 9, 23, 61, 15, 34, 61, 60, 62, 36, 61, 60, 62, 62, 61, 20, 61, 60, 62, 3, 7, 34, 61, 60, 62, 62, 2]\n",
            "pred [1, 17, 27, 61, 48, 38, 9, 62, 61, 3, 62, 62, 4, 9, 23, 61, 23, 36, 61, 60, 62, 36, 61, 60, 62, 62, 61, 36, 61, 60, 62, 3, 4, 60, 61, 60, 62, 62]\n",
            "iter 20\n",
            "batch loss 0.44934922456741333\n",
            "20 batch loss 0.5421338468790055\n",
            "trg [1, 27, 61, 57, 38, 4, 24, 62, 23, 61, 9, 57, 62, 61, 57, 3, 4, 12, 26, 57, 32, 62, 2]\n",
            "pred [1, 27, 61, 55, 38, 9, 9, 62, 23, 61, 57, 62, 62, 61, 8, 3, 9, 9, 57, 57, 40, 62]\n",
            "iter 40\n",
            "batch loss 0.6409021615982056\n",
            "20 batch loss 0.5174787536263465\n",
            "trg [1, 17, 27, 61, 59, 38, 24, 62, 23, 61, 12, 62, 61, 59, 40, 61, 4, 12, 62, 62, 25, 23, 61, 9, 62, 61, 59, 62, 3, 4, 13, 34, 61, 23, 61, 14, 62, 61, 59, 62, 62, 31, 2]\n",
            "pred [1, 17, 27, 61, 58, 38, 30, 62, 23, 61, 10, 62, 61, 59, 40, 61, 9, 9, 62, 62, 23, 23, 61, 9, 62, 61, 59, 62, 3, 4, 9, 34, 61, 59, 61, 10, 62, 61, 59, 62, 62]\n",
            "iter 60\n",
            "batch loss 0.4470233619213104\n",
            "20 batch loss 0.5127624690532684\n",
            "trg [1, 17, 27, 61, 44, 38, 13, 40, 61, 3, 62, 62, 4, 9, 23, 61, 12, 22, 61, 44, 62, 36, 61, 44, 62, 62, 61, 34, 61, 44, 62, 3, 4, 10, 44, 34, 61, 44, 62, 62, 2]\n",
            "pred [1, 23, 27, 61, 48, 38, 9, 62, 61, 3, 62, 62, 23, 9, 23, 61, 23, 34, 61, 44, 62, 20, 61, 44, 62, 62, 61, 36, 61, 44, 62, 3, 4, 9, 44, 34, 61, 44, 62, 62]\n",
            "iter 80\n",
            "batch loss 0.5365967154502869\n",
            "20 batch loss 0.5213338762521744\n",
            "trg [1, 27, 61, 59, 38, 13, 62, 23, 61, 34, 61, 25, 15, 59, 31, 62, 62, 61, 59, 22, 61, 25, 10, 59, 31, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 9, 62, 23, 61, 34, 61, 25, 9, 58, 31, 62, 62, 61, 36, 61, 25, 9, 58, 31, 62, 62]\n",
            "iter 20\n",
            "batch loss 6.391365051269531\n",
            "20 batch loss 5.162289679050446\n",
            "trg [1, 27, 61, 57, 38, 4, 24, 62, 23, 61, 16, 10, 57, 40, 61, 8, 62, 3, 4, 9, 57, 40, 61, 9, 62, 3, 9, 62, 61, 35, 61, 15, 10, 57, 40, 61, 10, 62, 3, 57, 40, 61, 9, 62, 3, 10, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 23, 61, 9, 58, 40, 61, 9, 62, 3, 58, 62, 61, 35, 61, 58, 40, 61, 9, 62, 3, 58, 62, 62]\n",
            "iter 40\n",
            "batch loss 3.428281784057617\n",
            "20 batch loss 4.955019330978393\n",
            "trg [1, 27, 61, 56, 38, 30, 6, 16, 62, 23, 61, 9, 36, 40, 61, 9, 62, 61, 56, 62, 3, 11, 20, 40, 61, 11, 62, 61, 56, 62, 62, 61, 11, 62, 2]\n",
            "pred [1, 27, 61, 59, 38, 30, 6, 9, 62, 23, 61, 9, 34, 40, 61, 10, 62, 61, 59, 62, 3, 4, 9, 36, 40, 61, 9, 62, 61, 59, 62, 62, 61, 14, 62]\n",
            "iter 60\n",
            "batch loss 5.264735698699951\n",
            "20 batch loss 5.203776383399964\n",
            "trg [1, 28, 61, 55, 62, 17, 23, 61, 27, 61, 51, 38, 23, 61, 30, 62, 61, 9, 62, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 51, 62, 20, 61, 51, 62, 62, 61, 27, 61, 51, 38, 23, 61, 30, 62, 61, 14, 62, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 51, 62, 4, 9, 20, 40, 61, 10, 62, 61, 51, 62, 62, 2]\n",
            "pred [1, 27, 61, 59, 38, 24, 62, 23, 61, 29, 41, 61, 8, 7, 62, 61, 59, 62, 62, 61, 29, 41, 61, 8, 13, 62, 61, 13, 62, 62, 23, 61, 29, 41, 61, 8, 13, 62, 61, 8, 62, 62, 61, 29, 41, 61, 8, 9, 62, 61, 59, 62, 62]\n",
            "iter 80\n",
            "batch loss 5.560909748077393\n",
            "20 batch loss 4.816630208492279\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|    | 5/9 [27:06<20:40, 310.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\tTrain Loss:   0.385 | Train PPL:   1.470\n",
            "\tValid Loss:   0.516 | Valid PPL:   1.675\n",
            "\tTest Loss:   4.999 | Test PPL: 148.209\n",
            "trg [1, 27, 61, 51, 38, 24, 62, 26, 51, 4, 14, 32, 3, 51, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 26, 51, 4, 9, 32, 3, 51]\n",
            "iter 20\n",
            "batch loss 0.40965646505355835\n",
            "20 batch loss 0.3833142340183258\n",
            "trg [1, 27, 61, 54, 38, 23, 61, 30, 62, 61, 10, 62, 62, 33, 40, 61, 16, 62, 61, 54, 62, 3, 20, 40, 61, 9, 62, 61, 54, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 23, 61, 30, 62, 61, 9, 62, 62, 20, 40, 61, 9, 62, 61, 54, 62, 3, 36, 40, 61, 9, 62, 61, 54, 62]\n",
            "iter 40\n",
            "batch loss 0.3556564152240753\n",
            "20 batch loss 0.3661136835813522\n",
            "trg [1, 27, 61, 48, 38, 23, 61, 30, 62, 61, 9, 62, 62, 36, 40, 61, 16, 62, 61, 48, 62, 3, 34, 40, 61, 14, 62, 61, 48, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 23, 61, 30, 62, 61, 9, 62, 62, 34, 40, 61, 9, 62, 61, 48, 62, 3, 34, 40, 61, 9, 62, 61, 48, 62]\n",
            "iter 60\n",
            "batch loss 0.41415348649024963\n",
            "20 batch loss 0.37207387536764147\n",
            "trg [1, 27, 61, 60, 38, 23, 61, 30, 62, 61, 9, 62, 62, 23, 61, 9, 34, 40, 61, 13, 62, 61, 60, 62, 3, 14, 20, 40, 61, 13, 62, 61, 60, 62, 62, 61, 9, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 23, 61, 30, 62, 61, 9, 62, 62, 23, 61, 34, 34, 40, 61, 10, 62, 61, 60, 62, 3, 4, 20, 40, 61, 10, 62, 61, 60, 62, 62, 61, 9, 62]\n",
            "iter 80\n",
            "batch loss 0.3082520067691803\n",
            "20 batch loss 0.36287515610456467\n",
            "trg [1, 17, 23, 61, 27, 61, 48, 38, 30, 6, 10, 40, 61, 4, 62, 62, 20, 61, 48, 62, 62, 61, 27, 61, 48, 38, 30, 6, 13, 40, 61, 4, 62, 62, 4, 13, 34, 40, 61, 15, 62, 61, 48, 62, 62, 2]\n",
            "pred [1, 17, 23, 61, 27, 61, 58, 38, 23, 6, 10, 40, 61, 4, 62, 62, 36, 61, 48, 62, 62, 61, 27, 61, 48, 38, 30, 6, 9, 40, 61, 4, 62, 62, 4, 9, 34, 40, 61, 9, 62, 61, 48, 62, 62]\n",
            "iter 100\n",
            "batch loss 0.33252623677253723\n",
            "20 batch loss 0.3583096131682396\n",
            "trg [1, 27, 61, 57, 38, 9, 40, 61, 4, 62, 62, 23, 61, 57, 62, 61, 26, 57, 4, 12, 32, 62, 2]\n",
            "pred [1, 27, 61, 57, 38, 7, 62, 61, 4, 62, 62, 23, 61, 57, 62, 61, 26, 57, 3, 9, 32, 62]\n",
            "iter 120\n",
            "batch loss 0.29825031757354736\n",
            "20 batch loss 0.35779291540384295\n",
            "trg [1, 17, 27, 61, 58, 38, 14, 62, 23, 61, 16, 62, 61, 58, 3, 12, 62, 23, 61, 14, 3, 9, 35, 61, 58, 3, 12, 62, 62, 61, 10, 35, 61, 58, 3, 13, 62, 62, 23, 61, 12, 3, 35, 61, 58, 3, 12, 62, 62, 61, 9, 3, 35, 61, 58, 3, 14, 62, 62, 2]\n",
            "pred [1, 17, 27, 61, 58, 38, 24, 62, 23, 61, 9, 62, 61, 58, 4, 9, 62, 23, 61, 9, 3, 35, 35, 61, 58, 3, 9, 62, 62, 61, 9, 35, 61, 58, 3, 9, 62, 62, 61, 9, 3, 35, 61, 58, 3, 9, 62, 62, 61, 10, 3, 35, 61, 58, 3, 9, 62, 62]\n",
            "iter 140\n",
            "batch loss 0.3770007789134979\n",
            "20 batch loss 0.3840456515550613\n",
            "trg [1, 27, 61, 56, 38, 15, 40, 61, 3, 62, 62, 22, 61, 56, 62, 3, 4, 15, 23, 61, 14, 62, 61, 56, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 9, 40, 61, 3, 62, 62, 34, 61, 56, 62, 3, 4, 9, 23, 61, 9, 62, 61, 56, 62]\n",
            "iter 160\n",
            "batch loss 0.3559296429157257\n",
            "20 batch loss 0.3588283210992813\n",
            "trg [1, 27, 61, 60, 38, 23, 61, 30, 62, 61, 15, 62, 62, 23, 61, 12, 33, 40, 61, 13, 62, 61, 60, 62, 3, 4, 10, 20, 40, 61, 13, 62, 61, 60, 62, 62, 61, 13, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 23, 61, 30, 62, 61, 9, 62, 62, 23, 61, 34, 34, 40, 61, 10, 62, 61, 60, 62, 3, 9, 9, 34, 40, 61, 9, 62, 61, 60, 62, 62, 61, 9, 62]\n",
            "iter 180\n",
            "batch loss 0.4617209732532501\n",
            "20 batch loss 0.3828467264771461\n",
            "trg [1, 27, 61, 52, 38, 24, 62, 23, 61, 29, 41, 61, 8, 11, 62, 61, 52, 62, 62, 61, 29, 41, 61, 8, 13, 62, 61, 11, 62, 62, 23, 61, 29, 41, 61, 13, 11, 62, 61, 15, 62, 62, 61, 29, 41, 61, 9, 8, 62, 61, 52, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 23, 61, 29, 41, 61, 9, 8, 62, 61, 52, 62, 62, 61, 29, 41, 61, 8, 9, 62, 61, 8, 62, 62, 23, 61, 29, 41, 61, 9, 9, 62, 61, 9, 62, 62, 61, 29, 41, 61, 9, 9, 62, 61, 52, 62, 62]\n",
            "iter 200\n",
            "batch loss 0.3873438835144043\n",
            "20 batch loss 0.3957292824983597\n",
            "trg [1, 28, 61, 59, 62, 17, 23, 61, 27, 61, 37, 38, 23, 61, 30, 62, 61, 11, 62, 40, 61, 4, 62, 62, 20, 61, 37, 62, 62, 61, 27, 61, 37, 38, 23, 61, 30, 62, 61, 13, 62, 40, 61, 4, 62, 62, 4, 9, 36, 40, 61, 10, 62, 61, 37, 62, 62, 2]\n",
            "pred [1, 28, 61, 57, 62, 17, 23, 61, 27, 61, 57, 38, 30, 61, 30, 62, 61, 9, 62, 40, 61, 4, 62, 62, 34, 61, 37, 62, 62, 61, 27, 61, 37, 38, 23, 61, 30, 62, 61, 11, 62, 40, 61, 4, 62, 62, 4, 9, 36, 40, 61, 9, 62, 61, 37, 62, 62]\n",
            "iter 220\n",
            "batch loss 0.32717299461364746\n",
            "20 batch loss 0.3592329606413841\n",
            "trg [1, 27, 61, 49, 38, 4, 24, 62, 46, 40, 61, 4, 11, 49, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 24, 62, 49, 40, 61, 4, 9, 49, 62]\n",
            "iter 240\n",
            "batch loss 0.4010918140411377\n",
            "20 batch loss 0.3624790459871292\n",
            "trg [1, 23, 61, 15, 62, 61, 12, 62, 27, 61, 58, 38, 23, 61, 30, 62, 61, 16, 62, 40, 61, 4, 62, 62, 23, 61, 10, 62, 61, 20, 40, 61, 9, 62, 61, 58, 62, 3, 4, 15, 36, 40, 61, 9, 62, 61, 58, 62, 62, 2]\n",
            "pred [1, 23, 61, 9, 62, 61, 9, 62, 27, 61, 58, 38, 23, 61, 30, 62, 61, 9, 62, 40, 61, 4, 62, 62, 23, 61, 9, 58, 61, 36, 40, 61, 9, 62, 61, 58, 62, 3, 4, 10, 34, 40, 61, 14, 62, 61, 58, 62, 62]\n",
            "iter 260\n",
            "batch loss 0.3622284233570099\n",
            "20 batch loss 0.3656984940171242\n",
            "trg [1, 27, 61, 42, 38, 14, 40, 61, 4, 62, 62, 23, 61, 25, 42, 4, 9, 31, 25, 42, 4, 9, 31, 62, 61, 25, 42, 4, 10, 31, 25, 42, 3, 7, 31, 62, 2]\n",
            "pred [1, 27, 61, 57, 38, 9, 62, 61, 3, 62, 62, 23, 61, 4, 42, 4, 9, 31, 25, 42, 4, 9, 31, 62, 61, 25, 42, 4, 9, 31, 25, 42, 3, 9, 31, 62]\n",
            "iter 280\n",
            "batch loss 0.40095382928848267\n",
            "20 batch loss 0.36200289279222486\n",
            "trg [1, 27, 61, 53, 38, 24, 62, 23, 61, 23, 61, 29, 41, 61, 9, 8, 62, 61, 53, 62, 62, 61, 29, 41, 61, 16, 13, 62, 61, 9, 62, 62, 62, 61, 23, 61, 29, 41, 61, 12, 11, 62, 61, 53, 62, 62, 61, 29, 41, 61, 9, 10, 62, 61, 10, 62, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 23, 61, 23, 61, 29, 41, 61, 9, 9, 62, 61, 53, 62, 62, 61, 29, 41, 61, 9, 9, 62, 61, 9, 62, 62, 62, 61, 23, 61, 29, 41, 61, 9, 9, 62, 61, 53, 62, 62, 61, 29, 41, 61, 9, 9, 62, 61, 9, 62, 62, 62]\n",
            "iter 300\n",
            "batch loss 0.3309290409088135\n",
            "20 batch loss 0.372326897084713\n",
            "trg [1, 27, 61, 56, 38, 23, 61, 30, 62, 61, 12, 62, 40, 61, 4, 62, 62, 23, 61, 20, 40, 61, 14, 62, 61, 56, 62, 25, 10, 56, 3, 25, 4, 9, 30, 31, 40, 61, 13, 62, 31, 62, 61, 4, 15, 62, 2]\n",
            "pred [1, 27, 61, 57, 38, 23, 61, 30, 62, 61, 9, 62, 62, 61, 4, 62, 62, 23, 61, 36, 40, 61, 15, 62, 61, 56, 62, 25, 10, 56, 3, 25, 4, 9, 30, 31, 40, 61, 9, 62, 31, 62, 61, 4, 9, 62]\n",
            "iter 320\n",
            "batch loss 0.35427868366241455\n",
            "20 batch loss 0.36395069658756257\n",
            "trg [1, 27, 61, 37, 38, 10, 40, 61, 3, 62, 62, 46, 40, 61, 28, 61, 25, 11, 3, 37, 40, 61, 36, 61, 37, 62, 62, 31, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 30, 40, 61, 3, 62, 62, 46, 40, 61, 28, 61, 25, 9, 3, 37, 40, 61, 36, 61, 37, 62, 62, 31, 62, 62]\n",
            "iter 340\n",
            "batch loss 0.34332776069641113\n",
            "20 batch loss 0.370000396668911\n",
            "trg [1, 27, 61, 59, 38, 12, 62, 59, 23, 61, 14, 62, 61, 33, 61, 59, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 9, 62, 23, 23, 61, 9, 62, 61, 34, 61, 59, 62, 62]\n",
            "iter 360\n",
            "batch loss 0.37190312147140503\n",
            "20 batch loss 0.3594341859221458\n",
            "trg [1, 27, 61, 58, 38, 10, 40, 61, 3, 62, 62, 4, 13, 23, 61, 23, 61, 45, 62, 61, 45, 58, 62, 36, 40, 61, 13, 62, 61, 58, 62, 62, 61, 23, 61, 45, 62, 61, 45, 58, 62, 58, 36, 61, 58, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 9, 62, 61, 3, 62, 62, 23, 23, 23, 61, 23, 61, 45, 62, 61, 45, 58, 62, 34, 40, 61, 9, 62, 61, 58, 62, 62, 61, 23, 61, 45, 62, 61, 45, 58, 62, 58, 20, 61, 58, 62, 62]\n",
            "iter 380\n",
            "batch loss 0.35601550340652466\n",
            "20 batch loss 0.3864054635167122\n",
            "trg [1, 27, 61, 59, 38, 16, 62, 23, 61, 9, 25, 59, 4, 12, 31, 35, 61, 59, 3, 16, 62, 25, 14, 3, 35, 61, 59, 3, 12, 62, 31, 62, 61, 13, 3, 4, 12, 25, 59, 3, 12, 31, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 23, 61, 25, 25, 59, 4, 9, 31, 35, 61, 59, 3, 11, 62, 25, 10, 3, 35, 61, 59, 3, 9, 62, 31, 62, 61, 14, 3, 4, 9, 25, 59, 3, 9, 31, 62]\n",
            "iter 400\n",
            "batch loss 0.3890330195426941\n",
            "20 batch loss 0.37018541246652603\n",
            "trg [1, 27, 61, 58, 38, 8, 62, 23, 61, 34, 61, 12, 62, 58, 62, 61, 36, 61, 10, 62, 58, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 9, 62, 23, 61, 34, 61, 25, 62, 58, 62, 61, 36, 61, 10, 62, 58, 62]\n",
            "iter 420\n",
            "batch loss 0.3954877555370331\n",
            "20 batch loss 0.37934980243444444\n",
            "trg [1, 27, 61, 54, 38, 24, 62, 14, 3, 4, 11, 28, 61, 25, 15, 54, 31, 62, 2]\n",
            "pred [1, 27, 61, 48, 38, 24, 62, 26, 54, 4, 9, 28, 61, 25, 9, 54, 31, 62, 62]\n",
            "iter 440\n",
            "batch loss 0.3732755780220032\n",
            "20 batch loss 0.3656138822436333\n",
            "trg [1, 27, 61, 51, 38, 9, 40, 61, 3, 62, 62, 23, 61, 23, 61, 13, 62, 61, 51, 62, 62, 61, 4, 15, 34, 61, 51, 62, 34, 61, 51, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 9, 40, 61, 3, 62, 62, 23, 61, 23, 61, 9, 62, 61, 51, 62, 62, 61, 4, 9, 36, 61, 51, 62, 20, 61, 51, 62, 62]\n",
            "iter 460\n",
            "batch loss 0.42461830377578735\n",
            "20 batch loss 0.38815082758665087\n",
            "trg [1, 27, 61, 59, 38, 23, 61, 30, 62, 61, 10, 62, 62, 23, 61, 12, 34, 61, 59, 62, 3, 4, 9, 21, 61, 59, 62, 62, 61, 10, 59, 3, 4, 9, 23, 61, 30, 62, 61, 11, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 23, 61, 30, 62, 61, 9, 62, 62, 23, 61, 34, 34, 61, 59, 62, 3, 4, 9, 36, 61, 59, 62, 62, 61, 9, 59, 3, 4, 9, 23, 61, 30, 62, 61, 9, 62, 62]\n",
            "iter 480\n",
            "batch loss 0.37663447856903076\n",
            "20 batch loss 0.3663533374667168\n",
            "trg [1, 46, 40, 61, 27, 61, 48, 38, 10, 40, 61, 3, 62, 62, 23, 61, 23, 61, 16, 62, 61, 48, 3, 9, 62, 62, 61, 20, 61, 48, 62, 62, 62, 2]\n",
            "pred [1, 46, 40, 61, 27, 61, 58, 38, 9, 40, 61, 3, 62, 62, 23, 61, 23, 61, 45, 62, 61, 48, 3, 12, 62, 62, 61, 34, 61, 48, 62, 62, 62]\n",
            "iter 20\n",
            "batch loss 0.619698703289032\n",
            "20 batch loss 0.539294770359993\n",
            "trg [1, 27, 61, 47, 38, 23, 61, 30, 62, 61, 13, 62, 40, 61, 4, 62, 62, 23, 61, 36, 40, 61, 16, 62, 61, 47, 62, 62, 61, 14, 23, 61, 13, 62, 61, 15, 47, 3, 25, 9, 30, 31, 40, 61, 13, 62, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 9, 61, 30, 62, 61, 9, 62, 62, 61, 4, 62, 62, 23, 61, 9, 61, 61, 9, 62, 61, 47, 62, 25, 61, 13, 3, 61, 9, 62, 61, 36, 47, 3, 4, 9, 30, 31, 62, 61, 9, 62, 62]\n",
            "iter 40\n",
            "batch loss 0.585421085357666\n",
            "20 batch loss 0.4787169575691223\n",
            "trg [1, 27, 61, 60, 38, 15, 40, 61, 3, 62, 62, 23, 61, 60, 40, 61, 11, 62, 3, 4, 12, 60, 3, 10, 8, 62, 61, 60, 4, 16, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 9, 62, 61, 3, 62, 62, 23, 61, 60, 3, 61, 9, 62, 3, 4, 9, 60, 3, 8, 62, 62, 61, 60, 4, 9, 62]\n",
            "iter 60\n",
            "batch loss 0.562964916229248\n",
            "20 batch loss 0.5238133400678635\n",
            "trg [1, 27, 61, 54, 38, 24, 62, 23, 61, 23, 61, 45, 62, 61, 45, 54, 62, 25, 46, 40, 61, 23, 61, 16, 62, 61, 54, 62, 62, 4, 13, 31, 62, 61, 23, 61, 45, 62, 61, 45, 54, 62, 23, 61, 12, 62, 61, 54, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 23, 61, 23, 61, 45, 62, 61, 45, 54, 62, 8, 46, 40, 61, 23, 61, 9, 62, 61, 54, 62, 62, 4, 10, 31, 62, 61, 23, 61, 45, 62, 61, 45, 54, 62, 25, 61, 10, 62, 61, 54, 62, 62]\n",
            "iter 80\n",
            "batch loss 0.48715153336524963\n",
            "20 batch loss 0.49742708504199984\n",
            "trg [1, 15, 6, 9, 27, 61, 44, 38, 24, 62, 23, 61, 34, 61, 9, 6, 44, 62, 3, 4, 9, 9, 6, 44, 36, 61, 11, 6, 44, 62, 62, 61, 44, 40, 61, 4, 10, 62, 62, 2]\n",
            "pred [1, 10, 6, 9, 27, 61, 58, 38, 24, 62, 23, 61, 23, 61, 45, 62, 61, 45, 58, 62, 25, 34, 61, 23, 61, 10, 62, 61, 58, 62, 62, 3, 4, 10, 23, 61, 10, 62, 61, 58, 62, 20, 61, 23, 61, 10, 62, 61, 58, 62, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 58, 62, 58, 40, 61, 4, 9, 62, 62, 2]\n",
            "iter 20\n",
            "batch loss 4.807602405548096\n",
            "20 batch loss 4.950195848941803\n",
            "trg [1, 27, 61, 60, 38, 24, 62, 23, 61, 35, 61, 60, 4, 8, 62, 40, 61, 7, 62, 3, 35, 61, 60, 4, 9, 62, 35, 61, 60, 4, 14, 62, 3, 4, 35, 61, 60, 4, 14, 62, 35, 61, 60, 4, 9, 62, 3, 4, 14, 35, 61, 60, 4, 15, 62, 40, 61, 10, 62, 62, 61, 35, 61, 60, 4, 15, 62, 3, 35, 61, 60, 4, 8, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 23, 61, 29, 41, 61, 9, 9, 62, 61, 58, 62, 62, 61, 29, 41, 61, 8, 7, 62, 61, 8, 62, 62, 23, 61, 29, 41, 61, 8, 7, 62, 61, 15, 62, 62, 61, 29, 41, 61, 8, 7, 62, 61, 58, 62, 62]\n",
            "iter 40\n",
            "batch loss 4.3518147468566895\n",
            "20 batch loss 4.6791838765144345\n",
            "trg [1, 23, 61, 27, 61, 52, 38, 14, 62, 25, 8, 3, 52, 40, 61, 12, 3, 52, 62, 31, 25, 10, 3, 28, 61, 25, 15, 3, 52, 31, 62, 31, 62, 61, 27, 61, 52, 38, 12, 62, 13, 62, 2]\n",
            "pred [1, 23, 61, 27, 61, 58, 38, 9, 62, 23, 61, 45, 62, 61, 45, 58, 62, 8, 7, 34, 61, 25, 58, 31, 62, 36, 61, 25, 58, 31, 62, 62, 61, 27, 61, 58, 38, 9, 62, 23, 61, 45, 62, 61, 45, 58, 62, 58, 62]\n",
            "iter 60\n",
            "batch loss 4.4591383934021\n",
            "20 batch loss 4.558491909503937\n",
            "trg [1, 27, 61, 43, 38, 24, 62, 23, 61, 29, 41, 61, 10, 8, 62, 61, 43, 62, 29, 41, 61, 11, 12, 62, 61, 8, 62, 62, 61, 29, 41, 61, 8, 7, 62, 61, 9, 62, 29, 41, 61, 12, 8, 62, 61, 43, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 23, 61, 23, 61, 45, 62, 61, 45, 58, 62, 25, 58, 40, 61, 9, 62, 3, 4, 9, 58, 40, 61, 10, 62, 3, 4, 9, 58, 4, 10, 31, 62, 61, 27, 61, 58, 38, 24, 62, 23, 61, 45, 62, 61, 45, 58, 62, 25, 58, 40, 61, 9, 62, 3, 4, 9]\n",
            "iter 80\n",
            "batch loss 5.5445427894592285\n",
            "20 batch loss 4.8205619096755985\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|   | 6/9 [32:04<15:18, 306.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\tTrain Loss:   0.370 | Train PPL:   1.448\n",
            "\tValid Loss:   0.506 | Valid PPL:   1.659\n",
            "\tTest Loss:   4.737 | Test PPL: 114.116\n",
            "trg [1, 12, 6, 13, 27, 61, 54, 38, 30, 6, 10, 40, 61, 4, 62, 62, 23, 61, 9, 54, 3, 4, 11, 30, 62, 61, 34, 61, 54, 62, 22, 61, 54, 62, 62, 2]\n",
            "pred [1, 10, 6, 9, 27, 61, 58, 38, 30, 6, 9, 40, 61, 4, 62, 62, 23, 61, 9, 62, 3, 4, 9, 30, 62, 61, 34, 61, 54, 62, 36, 61, 54, 62, 62]\n",
            "iter 20\n",
            "batch loss 0.40972205996513367\n",
            "20 batch loss 0.37137451469898225\n",
            "trg [1, 27, 61, 49, 38, 30, 6, 15, 62, 36, 40, 61, 15, 62, 61, 49, 62, 3, 21, 40, 61, 16, 62, 61, 49, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 30, 6, 9, 62, 20, 40, 61, 9, 62, 61, 49, 62, 3, 34, 40, 61, 9, 62, 61, 49, 62]\n",
            "iter 40\n",
            "batch loss 0.3290197253227234\n",
            "20 batch loss 0.34488980621099474\n",
            "trg [1, 27, 61, 59, 38, 9, 40, 61, 3, 62, 62, 23, 61, 9, 6, 59, 62, 61, 4, 13, 34, 61, 59, 62, 33, 61, 59, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 9, 40, 61, 3, 62, 62, 23, 61, 23, 6, 59, 62, 61, 4, 9, 36, 61, 59, 62, 36, 61, 59, 62, 62]\n",
            "iter 60\n",
            "batch loss 0.37973976135253906\n",
            "20 batch loss 0.3373581856489182\n",
            "trg [1, 27, 61, 58, 38, 30, 6, 13, 62, 36, 40, 61, 12, 62, 61, 58, 62, 3, 34, 40, 61, 9, 62, 61, 58, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 30, 6, 9, 62, 20, 40, 61, 9, 62, 61, 58, 62, 3, 34, 40, 61, 9, 62, 61, 58, 62]\n",
            "iter 80\n",
            "batch loss 0.35953667759895325\n",
            "20 batch loss 0.3552157565951347\n",
            "trg [1, 27, 61, 42, 38, 4, 24, 62, 23, 61, 42, 62, 61, 4, 13, 46, 40, 61, 4, 9, 42, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 4, 24, 62, 23, 61, 42, 62, 61, 42, 10, 46, 40, 61, 9, 10, 42, 62, 62]\n",
            "iter 100\n",
            "batch loss 0.3531081974506378\n",
            "20 batch loss 0.3463588744401932\n",
            "trg [1, 27, 61, 56, 38, 14, 40, 61, 4, 62, 62, 23, 61, 9, 62, 61, 56, 3, 14, 62, 2]\n",
            "pred [1, 27, 61, 59, 38, 9, 62, 61, 4, 62, 62, 23, 61, 56, 62, 61, 56, 3, 9, 62]\n",
            "iter 120\n",
            "batch loss 0.3604779839515686\n",
            "20 batch loss 0.36877600848674774\n",
            "trg [1, 55, 27, 61, 48, 38, 8, 62, 23, 61, 48, 40, 61, 8, 62, 3, 4, 12, 48, 62, 61, 48, 40, 61, 9, 62, 3, 4, 48, 3, 16, 62, 2]\n",
            "pred [1, 10, 27, 61, 58, 38, 9, 62, 23, 61, 25, 40, 61, 8, 62, 3, 4, 48, 48, 3, 61, 48, 40, 61, 8, 62, 3, 4, 48, 40, 8, 62]\n",
            "iter 140\n",
            "batch loss 0.34840765595436096\n",
            "20 batch loss 0.3565361022949219\n",
            "trg [1, 27, 61, 53, 38, 10, 40, 61, 3, 62, 62, 46, 40, 61, 28, 61, 25, 9, 3, 53, 40, 61, 36, 61, 53, 62, 62, 31, 62, 62, 2]\n",
            "pred [1, 27, 61, 59, 38, 9, 40, 61, 3, 62, 62, 46, 40, 61, 28, 61, 25, 9, 3, 53, 40, 61, 36, 61, 53, 62, 62, 31, 62, 62]\n",
            "iter 160\n",
            "batch loss 0.29756781458854675\n",
            "20 batch loss 0.3656442016363144\n",
            "trg [1, 27, 61, 51, 38, 8, 40, 61, 3, 62, 62, 23, 61, 4, 15, 36, 61, 51, 62, 33, 40, 61, 9, 62, 61, 51, 62, 62, 61, 34, 40, 61, 16, 62, 61, 51, 62, 3, 25, 16, 51, 36, 61, 51, 62, 3, 13, 31, 20, 40, 61, 13, 62, 61, 51, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 8, 40, 61, 3, 62, 62, 23, 61, 4, 13, 34, 61, 51, 62, 34, 40, 61, 9, 62, 61, 51, 62, 62, 61, 34, 40, 61, 9, 62, 61, 51, 62, 3, 25, 9, 51, 36, 61, 51, 62, 3, 9, 31, 36, 40, 61, 8, 62, 61, 51, 62, 62]\n",
            "iter 180\n",
            "batch loss 0.31258970499038696\n",
            "20 batch loss 0.3497239947319031\n",
            "trg [1, 27, 61, 58, 38, 30, 6, 9, 62, 23, 61, 16, 34, 61, 58, 62, 3, 4, 11, 36, 61, 58, 62, 62, 61, 16, 58, 3, 4, 9, 30, 6, 15, 62, 2]\n",
            "pred [1, 27, 61, 48, 38, 30, 6, 10, 62, 23, 61, 36, 36, 61, 58, 62, 3, 4, 9, 20, 61, 58, 62, 62, 61, 9, 58, 3, 4, 10, 30, 6, 10, 62]\n",
            "iter 200\n",
            "batch loss 0.25600558519363403\n",
            "20 batch loss 0.35324387848377226\n",
            "trg [1, 27, 61, 52, 38, 4, 24, 62, 16, 3, 9, 6, 52, 3, 23, 61, 9, 15, 62, 61, 52, 40, 61, 15, 62, 62, 2]\n",
            "pred [1, 27, 61, 59, 38, 4, 24, 62, 26, 3, 4, 6, 52, 3, 23, 61, 9, 62, 62, 61, 52, 40, 61, 16, 62, 62]\n",
            "iter 220\n",
            "batch loss 0.35093894600868225\n",
            "20 batch loss 0.3691579088568687\n",
            "trg [1, 27, 61, 53, 38, 24, 62, 8, 2]\n",
            "pred [1, 27, 61, 54, 38, 24, 62, 9]\n",
            "iter 240\n",
            "batch loss 0.3499757945537567\n",
            "20 batch loss 0.35970384180545806\n",
            "trg [1, 27, 61, 59, 38, 11, 40, 61, 4, 62, 62, 23, 61, 36, 61, 59, 62, 62, 61, 20, 40, 61, 16, 62, 61, 59, 62, 4, 15, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 9, 62, 61, 4, 62, 62, 23, 61, 25, 61, 59, 62, 62, 61, 20, 40, 61, 9, 62, 61, 59, 62, 4, 10, 62]\n",
            "iter 260\n",
            "batch loss 0.4064396619796753\n",
            "20 batch loss 0.3714884266257286\n",
            "trg [1, 27, 61, 58, 38, 24, 62, 23, 61, 23, 61, 45, 62, 61, 45, 58, 62, 58, 62, 61, 23, 61, 45, 62, 61, 45, 58, 62, 25, 15, 15, 58, 3, 11, 31, 62, 2]\n",
            "pred [1, 27, 61, 59, 38, 24, 62, 23, 61, 23, 61, 45, 62, 61, 45, 58, 62, 28, 7, 61, 58, 61, 45, 62, 61, 45, 58, 62, 25, 13, 58, 58, 3, 10, 31, 62]\n",
            "iter 280\n",
            "batch loss 0.3470315635204315\n",
            "20 batch loss 0.3511134430766106\n",
            "trg [1, 17, 27, 61, 59, 38, 30, 6, 11, 62, 23, 61, 9, 34, 61, 59, 62, 3, 4, 10, 36, 61, 59, 62, 62, 61, 14, 59, 3, 4, 13, 30, 6, 16, 62, 2]\n",
            "pred [1, 17, 27, 61, 48, 38, 30, 6, 9, 62, 23, 61, 9, 34, 61, 59, 62, 3, 4, 9, 36, 61, 59, 62, 62, 61, 9, 59, 3, 4, 9, 30, 6, 9, 62]\n",
            "iter 300\n",
            "batch loss 0.3854159712791443\n",
            "20 batch loss 0.3651368752121925\n",
            "trg [1, 27, 61, 58, 38, 9, 40, 61, 3, 62, 62, 23, 61, 4, 14, 34, 61, 58, 62, 36, 40, 61, 15, 62, 61, 58, 62, 62, 61, 20, 40, 61, 9, 62, 61, 58, 62, 3, 25, 15, 58, 34, 61, 58, 62, 3, 9, 31, 20, 40, 61, 10, 62, 61, 58, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 9, 40, 61, 3, 62, 62, 23, 61, 4, 9, 36, 61, 58, 62, 36, 40, 61, 8, 62, 61, 58, 62, 62, 61, 20, 40, 61, 8, 62, 61, 58, 62, 3, 25, 58, 58, 36, 61, 58, 62, 3, 9, 31, 20, 40, 61, 9, 62, 61, 58, 62, 62]\n",
            "iter 320\n",
            "batch loss 0.319216251373291\n",
            "20 batch loss 0.36335594952106476\n",
            "trg [1, 27, 61, 48, 38, 23, 61, 30, 62, 61, 9, 62, 62, 23, 61, 13, 36, 40, 61, 12, 62, 61, 48, 62, 3, 9, 36, 40, 61, 14, 62, 61, 48, 62, 62, 61, 15, 62, 2]\n",
            "pred [1, 27, 61, 57, 38, 23, 61, 30, 62, 61, 9, 62, 62, 23, 61, 9, 34, 40, 61, 9, 62, 61, 48, 62, 3, 4, 22, 40, 61, 9, 62, 61, 48, 62, 62, 61, 9, 62]\n",
            "iter 340\n",
            "batch loss 0.3644636273384094\n",
            "20 batch loss 0.3529025658965111\n",
            "trg [1, 27, 61, 48, 38, 23, 61, 30, 62, 61, 13, 62, 62, 23, 61, 9, 3, 4, 9, 36, 61, 48, 62, 62, 61, 13, 48, 3, 4, 9, 30, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 23, 61, 30, 62, 61, 9, 62, 62, 23, 61, 34, 34, 4, 9, 36, 61, 48, 62, 62, 61, 16, 48, 3, 4, 10, 30, 62]\n",
            "iter 360\n",
            "batch loss 0.3081587851047516\n",
            "20 batch loss 0.3501249745488167\n",
            "trg [1, 27, 61, 55, 38, 4, 24, 62, 9, 3, 7, 3, 55, 2]\n",
            "pred [1, 27, 61, 58, 38, 4, 24, 62, 4, 55, 4, 55, 55]\n",
            "iter 380\n",
            "batch loss 0.3812207579612732\n",
            "20 batch loss 0.36053003668785094\n",
            "trg [1, 27, 61, 44, 38, 15, 40, 61, 3, 62, 62, 22, 40, 61, 20, 61, 25, 44, 31, 62, 62, 25, 44, 31, 2]\n",
            "pred [1, 27, 61, 58, 38, 9, 40, 61, 3, 62, 62, 34, 40, 61, 36, 61, 25, 44, 31, 62, 62, 25, 44, 31]\n",
            "iter 400\n",
            "batch loss 0.3993755877017975\n",
            "20 batch loss 0.3704114153981209\n",
            "trg [1, 17, 27, 61, 53, 38, 24, 62, 23, 61, 4, 15, 25, 36, 61, 12, 6, 53, 62, 3, 4, 9, 12, 6, 53, 20, 61, 9, 6, 53, 62, 31, 62, 61, 4, 11, 53, 40, 61, 4, 10, 62, 62, 2]\n",
            "pred [1, 17, 27, 61, 59, 38, 24, 62, 23, 61, 4, 9, 25, 34, 61, 23, 6, 53, 62, 3, 4, 9, 9, 6, 53, 20, 61, 9, 6, 53, 62, 31, 62, 61, 4, 9, 53, 40, 61, 4, 9, 62, 62]\n",
            "iter 420\n",
            "batch loss 0.32814550399780273\n",
            "20 batch loss 0.35618153065443037\n",
            "trg [1, 27, 61, 56, 38, 11, 62, 23, 61, 10, 19, 16, 56, 20, 61, 25, 10, 56, 31, 62, 62, 61, 10, 56, 11, 34, 61, 25, 56, 31, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 9, 62, 23, 61, 46, 3, 7, 56, 34, 61, 25, 9, 56, 31, 62, 62, 61, 10, 56, 36, 34, 61, 25, 56, 31, 62, 62]\n",
            "iter 440\n",
            "batch loss 0.39564263820648193\n",
            "20 batch loss 0.3624111250042915\n",
            "trg [1, 27, 61, 51, 38, 13, 40, 61, 3, 62, 62, 23, 61, 23, 61, 13, 62, 61, 51, 62, 62, 61, 4, 16, 20, 61, 51, 62, 21, 61, 51, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 9, 40, 61, 3, 62, 62, 23, 61, 23, 61, 10, 62, 61, 51, 62, 62, 61, 4, 9, 36, 61, 51, 62, 20, 61, 51, 62, 62]\n",
            "iter 460\n",
            "batch loss 0.2748158276081085\n",
            "20 batch loss 0.34193808734416964\n",
            "trg [1, 46, 40, 61, 27, 61, 49, 38, 12, 40, 61, 3, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 49, 62, 28, 61, 25, 8, 3, 49, 31, 62, 62, 61, 23, 61, 45, 62, 61, 45, 49, 62, 36, 61, 49, 62, 62, 62, 2]\n",
            "pred [1, 27, 40, 61, 27, 61, 55, 38, 9, 40, 61, 3, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 49, 62, 28, 61, 25, 9, 3, 49, 31, 62, 62, 61, 23, 61, 45, 62, 61, 45, 49, 62, 34, 61, 49, 62, 62, 62]\n",
            "iter 480\n",
            "batch loss 0.2911031246185303\n",
            "20 batch loss 0.34286091923713685\n",
            "trg [1, 27, 61, 58, 38, 15, 40, 61, 3, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 58, 62, 25, 13, 3, 4, 13, 20, 40, 61, 10, 62, 61, 58, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 58, 62, 25, 34, 61, 58, 62, 3, 58, 34, 40, 61, 8, 62, 61, 58, 62, 31, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 8, 40, 61, 3, 62, 62, 23, 61, 4, 61, 45, 62, 61, 45, 58, 62, 34, 34, 58, 4, 9, 34, 61, 61, 9, 62, 61, 58, 62, 62, 62, 61, 23, 61, 45, 62, 61, 45, 58, 62, 58, 58, 61, 58, 62, 3, 4, 31, 31, 61, 10, 62, 61, 58, 62, 62, 62, 2]\n",
            "iter 20\n",
            "batch loss 0.4729965329170227\n",
            "20 batch loss 0.5585597410798073\n",
            "trg [1, 27, 61, 58, 38, 4, 24, 62, 46, 40, 61, 58, 62, 20, 61, 58, 62, 3, 16, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 24, 62, 26, 40, 61, 58, 62, 3, 61, 58, 62, 3, 9]\n",
            "iter 40\n",
            "batch loss 0.40106233954429626\n",
            "20 batch loss 0.48438804745674136\n",
            "trg [1, 27, 61, 59, 38, 24, 62, 23, 61, 29, 41, 61, 16, 7, 62, 61, 16, 62, 62, 61, 29, 41, 61, 16, 11, 62, 61, 14, 62, 62, 2]\n",
            "pred [1, 27, 61, 57, 38, 24, 62, 23, 61, 59, 41, 61, 8, 8, 62, 61, 59, 62, 62, 61, 29, 41, 61, 8, 8, 62, 61, 9, 62, 62, 23]\n",
            "iter 60\n",
            "batch loss 0.5407789945602417\n",
            "20 batch loss 0.5171483471989632\n",
            "trg [1, 27, 61, 48, 38, 8, 40, 61, 3, 62, 62, 23, 61, 4, 10, 36, 61, 48, 62, 36, 40, 61, 9, 62, 61, 48, 62, 62, 61, 34, 40, 61, 9, 62, 61, 48, 62, 3, 25, 10, 48, 36, 61, 48, 62, 3, 15, 31, 34, 40, 61, 7, 62, 61, 48, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 8, 40, 61, 3, 62, 62, 23, 61, 4, 9, 36, 61, 48, 62, 20, 40, 61, 8, 62, 61, 48, 62, 62, 61, 36, 40, 61, 8, 62, 61, 48, 62, 3, 25, 9, 48, 34, 61, 48, 62, 3, 9, 31, 34, 40, 61, 8, 62, 61, 48, 62, 62]\n",
            "iter 80\n",
            "batch loss 0.5096449255943298\n",
            "20 batch loss 0.5119316443800926\n",
            "trg [1, 27, 61, 60, 38, 24, 62, 23, 61, 35, 61, 60, 40, 61, 15, 62, 3, 4, 16, 56, 60, 62, 3, 35, 61, 60, 40, 61, 9, 62, 3, 4, 13, 60, 62, 62, 61, 60, 40, 61, 12, 62, 3, 4, 10, 56, 60, 3, 4, 10, 25, 60, 40, 61, 16, 62, 3, 4, 10, 60, 31, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 9, 62, 23, 61, 25, 58, 4, 9, 31, 25, 35, 61, 9, 58, 3, 9, 62, 3, 10, 31, 62, 61, 10, 25, 58, 4, 8, 31, 62]\n",
            "iter 20\n",
            "batch loss 3.696958541870117\n",
            "20 batch loss 5.072656774520874\n",
            "trg [1, 27, 61, 55, 38, 30, 62, 23, 61, 4, 12, 23, 61, 45, 62, 61, 45, 55, 62, 34, 61, 55, 62, 62, 61, 23, 61, 45, 62, 61, 45, 55, 62, 25, 7, 3, 4, 10, 30, 31, 62, 2]\n",
            "pred [1, 27, 61, 51, 38, 30, 62, 23, 61, 4, 9, 23, 61, 45, 62, 61, 45, 51, 62, 34, 61, 51, 62, 62, 61, 23, 61, 45, 62, 61, 45, 51, 62, 25, 9, 51, 3, 4, 9, 30, 31, 62]\n",
            "iter 40\n",
            "batch loss 5.692999362945557\n",
            "20 batch loss 4.9709667801857\n",
            "trg [1, 27, 61, 47, 38, 14, 40, 61, 3, 62, 62, 34, 61, 47, 62, 3, 4, 14, 23, 61, 9, 62, 61, 47, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 23, 61, 30, 62, 61, 10, 62, 40, 61, 4, 62, 62, 36, 61, 58, 62, 3, 4, 10, 36, 61, 58, 62]\n",
            "iter 60\n",
            "batch loss 6.119447231292725\n",
            "20 batch loss 4.876575946807861\n",
            "trg [1, 27, 61, 50, 38, 12, 40, 61, 3, 62, 62, 23, 61, 8, 3, 4, 16, 34, 40, 61, 12, 62, 61, 50, 62, 62, 61, 36, 3, 50, 34, 40, 61, 8, 62, 61, 50, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 9, 62, 23, 61, 46, 40, 61, 58, 62, 3, 4, 9, 34, 61, 58, 62, 4, 8, 62, 61, 58, 40, 61, 8, 62, 3, 9, 58, 40, 61, 8, 62, 3, 8, 7, 58, 40, 61, 10, 62, 62]\n",
            "iter 80\n",
            "batch loss 5.183969497680664\n",
            "20 batch loss 4.810144078731537\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|  | 7/9 [37:01<10:06, 303.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\tTrain Loss:   0.357 | Train PPL:   1.428\n",
            "\tValid Loss:   0.507 | Valid PPL:   1.660\n",
            "\tTest Loss:   4.926 | Test PPL: 137.797\n",
            "trg [1, 27, 61, 60, 38, 23, 61, 30, 62, 61, 12, 62, 62, 23, 61, 10, 34, 40, 61, 12, 62, 61, 60, 62, 3, 4, 9, 22, 40, 61, 11, 62, 61, 60, 62, 62, 61, 13, 62, 2]\n",
            "pred [1, 27, 61, 54, 38, 23, 61, 30, 62, 61, 10, 62, 62, 23, 61, 9, 20, 40, 61, 10, 62, 61, 60, 62, 3, 4, 10, 36, 40, 61, 12, 62, 61, 60, 62, 62, 61, 15, 62]\n",
            "iter 20\n",
            "batch loss 0.3205740451812744\n",
            "20 batch loss 0.3526390343904495\n",
            "trg [1, 27, 61, 51, 38, 24, 62, 23, 61, 23, 61, 29, 41, 61, 10, 12, 62, 61, 51, 62, 62, 61, 29, 41, 61, 8, 7, 62, 61, 15, 62, 62, 62, 61, 23, 61, 29, 41, 61, 8, 12, 62, 61, 51, 62, 62, 61, 29, 41, 61, 14, 13, 62, 61, 13, 62, 62, 62, 2]\n",
            "pred [1, 27, 61, 55, 38, 24, 62, 23, 61, 23, 61, 29, 41, 61, 8, 8, 62, 61, 51, 62, 62, 61, 29, 41, 61, 8, 7, 62, 61, 8, 62, 62, 62, 61, 23, 61, 29, 41, 61, 8, 7, 62, 61, 51, 62, 62, 61, 29, 41, 61, 8, 9, 62, 61, 8, 62, 62, 62, 2]\n",
            "iter 40\n",
            "batch loss 0.35861894488334656\n",
            "20 batch loss 0.33886961191892623\n",
            "trg [1, 27, 61, 59, 38, 24, 62, 23, 61, 23, 61, 29, 41, 61, 15, 7, 62, 61, 59, 62, 62, 61, 29, 41, 61, 10, 12, 62, 61, 8, 62, 62, 62, 61, 23, 61, 29, 41, 61, 12, 8, 62, 61, 59, 62, 62, 61, 29, 41, 61, 11, 13, 62, 61, 7, 62, 62, 62, 2]\n",
            "pred [1, 27, 61, 55, 38, 24, 62, 23, 61, 23, 61, 29, 41, 61, 10, 13, 62, 61, 59, 62, 62, 61, 29, 41, 61, 9, 9, 62, 61, 9, 62, 62, 62, 61, 23, 61, 29, 41, 61, 8, 13, 62, 61, 59, 62, 62, 61, 29, 41, 61, 9, 13, 62, 61, 9, 62, 62, 62, 2]\n",
            "iter 60\n",
            "batch loss 0.3322599232196808\n",
            "20 batch loss 0.3455511718988419\n",
            "trg [1, 27, 61, 51, 38, 9, 40, 61, 3, 62, 62, 23, 61, 4, 14, 36, 61, 51, 62, 33, 40, 61, 9, 62, 61, 51, 62, 62, 61, 22, 40, 61, 7, 62, 61, 51, 62, 3, 25, 14, 51, 36, 61, 51, 62, 3, 13, 31, 36, 40, 61, 8, 62, 61, 51, 62, 62, 2]\n",
            "pred [1, 27, 61, 59, 38, 8, 40, 61, 3, 62, 62, 23, 61, 4, 36, 36, 61, 51, 62, 36, 40, 61, 10, 62, 61, 51, 62, 62, 61, 34, 40, 61, 8, 62, 61, 51, 62, 3, 25, 10, 51, 34, 61, 51, 62, 3, 8, 31, 20, 40, 61, 8, 62, 61, 51, 62, 62]\n",
            "iter 80\n",
            "batch loss 0.40035295486450195\n",
            "20 batch loss 0.3401481777429581\n",
            "trg [1, 27, 61, 43, 38, 12, 40, 61, 3, 62, 62, 23, 61, 12, 6, 43, 62, 61, 4, 15, 34, 61, 43, 62, 34, 61, 43, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 9, 40, 61, 3, 62, 62, 23, 61, 11, 6, 43, 62, 61, 4, 9, 36, 61, 43, 62, 36, 61, 43, 62, 62]\n",
            "iter 100\n",
            "batch loss 0.3394225537776947\n",
            "20 batch loss 0.35035222619771955\n",
            "trg [1, 27, 61, 49, 38, 24, 62, 23, 61, 23, 61, 29, 41, 61, 7, 62, 61, 49, 62, 62, 61, 29, 41, 61, 8, 7, 62, 61, 16, 62, 62, 62, 61, 23, 61, 29, 41, 61, 8, 12, 62, 61, 49, 62, 62, 61, 29, 41, 61, 14, 10, 62, 61, 7, 62, 62, 62, 2]\n",
            "pred [1, 27, 61, 54, 38, 24, 62, 23, 61, 23, 61, 29, 41, 61, 9, 9, 61, 49, 62, 62, 61, 29, 41, 61, 8, 9, 62, 61, 9, 62, 62, 62, 61, 23, 61, 29, 41, 61, 9, 9, 62, 61, 49, 62, 62, 61, 29, 41, 61, 9, 9, 62, 61, 9, 62, 62, 62, 2]\n",
            "iter 120\n",
            "batch loss 0.3137226402759552\n",
            "20 batch loss 0.35030102282762526\n",
            "trg [1, 27, 61, 54, 38, 10, 62, 23, 61, 14, 34, 61, 25, 12, 54, 31, 62, 62, 61, 13, 54, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 23, 61, 25, 3, 61, 25, 16, 54, 31, 62, 62, 61, 11, 54, 62]\n",
            "iter 140\n",
            "batch loss 0.3284689486026764\n",
            "20 batch loss 0.35943066477775576\n",
            "trg [1, 27, 61, 48, 38, 9, 62, 23, 61, 48, 40, 61, 11, 62, 4, 12, 62, 61, 48, 4, 9, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 9, 62, 23, 61, 46, 40, 61, 9, 62, 4, 10, 62, 61, 48, 4, 10, 62]\n",
            "iter 160\n",
            "batch loss 0.35257774591445923\n",
            "20 batch loss 0.3499204754829407\n",
            "trg [1, 23, 61, 27, 61, 57, 38, 9, 62, 10, 25, 9, 6, 13, 25, 10, 57, 3, 25, 4, 9, 57, 40, 61, 9, 62, 31, 40, 61, 9, 6, 12, 62, 31, 25, 9, 3, 4, 16, 57, 40, 61, 10, 62, 31, 3, 4, 14, 14, 6, 10, 57, 40, 61, 11, 6, 12, 62, 31, 62, 61, 27, 61, 57, 38, 12, 62, 23, 61, 45, 62, 61, 45, 57, 62, 10, 3, 4, 16, 23, 61, 45, 62, 61, 45, 57, 62, 57, 40, 61, 9, 6, 12, 62, 62, 2]\n",
            "pred [1, 23, 61, 27, 61, 48, 38, 9, 62, 23, 25, 34, 34, 57, 25, 57, 57, 3, 25, 4, 9, 57, 40, 61, 9, 62, 31, 40, 61, 9, 62, 57, 62, 31, 25, 11, 3, 4, 11, 57, 40, 61, 9, 62, 31, 62, 4, 14, 23, 6, 55, 55, 40, 61, 9, 6, 57, 62, 31, 62, 61, 27, 61, 57, 38, 9, 62, 23, 61, 45, 62, 61, 45, 57, 62, 11, 3, 4, 9, 23, 61, 45, 62, 61, 45, 57, 62, 57, 40, 61, 9, 6, 9, 62, 62, 2]\n",
            "iter 180\n",
            "batch loss 0.27962562441825867\n",
            "20 batch loss 0.35500523149967195\n",
            "trg [1, 27, 61, 55, 38, 30, 6, 14, 62, 23, 61, 9, 20, 40, 61, 9, 62, 61, 55, 62, 3, 13, 33, 40, 61, 13, 62, 61, 55, 62, 62, 61, 13, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 30, 6, 12, 62, 23, 61, 9, 20, 40, 61, 10, 62, 61, 55, 62, 3, 4, 34, 40, 61, 9, 62, 61, 55, 62, 62, 61, 9, 62]\n",
            "iter 200\n",
            "batch loss 0.35627421736717224\n",
            "20 batch loss 0.34752250611782076\n",
            "trg [1, 27, 61, 60, 38, 24, 62, 23, 61, 25, 60, 4, 15, 31, 25, 60, 4, 16, 31, 62, 61, 60, 4, 12, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 23, 61, 25, 60, 4, 9, 31, 25, 60, 4, 9, 31, 62, 61, 60, 4, 9, 62]\n",
            "iter 220\n",
            "batch loss 0.3267247676849365\n",
            "20 batch loss 0.365790356695652\n",
            "trg [1, 27, 61, 59, 38, 9, 62, 23, 61, 25, 59, 4, 10, 31, 25, 59, 3, 10, 31, 62, 61, 59, 4, 9, 62, 2]\n",
            "pred [1, 27, 61, 59, 38, 9, 62, 23, 61, 25, 59, 4, 9, 31, 25, 59, 3, 9, 31, 62, 61, 59, 4, 8, 62]\n",
            "iter 240\n",
            "batch loss 0.3057268559932709\n",
            "20 batch loss 0.3446785569190979\n",
            "trg [1, 17, 23, 61, 27, 61, 57, 38, 23, 61, 30, 62, 61, 11, 62, 40, 61, 4, 62, 62, 36, 61, 57, 62, 62, 61, 27, 61, 57, 38, 23, 61, 30, 62, 61, 9, 62, 40, 61, 4, 62, 62, 4, 11, 34, 40, 61, 15, 62, 61, 57, 62, 62, 2]\n",
            "pred [1, 17, 23, 61, 27, 61, 58, 38, 23, 61, 30, 62, 61, 9, 62, 40, 61, 4, 62, 62, 20, 61, 57, 62, 62, 61, 27, 61, 57, 38, 23, 61, 30, 62, 61, 9, 62, 40, 61, 4, 62, 62, 4, 9, 33, 40, 61, 9, 62, 61, 57, 62, 62]\n",
            "iter 260\n",
            "batch loss 0.33190739154815674\n",
            "20 batch loss 0.3335874989628792\n",
            "trg [1, 27, 61, 53, 38, 8, 62, 23, 61, 53, 40, 61, 7, 62, 3, 53, 4, 8, 62, 61, 53, 40, 61, 16, 62, 3, 4, 16, 53, 3, 9, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 8, 62, 23, 61, 53, 40, 61, 8, 62, 3, 4, 4, 8, 62, 61, 53, 40, 61, 8, 62, 3, 4, 53, 53, 3, 9, 62]\n",
            "iter 280\n",
            "batch loss 0.39763057231903076\n",
            "20 batch loss 0.3270053878426552\n",
            "trg [1, 27, 61, 48, 38, 24, 62, 23, 61, 9, 12, 48, 3, 11, 62, 61, 16, 9, 48, 3, 8, 13, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 23, 61, 9, 48, 48, 3, 9, 62, 61, 9, 48, 48, 3, 9, 62, 62]\n",
            "iter 300\n",
            "batch loss 0.4472200572490692\n",
            "20 batch loss 0.3419121727347374\n",
            "trg [1, 27, 61, 55, 38, 16, 40, 61, 3, 62, 62, 23, 61, 11, 6, 55, 62, 61, 4, 13, 34, 61, 55, 62, 21, 61, 55, 62, 62, 2]\n",
            "pred [1, 27, 61, 55, 38, 9, 40, 61, 3, 62, 62, 23, 61, 9, 6, 55, 62, 61, 4, 9, 20, 61, 55, 62, 36, 61, 55, 62, 62]\n",
            "iter 320\n",
            "batch loss 0.3163568377494812\n",
            "20 batch loss 0.3427462190389633\n",
            "trg [1, 27, 61, 43, 38, 23, 61, 30, 62, 61, 16, 62, 40, 61, 4, 62, 62, 36, 40, 61, 22, 61, 25, 43, 31, 62, 62, 25, 43, 31, 2]\n",
            "pred [1, 27, 61, 55, 38, 23, 61, 30, 62, 61, 10, 62, 40, 61, 4, 62, 62, 36, 61, 61, 36, 61, 25, 43, 31, 62, 62, 25, 43, 31]\n",
            "iter 340\n",
            "batch loss 0.40748122334480286\n",
            "20 batch loss 0.3482844829559326\n",
            "trg [1, 27, 61, 47, 38, 10, 62, 23, 61, 47, 4, 13, 62, 61, 47, 25, 47, 4, 14, 31, 25, 47, 40, 61, 7, 62, 3, 12, 47, 31, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 9, 62, 23, 61, 47, 4, 9, 62, 61, 47, 40, 47, 4, 8, 31, 25, 47, 40, 61, 9, 62, 3, 47, 47, 4, 62]\n",
            "iter 360\n",
            "batch loss 0.3539475202560425\n",
            "20 batch loss 0.3565629690885544\n",
            "trg [1, 27, 61, 50, 38, 9, 40, 61, 3, 62, 62, 4, 16, 23, 61, 23, 61, 45, 62, 61, 45, 50, 62, 34, 40, 61, 11, 62, 61, 50, 62, 62, 61, 23, 61, 45, 62, 61, 45, 50, 62, 50, 20, 61, 50, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 9, 40, 61, 3, 62, 62, 4, 23, 23, 61, 23, 61, 45, 62, 61, 45, 50, 62, 36, 40, 61, 9, 62, 61, 50, 62, 62, 61, 23, 61, 45, 62, 61, 45, 50, 62, 50, 36, 61, 50, 62, 62]\n",
            "iter 380\n",
            "batch loss 0.2934543192386627\n",
            "20 batch loss 0.33798962384462355\n",
            "trg [1, 27, 61, 57, 38, 24, 62, 23, 61, 12, 62, 61, 9, 57, 40, 61, 13, 62, 3, 4, 10, 35, 61, 10, 57, 40, 61, 12, 62, 3, 4, 12, 57, 40, 61, 12, 62, 62, 62, 23, 61, 15, 57, 40, 61, 9, 62, 3, 35, 61, 9, 57, 40, 61, 11, 62, 3, 4, 10, 57, 40, 61, 10, 62, 62, 62, 61, 11, 57, 40, 61, 9, 62, 3, 35, 61, 13, 57, 40, 61, 10, 62, 3, 4, 14, 57, 40, 61, 13, 62, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 23, 61, 10, 62, 61, 35, 57, 40, 61, 9, 62, 3, 35, 35, 35, 61, 10, 57, 40, 61, 9, 62, 3, 4, 9, 57, 40, 61, 8, 62, 62, 62, 61, 57, 57, 40, 61, 9, 62, 3, 35, 61, 10, 57, 40, 61, 9, 62, 3, 4, 10, 57, 40, 61, 9, 62, 62, 62, 61, 57, 57, 40, 61, 9, 62, 3, 35, 61, 57, 57, 40, 61, 8, 62, 3, 9, 10, 57, 40, 61, 7, 62, 62, 62]\n",
            "iter 400\n",
            "batch loss 0.26878654956817627\n",
            "20 batch loss 0.3436502397060394\n",
            "trg [1, 23, 61, 27, 61, 42, 38, 12, 62, 23, 61, 45, 62, 61, 45, 42, 62, 13, 14, 36, 61, 25, 10, 42, 31, 62, 34, 61, 25, 7, 31, 62, 62, 61, 27, 61, 42, 38, 8, 62, 23, 61, 45, 62, 61, 45, 42, 62, 16, 42, 62, 2]\n",
            "pred [1, 23, 61, 27, 61, 48, 38, 9, 62, 23, 61, 45, 62, 61, 45, 42, 62, 9, 9, 34, 61, 25, 11, 42, 31, 62, 34, 61, 25, 42, 31, 62, 62, 61, 27, 61, 42, 38, 9, 62, 23, 61, 45, 62, 61, 45, 42, 62, 42, 42, 62]\n",
            "iter 420\n",
            "batch loss 0.3274482786655426\n",
            "20 batch loss 0.3501968264579773\n",
            "trg [1, 17, 27, 61, 50, 38, 30, 6, 12, 62, 23, 61, 36, 40, 61, 10, 62, 61, 50, 62, 3, 20, 40, 61, 12, 62, 61, 50, 62, 62, 61, 14, 62, 2]\n",
            "pred [1, 17, 27, 61, 58, 38, 30, 6, 9, 62, 23, 61, 20, 40, 61, 9, 62, 61, 50, 62, 3, 20, 40, 61, 9, 62, 61, 50, 62, 62, 61, 9, 62]\n",
            "iter 440\n",
            "batch loss 0.3275015354156494\n",
            "20 batch loss 0.3498451247811317\n",
            "trg [1, 27, 61, 57, 38, 30, 6, 14, 62, 23, 61, 36, 61, 57, 62, 3, 4, 10, 22, 61, 57, 62, 62, 61, 57, 3, 4, 10, 30, 6, 12, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 30, 6, 9, 62, 23, 61, 34, 61, 57, 62, 3, 4, 10, 20, 61, 57, 62, 62, 61, 57, 3, 4, 10, 30, 6, 9, 62]\n",
            "iter 460\n",
            "batch loss 0.2929104268550873\n",
            "20 batch loss 0.34866069108247755\n",
            "trg [1, 27, 61, 37, 38, 30, 6, 10, 40, 61, 4, 62, 62, 20, 61, 37, 62, 3, 4, 14, 34, 61, 37, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 30, 6, 9, 40, 61, 4, 62, 62, 34, 61, 37, 62, 3, 4, 10, 36, 61, 37, 62]\n",
            "iter 480\n",
            "batch loss 0.3491319715976715\n",
            "20 batch loss 0.3551951736211777\n",
            "trg [1, 17, 27, 61, 43, 38, 16, 62, 43, 40, 61, 8, 62, 3, 4, 12, 43, 3, 9, 2]\n",
            "pred [1, 17, 27, 61, 58, 38, 9, 62, 10, 3, 61, 9, 62, 3, 4, 9, 43, 3, 8]\n",
            "iter 20\n",
            "batch loss 0.4203106164932251\n",
            "20 batch loss 0.5159889131784439\n",
            "trg [1, 27, 61, 54, 38, 13, 40, 61, 3, 62, 62, 23, 61, 4, 36, 61, 54, 62, 34, 40, 61, 11, 62, 61, 54, 62, 62, 61, 34, 40, 61, 15, 62, 61, 54, 62, 3, 25, 54, 22, 61, 54, 62, 3, 16, 31, 20, 40, 61, 8, 62, 61, 54, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 9, 40, 61, 3, 62, 62, 23, 61, 4, 16, 61, 54, 62, 20, 40, 61, 9, 62, 61, 54, 62, 62, 61, 34, 40, 61, 9, 62, 61, 54, 62, 3, 25, 9, 34, 61, 54, 62, 3, 9, 31, 36, 40, 61, 8, 62, 61, 54, 62, 62]\n",
            "iter 40\n",
            "batch loss 0.42532700300216675\n",
            "20 batch loss 0.4968304008245468\n",
            "trg [1, 27, 61, 60, 38, 30, 6, 9, 62, 36, 40, 61, 11, 62, 61, 60, 62, 3, 34, 40, 61, 9, 62, 61, 60, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 30, 6, 9, 40, 34, 40, 61, 9, 62, 61, 60, 62, 3, 34, 40, 61, 9, 62, 61, 60, 62]\n",
            "iter 60\n",
            "batch loss 0.40993669629096985\n",
            "20 batch loss 0.526279878616333\n",
            "trg [1, 17, 27, 61, 54, 38, 9, 40, 61, 4, 62, 62, 23, 61, 54, 4, 9, 62, 61, 54, 40, 61, 13, 62, 3, 4, 12, 54, 62, 2]\n",
            "pred [1, 17, 27, 61, 58, 38, 9, 40, 61, 3, 62, 62, 23, 61, 54, 62, 9, 62, 61, 54, 3, 61, 9, 62, 62, 4, 14, 54, 62]\n",
            "iter 80\n",
            "batch loss 0.5446807146072388\n",
            "20 batch loss 0.5139362394809723\n",
            "trg [1, 27, 61, 57, 38, 13, 40, 61, 3, 62, 62, 23, 61, 23, 61, 16, 3, 9, 57, 62, 61, 57, 62, 62, 61, 23, 61, 57, 3, 57, 28, 61, 57, 62, 4, 12, 62, 61, 57, 62, 62, 2]\n",
            "pred [1, 27, 61, 57, 38, 9, 62, 23, 61, 23, 61, 9, 62, 61, 57, 40, 61, 11, 62, 3, 9, 57, 62, 3, 4, 10, 23, 61, 10, 62, 61, 57, 62, 62, 61, 23, 61, 45, 62, 61, 45, 57, 62, 35, 61, 57, 62, 62]\n",
            "iter 20\n",
            "batch loss 5.865234851837158\n",
            "20 batch loss 5.505327987670898\n",
            "trg [1, 27, 61, 59, 38, 16, 62, 23, 61, 34, 61, 25, 13, 59, 31, 62, 62, 61, 59, 62, 12, 6, 9, 2]\n",
            "pred [1, 27, 61, 59, 38, 9, 62, 23, 61, 34, 61, 25, 9, 59, 31, 62, 62, 61, 59, 62]\n",
            "iter 40\n",
            "batch loss 5.597382068634033\n",
            "20 batch loss 5.2874980688095095\n",
            "trg [1, 27, 61, 48, 38, 23, 61, 30, 62, 61, 10, 62, 62, 23, 61, 12, 36, 40, 61, 12, 62, 61, 48, 62, 3, 10, 36, 40, 61, 16, 62, 61, 48, 62, 62, 61, 11, 62, 2]\n",
            "pred [1, 27, 61, 57, 38, 23, 61, 30, 62, 61, 9, 62, 62, 23, 61, 9, 34, 40, 61, 9, 62, 61, 57, 62, 3, 4, 9, 20, 40, 61, 9, 62, 61, 57, 62, 62, 61, 9, 62]\n",
            "iter 60\n",
            "batch loss 4.513293743133545\n",
            "20 batch loss 5.290702545642853\n",
            "trg [1, 27, 61, 48, 38, 4, 12, 62, 23, 61, 4, 12, 48, 40, 61, 14, 62, 3, 15, 62, 61, 14, 48, 4, 8, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 9, 62, 23, 61, 58, 40, 61, 9, 62, 3, 4, 9, 58, 3, 8, 62, 61, 58, 40, 61, 8, 62, 4, 10, 62]\n",
            "iter 80\n",
            "batch loss 5.157160758972168\n",
            "20 batch loss 5.278824627399445\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%| | 8/9 [42:01<05:02, 302.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\tTrain Loss:   0.347 | Train PPL:   1.414\n",
            "\tValid Loss:   0.507 | Valid PPL:   1.660\n",
            "\tTest Loss:   5.233 | Test PPL: 187.355\n",
            "trg [1, 27, 61, 53, 38, 24, 62, 23, 61, 16, 53, 40, 61, 9, 62, 3, 53, 34, 61, 53, 62, 62, 61, 53, 40, 61, 14, 62, 62, 2]\n",
            "pred [1, 27, 61, 57, 38, 24, 62, 23, 61, 25, 53, 40, 61, 8, 62, 3, 53, 34, 61, 53, 62, 62, 61, 53, 40, 61, 9, 62, 62]\n",
            "iter 20\n",
            "batch loss 0.27997252345085144\n",
            "20 batch loss 0.3502157524228096\n",
            "trg [1, 27, 61, 55, 38, 15, 40, 61, 4, 62, 62, 23, 61, 36, 61, 55, 62, 62, 61, 36, 40, 61, 8, 62, 61, 55, 62, 4, 11, 62, 2]\n",
            "pred [1, 27, 61, 57, 38, 4, 62, 61, 3, 62, 62, 23, 61, 55, 61, 55, 62, 62, 61, 36, 40, 61, 9, 62, 61, 55, 62, 4, 9, 62]\n",
            "iter 40\n",
            "batch loss 0.3586333692073822\n",
            "20 batch loss 0.3197669818997383\n",
            "trg [1, 27, 61, 48, 38, 10, 40, 61, 3, 62, 62, 21, 61, 48, 62, 3, 4, 16, 23, 61, 16, 62, 61, 48, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 9, 40, 61, 3, 62, 62, 34, 61, 48, 62, 3, 4, 10, 23, 61, 9, 62, 61, 48, 62]\n",
            "iter 60\n",
            "batch loss 0.2996523082256317\n",
            "20 batch loss 0.3471584960818291\n",
            "trg [1, 27, 61, 43, 38, 30, 6, 11, 62, 23, 61, 36, 61, 43, 62, 3, 4, 13, 34, 61, 43, 62, 62, 61, 43, 3, 4, 11, 30, 6, 14, 62, 2]\n",
            "pred [1, 27, 61, 48, 38, 30, 6, 9, 62, 23, 61, 34, 61, 43, 62, 3, 4, 9, 36, 61, 43, 62, 62, 61, 43, 3, 4, 9, 30, 6, 9, 62]\n",
            "iter 80\n",
            "batch loss 0.36855730414390564\n",
            "20 batch loss 0.33326293230056764\n",
            "trg [1, 27, 61, 55, 38, 24, 62, 23, 61, 23, 61, 45, 62, 61, 45, 55, 62, 25, 13, 10, 55, 3, 11, 31, 62, 61, 23, 61, 45, 62, 61, 45, 55, 62, 25, 8, 7, 3, 8, 31, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 23, 61, 23, 61, 45, 62, 61, 45, 55, 62, 25, 55, 55, 55, 3, 9, 31, 62, 61, 23, 61, 45, 62, 61, 45, 55, 62, 25, 28, 7, 3, 11, 31, 62]\n",
            "iter 100\n",
            "batch loss 0.3835448622703552\n",
            "20 batch loss 0.3282857283949852\n",
            "trg [1, 27, 61, 54, 38, 15, 62, 23, 61, 34, 40, 61, 14, 62, 61, 54, 62, 62, 61, 14, 3, 4, 9, 34, 61, 54, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 9, 62, 23, 61, 34, 40, 61, 7, 62, 61, 54, 62, 62, 61, 10, 3, 4, 16, 34, 61, 54, 62, 62]\n",
            "iter 120\n",
            "batch loss 0.33436647057533264\n",
            "20 batch loss 0.33366804122924804\n",
            "trg [1, 27, 61, 42, 38, 24, 62, 23, 61, 26, 42, 32, 62, 61, 7, 62, 2]\n",
            "pred [1, 27, 61, 59, 38, 24, 62, 23, 61, 26, 42, 32, 62, 61, 42, 62]\n",
            "iter 140\n",
            "batch loss 0.30788707733154297\n",
            "20 batch loss 0.31840226203203204\n",
            "trg [1, 27, 61, 37, 38, 24, 62, 23, 61, 4, 9, 25, 36, 61, 23, 61, 10, 62, 61, 37, 62, 62, 3, 4, 14, 23, 61, 12, 62, 61, 37, 62, 33, 61, 23, 61, 14, 62, 61, 37, 62, 62, 31, 62, 61, 4, 13, 37, 40, 61, 4, 15, 62, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 24, 62, 23, 61, 4, 9, 25, 34, 61, 23, 61, 10, 62, 61, 37, 62, 62, 3, 4, 9, 23, 61, 9, 62, 61, 37, 62, 34, 61, 23, 61, 9, 62, 61, 37, 62, 62, 31, 62, 61, 4, 9, 37, 40, 61, 4, 9, 62, 62]\n",
            "iter 160\n",
            "batch loss 0.33054813742637634\n",
            "20 batch loss 0.33250562846660614\n",
            "trg [1, 27, 61, 55, 38, 24, 62, 36, 40, 61, 55, 40, 61, 13, 62, 62, 23, 61, 13, 62, 61, 55, 40, 61, 16, 62, 62, 2]\n",
            "pred [1, 27, 61, 57, 38, 4, 62, 34, 40, 61, 55, 62, 61, 14, 62, 62, 23, 61, 9, 62, 61, 55, 40, 61, 9, 62, 62]\n",
            "iter 180\n",
            "batch loss 0.29427674412727356\n",
            "20 batch loss 0.3390920028090477\n",
            "trg [1, 27, 61, 48, 38, 9, 40, 61, 3, 62, 62, 23, 61, 48, 62, 61, 48, 21, 61, 48, 62, 62, 3, 9, 23, 61, 34, 61, 48, 62, 62, 61, 48, 34, 61, 48, 62, 62, 2]\n",
            "pred [1, 27, 61, 55, 38, 9, 40, 61, 3, 62, 62, 23, 61, 11, 3, 61, 35, 3, 61, 48, 62, 62, 3, 9, 23, 61, 48, 61, 48, 62, 62, 61, 48, 34, 61, 48, 62, 62]\n",
            "iter 200\n",
            "batch loss 0.3871435821056366\n",
            "20 batch loss 0.3430928513407707\n",
            "trg [1, 27, 61, 50, 38, 4, 24, 62, 23, 61, 4, 13, 8, 62, 61, 9, 62, 2]\n",
            "pred [1, 27, 61, 53, 38, 24, 24, 62, 23, 61, 9, 15, 62, 62, 61, 9, 62]\n",
            "iter 220\n",
            "batch loss 0.3105328381061554\n",
            "20 batch loss 0.3319105848670006\n",
            "trg [1, 27, 61, 37, 38, 14, 40, 61, 3, 62, 62, 36, 61, 37, 62, 3, 4, 12, 23, 61, 9, 62, 61, 37, 62, 2]\n",
            "pred [1, 27, 61, 59, 38, 9, 40, 61, 3, 62, 62, 34, 40, 37, 62, 3, 4, 9, 23, 61, 11, 62, 61, 37, 62]\n",
            "iter 240\n",
            "batch loss 0.3029356002807617\n",
            "20 batch loss 0.3441074460744858\n",
            "trg [1, 27, 61, 52, 38, 8, 62, 52, 40, 61, 12, 62, 3, 13, 52, 40, 61, 12, 62, 3, 9, 52, 40, 61, 13, 62, 3, 16, 52, 3, 15, 2]\n",
            "pred [1, 27, 61, 58, 38, 10, 62, 25, 40, 61, 9, 62, 3, 4, 52, 40, 61, 10, 62, 3, 10, 52, 40, 61, 16, 62, 3, 10, 52, 3, 10, 31]\n",
            "iter 260\n",
            "batch loss 0.34766650199890137\n",
            "20 batch loss 0.3479929998517036\n",
            "trg [1, 27, 61, 58, 38, 23, 61, 30, 62, 61, 9, 62, 40, 61, 4, 62, 62, 36, 61, 58, 62, 3, 4, 10, 34, 61, 58, 62, 2]\n",
            "pred [1, 27, 61, 57, 38, 23, 61, 30, 62, 61, 9, 62, 40, 61, 4, 62, 62, 34, 61, 58, 62, 3, 4, 16, 20, 61, 58, 62]\n",
            "iter 280\n",
            "batch loss 0.3558979332447052\n",
            "20 batch loss 0.3399132028222084\n",
            "trg [1, 27, 61, 42, 38, 10, 62, 23, 61, 42, 3, 7, 62, 61, 26, 42, 4, 14, 32, 62, 2]\n",
            "pred [1, 27, 61, 55, 38, 24, 62, 23, 61, 42, 4, 9, 62, 61, 42, 42, 4, 15, 32, 62]\n",
            "iter 300\n",
            "batch loss 0.370090126991272\n",
            "20 batch loss 0.34653701931238173\n",
            "trg [1, 27, 61, 44, 38, 23, 61, 30, 62, 61, 10, 62, 62, 23, 61, 36, 61, 44, 62, 4, 10, 62, 61, 35, 61, 36, 61, 44, 62, 62, 4, 13, 62, 2]\n",
            "pred [1, 27, 61, 51, 38, 23, 61, 30, 62, 61, 9, 62, 62, 23, 61, 20, 61, 44, 62, 3, 9, 62, 61, 35, 61, 34, 61, 44, 62, 62, 62, 13, 62]\n",
            "iter 320\n",
            "batch loss 0.3330146074295044\n",
            "20 batch loss 0.3492004856467247\n",
            "trg [1, 27, 61, 47, 38, 14, 40, 61, 3, 62, 62, 4, 12, 23, 61, 8, 33, 61, 47, 62, 36, 61, 47, 62, 62, 61, 36, 61, 47, 62, 3, 4, 15, 47, 20, 61, 47, 62, 62, 2]\n",
            "pred [1, 27, 61, 59, 38, 8, 40, 61, 3, 62, 62, 4, 9, 23, 61, 9, 36, 61, 47, 62, 36, 61, 47, 62, 62, 61, 34, 61, 47, 62, 3, 4, 9, 47, 20, 61, 47, 62, 62]\n",
            "iter 340\n",
            "batch loss 0.36226072907447815\n",
            "20 batch loss 0.32844953089952467\n",
            "trg [1, 27, 61, 50, 38, 30, 6, 9, 62, 34, 40, 61, 10, 62, 61, 50, 62, 3, 22, 40, 61, 9, 62, 61, 50, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 30, 6, 9, 62, 20, 40, 61, 9, 62, 61, 50, 62, 3, 20, 40, 61, 15, 62, 61, 50, 62]\n",
            "iter 360\n",
            "batch loss 0.3222356140613556\n",
            "20 batch loss 0.3320124357938766\n",
            "trg [1, 27, 61, 49, 38, 9, 40, 61, 3, 62, 62, 36, 40, 61, 36, 61, 25, 49, 31, 62, 62, 25, 49, 31, 2]\n",
            "pred [1, 27, 61, 57, 38, 9, 40, 61, 3, 62, 62, 34, 40, 61, 36, 61, 25, 49, 31, 62, 62, 25, 49, 31]\n",
            "iter 380\n",
            "batch loss 0.3103746771812439\n",
            "20 batch loss 0.33488949537277224\n",
            "trg [1, 28, 61, 42, 62, 17, 23, 61, 27, 61, 57, 38, 23, 61, 30, 62, 61, 14, 62, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 57, 62, 34, 61, 57, 62, 62, 61, 27, 61, 57, 38, 23, 61, 30, 62, 61, 11, 62, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 57, 62, 4, 13, 20, 40, 61, 14, 62, 61, 57, 62, 62, 2]\n",
            "pred [1, 28, 61, 58, 62, 17, 23, 61, 27, 61, 58, 38, 23, 61, 30, 62, 61, 10, 62, 40, 61, 4, 62, 62, 36, 61, 45, 62, 61, 45, 57, 62, 36, 61, 57, 62, 62, 61, 27, 61, 57, 38, 23, 61, 30, 62, 61, 10, 62, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 57, 62, 4, 16, 36, 40, 61, 9, 62, 61, 57, 62, 62, 2]\n",
            "iter 400\n",
            "batch loss 0.3064486086368561\n",
            "20 batch loss 0.3340737998485565\n",
            "trg [1, 27, 61, 58, 38, 30, 6, 9, 62, 23, 61, 11, 34, 61, 58, 62, 3, 4, 16, 21, 61, 58, 62, 62, 61, 11, 58, 3, 4, 11, 30, 6, 14, 62, 2]\n",
            "pred [1, 27, 61, 57, 38, 30, 6, 9, 62, 23, 61, 9, 34, 61, 58, 62, 3, 4, 9, 36, 61, 58, 62, 62, 61, 9, 58, 3, 4, 13, 30, 6, 9, 62]\n",
            "iter 420\n",
            "batch loss 0.28117790818214417\n",
            "20 batch loss 0.3360120430588722\n",
            "trg [1, 27, 61, 60, 38, 4, 24, 62, 23, 61, 8, 60, 40, 61, 11, 62, 3, 10, 60, 40, 61, 12, 62, 3, 4, 15, 60, 62, 61, 8, 7, 60, 40, 61, 16, 62, 3, 60, 40, 61, 12, 62, 3, 14, 60, 3, 13, 62, 2]\n",
            "pred [1, 27, 61, 59, 38, 24, 24, 62, 23, 61, 60, 60, 40, 61, 9, 62, 3, 9, 62, 40, 61, 9, 62, 3, 9, 15, 60, 62, 61, 8, 7, 60, 40, 61, 9, 62, 3, 60, 40, 61, 10, 62, 3, 9, 60, 3, 10, 62]\n",
            "iter 440\n",
            "batch loss 0.3339572846889496\n",
            "20 batch loss 0.341678224503994\n",
            "trg [1, 23, 61, 27, 61, 57, 38, 10, 62, 23, 61, 45, 62, 61, 45, 57, 62, 9, 15, 20, 61, 25, 9, 57, 31, 62, 20, 61, 25, 12, 57, 31, 62, 62, 61, 27, 61, 57, 38, 11, 62, 23, 61, 45, 62, 61, 45, 57, 62, 57, 62, 2]\n",
            "pred [1, 23, 61, 27, 61, 57, 38, 8, 62, 23, 61, 45, 62, 61, 45, 57, 62, 9, 8, 34, 61, 25, 57, 57, 31, 62, 20, 61, 25, 9, 57, 31, 62, 62, 61, 27, 61, 57, 38, 9, 62, 23, 61, 45, 62, 61, 45, 57, 62, 10, 62]\n",
            "iter 460\n",
            "batch loss 0.3600323796272278\n",
            "20 batch loss 0.34066434353590014\n",
            "trg [1, 27, 61, 42, 38, 24, 62, 23, 61, 9, 42, 62, 61, 10, 42, 40, 61, 9, 62, 62, 2]\n",
            "pred [1, 27, 61, 48, 38, 24, 62, 23, 61, 9, 42, 62, 61, 8, 42, 62, 61, 9, 62, 62]\n",
            "iter 480\n",
            "batch loss 0.3268362879753113\n",
            "20 batch loss 0.33564750850200653\n",
            "trg [1, 27, 61, 37, 38, 30, 6, 16, 62, 23, 61, 33, 61, 37, 62, 62, 61, 20, 61, 37, 62, 62, 2]\n",
            "pred [1, 46, 61, 58, 38, 30, 6, 9, 62, 23, 61, 20, 61, 37, 62, 62, 61, 11, 61, 37, 62, 3, 3]\n",
            "iter 20\n",
            "batch loss 0.4039589464664459\n",
            "20 batch loss 0.5530259683728218\n",
            "trg [1, 27, 61, 58, 38, 23, 61, 30, 62, 61, 9, 62, 62, 23, 61, 33, 40, 61, 9, 62, 61, 58, 62, 3, 20, 40, 61, 16, 62, 61, 58, 62, 62, 61, 9, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 23, 61, 30, 62, 61, 9, 62, 62, 23, 61, 20, 40, 61, 10, 62, 61, 58, 62, 3, 20, 40, 61, 10, 62, 61, 58, 62, 62, 61, 9, 62]\n",
            "iter 40\n",
            "batch loss 0.4144950211048126\n",
            "20 batch loss 0.4714964285492897\n",
            "trg [1, 27, 61, 43, 38, 23, 61, 30, 62, 61, 15, 62, 62, 23, 61, 10, 36, 40, 61, 9, 62, 61, 43, 62, 3, 10, 33, 40, 61, 11, 62, 61, 43, 62, 62, 61, 15, 62, 2]\n",
            "pred [1, 27, 61, 58, 38, 23, 61, 30, 62, 61, 13, 62, 62, 23, 61, 10, 20, 40, 61, 10, 62, 61, 43, 62, 3, 4, 20, 40, 61, 9, 62, 61, 43, 62, 62, 61, 9, 62]\n",
            "iter 60\n",
            "batch loss 0.6383348703384399\n",
            "20 batch loss 0.5184796020388603\n",
            "trg [1, 28, 61, 57, 62, 17, 23, 61, 27, 61, 48, 38, 30, 6, 16, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 48, 62, 22, 61, 48, 62, 62, 61, 27, 61, 48, 38, 30, 6, 10, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 48, 62, 4, 15, 20, 40, 61, 12, 62, 61, 48, 62, 62, 2]\n",
            "pred [1, 28, 61, 57, 62, 17, 23, 61, 27, 61, 57, 38, 30, 6, 9, 40, 61, 4, 62, 62, 34, 61, 45, 62, 61, 45, 48, 62, 36, 61, 48, 62, 62, 61, 27, 61, 48, 38, 30, 6, 9, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 48, 62, 4, 9, 34, 40, 61, 9, 62, 61, 48, 62, 62, 2]\n",
            "iter 80\n",
            "batch loss 0.4194479286670685\n",
            "20 batch loss 0.4899800091981888\n",
            "trg [1, 27, 61, 54, 38, 13, 40, 61, 3, 62, 62, 34, 61, 54, 62, 3, 4, 15, 12, 6, 54, 2]\n",
            "pred [1, 27, 61, 58, 38, 9, 40, 61, 3, 62, 62, 34, 61, 58, 62, 3, 4, 9, 23, 61, 9, 62, 61, 58, 62]\n",
            "iter 20\n",
            "batch loss 6.06064510345459\n",
            "20 batch loss 5.802363812923431\n",
            "trg [1, 27, 61, 47, 38, 24, 62, 14, 3, 23, 61, 34, 61, 47, 62, 62, 61, 35, 61, 58, 62, 62, 2]\n",
            "pred [1, 27, 61, 59, 38, 9, 62, 23, 61, 34, 61, 25, 10, 59, 31, 62, 62, 61, 34, 61, 59, 62, 62]\n",
            "iter 40\n",
            "batch loss 4.972196102142334\n",
            "20 batch loss 5.305696988105774\n",
            "trg [1, 27, 61, 48, 38, 24, 62, 23, 61, 12, 3, 23, 61, 10, 62, 61, 48, 62, 62, 61, 23, 61, 35, 61, 48, 40, 61, 15, 62, 3, 48, 3, 11, 62, 3, 35, 61, 48, 40, 61, 10, 62, 3, 4, 16, 48, 62, 62, 61, 48, 40, 61, 14, 40, 61, 23, 61, 12, 62, 61, 13, 62, 62, 62, 62, 62, 2]\n",
            "pred [1, 27, 61, 57, 38, 24, 62, 23, 61, 23, 61, 29, 41, 61, 10, 62, 61, 57, 62, 62, 61, 29, 41, 61, 8, 7, 62, 61, 10, 62, 62, 62, 61, 23, 61, 29, 41, 61, 8, 7, 62, 61, 57, 62, 62, 61, 29, 41, 61, 8, 7, 62, 61, 10, 62, 62, 62]\n",
            "iter 60\n",
            "batch loss 4.2167534828186035\n",
            "20 batch loss 5.510775852203369\n",
            "trg [1, 46, 40, 61, 27, 61, 49, 38, 16, 40, 61, 3, 62, 62, 12, 23, 61, 28, 61, 49, 62, 62, 61, 11, 6, 49, 62, 62, 2]\n",
            "pred [1, 27, 61, 60, 38, 9, 62, 23, 61, 34, 61, 60, 62, 3, 4, 10, 34, 61, 60, 62, 62, 61, 60, 40, 61, 9, 62, 62]\n",
            "iter 80\n",
            "batch loss 5.816775321960449\n",
            "20 batch loss 5.512706899642945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 9/9 [47:05<00:00, 313.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\tTrain Loss:   0.337 | Train PPL:   1.400\n",
            "\tValid Loss:   0.502 | Valid PPL:   1.652\n",
            "\tTest Loss:   5.454 | Test PPL: 233.635\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_expression(\n",
        "    input_seq,\n",
        "    max_expression_length,\n",
        "    model,\n",
        "    label_eos_token,\n",
        "    label_sos_token,\n",
        "):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    hidden, cell = model.encoder(input_seq)\n",
        "    next_input = label_sos_token\n",
        "    next_input = next_input[None,None,:]\n",
        "    outputs = [label_sos_token]\n",
        "    predicted_expression = []\n",
        "    for _ in range(max_expression_length):\n",
        "      # next_input = next_input[None,:]\n",
        "      if _ > 0:\n",
        "        next_input = next_input.unsqueeze(0)\n",
        "      output, hidden, cell = model.decoder(next_input, hidden, cell)\n",
        "      top1 = output.argmax(1)\n",
        "      one_hot_encoded_top1 = torch.tensor([\n",
        "        1 if i == top1.item()\n",
        "        else 0\n",
        "        for i in range(63)\n",
        "      ])\n",
        "      predicted_expression.append(top1.item())\n",
        "      next_input = torch.tensor(one_hot_encoded_top1).float().to(device)\n",
        "      outputs.append(next_input)\n",
        "      next_input = next_input.unsqueeze(0)\n",
        "      if next_input[0][2] == 1 or next_input[0][0] == 1:\n",
        "        break\n",
        "    return predicted_expression"
      ],
      "metadata": {
        "id": "d5ifF6sxGQAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_create_expression(model, data_loader):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    current_loss = 0\n",
        "    acc = 0\n",
        "    total_acc = 0\n",
        "    batch_acc = 0\n",
        "    max_acc = -1\n",
        "    min_acc = 101\n",
        "    accs = []\n",
        "    with torch.no_grad():\n",
        "        for j, d in enumerate(data_loader):\n",
        "          src = []\n",
        "          trg = []\n",
        "          for p in d:\n",
        "            src.append(p[\"image\"])\n",
        "            # print('image shape',p[\"image\"].shape)\n",
        "            trg.append(p[\"target\"])\n",
        "          src = torch.stack(src,dim=0).to(device)\n",
        "          # print('src shape',src.shape)\n",
        "          # src = torch.transpose(src,0,1)\n",
        "          trg = torch.tensor(trg).to(device)\n",
        "          trg = torch.transpose(trg,0,1)\n",
        "          label_sos_token = torch.tensor([1 if i == 1 else 0 for i in range(63)]).to(device)\n",
        "          label_eos_token = torch.tensor([1 if i == 2 else 0 for i in range(63)]).to(device)\n",
        "          predicted_expression = create_expression(src,100,model,label_sos_token,label_eos_token)\n",
        "          decoded_trg = []\n",
        "          trg_ls = trg.tolist()\n",
        "          for ls in trg_ls:\n",
        "            for i,l in enumerate(ls[0]):\n",
        "              if l == 1:\n",
        "                decoded_trg.append(i)\n",
        "                break\n",
        "          if len(predicted_expression) < len(decoded_trg) - 1:\n",
        "            while len(predicted_expression) < len(decoded_trg) - 1:\n",
        "              predicted_expression.append(0)\n",
        "            predicted_expression.append(2)\n",
        "          elif len(predicted_expression) < len(decoded_trg):\n",
        "            predicted_expression.append(2)\n",
        "          elif len(predicted_expression) == len(decoded_trg):\n",
        "            predicted_expression[-1] = 2\n",
        "          elif len(predicted_expression) > len(decoded_trg) - 1:\n",
        "            decoded_trg[-1] = 0\n",
        "            while len(predicted_expression) -1 > len(decoded_trg):\n",
        "              decoded_trg.append(0)\n",
        "            decoded_trg.append(2)\n",
        "            predicted_expression[-1]= 2\n",
        "          elif len(predicted_expression) > len(decoded_trg):\n",
        "            decoded_trg[-1] = 0\n",
        "            decoded_trg.append(2)\n",
        "            predicted_expression[-1]= 2\n",
        "          p,t = np.array(predicted_expression),np.array(decoded_trg)\n",
        "          curr_acc = np.mean(p == t) * 100\n",
        "          total_acc += curr_acc\n",
        "          max_acc = max(max_acc, curr_acc)\n",
        "          min_acc = min(min_acc,curr_acc)\n",
        "          accs.append(curr_acc)\n",
        "          if j % 20 == 0:\n",
        "            print('predicted expression')\n",
        "            print(predicted_expression)\n",
        "            print('ground truth expression')\n",
        "            print(decoded_trg)\n",
        "            print('current accuracy',curr_acc)\n",
        "            print('current ave accuracy',total_acc / (j+1))\n",
        "            print('min accuracy in batch',min_acc)\n",
        "            print('max accuracy in batch',max_acc)\n",
        "            max_acc = -1\n",
        "            min_acc = 101\n",
        "    return np.array(accs)"
      ],
      "metadata": {
        "id": "TSXdeEaa1Ppg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "  return batch\n",
        "crnn_translate_dl = torch.utils.data.DataLoader(\n",
        "    crnn_test_dataset,\n",
        "    batch_size = 1,\n",
        "    shuffle = True,\n",
        "    collate_fn = collate_fn,\n",
        "    pin_memory = True if torch.cuda.is_available() else False\n",
        ")"
      ],
      "metadata": {
        "id": "YvSh4l8hPWxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accs = evaluate_create_expression(model, crnn_translate_dl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEAbL7cF-zw6",
        "outputId": "d17e7509-e2b9-4708-d48b-a9f1effd85a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-160-216b7956e2ee>:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_input = torch.tensor(one_hot_encoded_top1).float().to(device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted expression\n",
            "[27, 61, 58, 38, 4, 24, 62, 9, 58, 40, 61, 4, 8, 62, 2]\n",
            "ground truth expression\n",
            "[27, 61, 49, 38, 4, 24, 62, 11, 49, 40, 61, 16, 0, 0, 2]\n",
            "current accuracy 60.0\n",
            "current ave accuracy 60.0\n",
            "min accuracy in batch 60.0\n",
            "max accuracy in batch 60.0\n",
            "predicted expression\n",
            "[27, 61, 57, 38, 24, 62, 23, 61, 4, 9, 25, 34, 61, 23, 61, 10, 62, 61, 57, 62, 62, 3, 4, 10, 23, 61, 10, 62, 61, 57, 62, 20, 61, 23, 61, 13, 62, 61, 57, 62, 62, 31, 62, 61, 4, 10, 57, 40, 61, 4, 9, 62, 62, 2]\n",
            "ground truth expression\n",
            "[10, 6, 10, 27, 61, 43, 38, 24, 62, 23, 61, 20, 61, 9, 6, 43, 62, 3, 4, 14, 9, 6, 43, 34, 61, 13, 6, 43, 62, 62, 61, 43, 40, 61, 4, 15, 62, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2]\n",
            "current accuracy 7.4074074074074066\n",
            "current ave accuracy 30.28490857717399\n",
            "min accuracy in batch 3.225806451612903\n",
            "max accuracy in batch 79.59183673469387\n",
            "predicted expression\n",
            "[27, 61, 57, 38, 30, 6, 9, 62, 23, 61, 20, 40, 61, 10, 62, 61, 57, 62, 3, 20, 40, 61, 9, 62, 61, 57, 62, 62, 61, 10, 62, 0, 2]\n",
            "ground truth expression\n",
            "[27, 61, 50, 38, 30, 6, 14, 62, 23, 61, 10, 36, 40, 61, 10, 62, 61, 50, 62, 3, 15, 34, 40, 61, 9, 62, 61, 50, 62, 62, 61, 9, 62]\n",
            "current accuracy 24.242424242424242\n",
            "current ave accuracy 32.52580795323112\n",
            "min accuracy in batch 6.521739130434782\n",
            "max accuracy in batch 71.42857142857143\n",
            "predicted expression\n",
            "[27, 61, 58, 38, 30, 6, 9, 62, 23, 61, 20, 61, 58, 62, 3, 4, 10, 22, 61, 58, 62, 62, 61, 58, 3, 4, 11, 30, 6, 9, 62, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2]\n",
            "ground truth expression\n",
            "[27, 61, 54, 38, 30, 6, 15, 40, 61, 4, 62, 62, 23, 61, 20, 40, 61, 9, 62, 61, 54, 62, 62, 61, 13, 23, 61, 10, 62, 61, 15, 54, 3, 25, 14, 30, 31, 40, 61, 16, 62, 62, 62]\n",
            "current accuracy 13.953488372093023\n",
            "current ave accuracy 33.65331048457359\n",
            "min accuracy in batch 11.475409836065573\n",
            "max accuracy in batch 85.24590163934425\n",
            "predicted expression\n",
            "[27, 61, 58, 38, 4, 9, 62, 23, 61, 46, 40, 61, 58, 62, 62, 61, 58, 3, 4, 46, 40, 61, 58, 62, 62, 2]\n",
            "ground truth expression\n",
            "[27, 61, 44, 38, 14, 62, 23, 61, 46, 40, 61, 14, 44, 62, 4, 8, 62, 61, 46, 40, 61, 44, 62, 4, 9, 62]\n",
            "current accuracy 15.384615384615385\n",
            "current ave accuracy 32.53234434555672\n",
            "min accuracy in batch 11.11111111111111\n",
            "max accuracy in batch 65.38461538461539\n",
            "predicted expression\n",
            "[23, 61, 27, 61, 60, 38, 9, 62, 8, 7, 25, 4, 10, 34, 40, 61, 10, 62, 61, 25, 9, 60, 31, 62, 3, 36, 40, 61, 9, 62, 61, 25, 9, 60, 31, 62, 31, 62, 61, 9, 62, 2]\n",
            "ground truth expression\n",
            "[23, 61, 27, 61, 58, 38, 14, 62, 12, 8, 22, 61, 25, 7, 31, 62, 36, 61, 25, 58, 31, 62, 62, 61, 27, 61, 58, 38, 10, 62, 9, 58, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2]\n",
            "current accuracy 19.047619047619047\n",
            "current ave accuracy 32.75686482353364\n",
            "min accuracy in batch 10.204081632653061\n",
            "max accuracy in batch 81.03448275862068\n",
            "predicted expression\n",
            "[27, 61, 59, 38, 23, 61, 30, 62, 61, 9, 62, 62, 23, 61, 34, 61, 59, 62, 3, 4, 10, 34, 61, 59, 62, 62, 61, 59, 3, 4, 10, 23, 61, 30, 62, 61, 10, 62, 62, 2]\n",
            "ground truth expression\n",
            "[27, 61, 59, 38, 23, 61, 30, 62, 61, 13, 62, 62, 23, 61, 36, 61, 59, 62, 62, 61, 36, 61, 59, 62, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2]\n",
            "current accuracy 42.5\n",
            "current ave accuracy 33.09475305648803\n",
            "min accuracy in batch 13.953488372093023\n",
            "max accuracy in batch 65.9090909090909\n",
            "predicted expression\n",
            "[27, 61, 58, 38, 9, 62, 23, 61, 46, 40, 61, 58, 62, 3, 4, 9, 34, 61, 58, 62, 4, 8, 62, 61, 58, 40, 61, 10, 62, 3, 10, 58, 40, 61, 8, 62, 3, 8, 7, 58, 40, 61, 10, 62, 62, 2]\n",
            "ground truth expression\n",
            "[27, 61, 47, 38, 13, 40, 61, 3, 62, 62, 23, 61, 14, 3, 4, 10, 36, 40, 61, 8, 62, 61, 47, 62, 62, 61, 36, 61, 47, 62, 3, 47, 36, 40, 61, 8, 62, 61, 47, 62, 0, 0, 0, 0, 0, 2]\n",
            "current accuracy 13.043478260869565\n",
            "current ave accuracy 33.053658426481334\n",
            "min accuracy in batch 9.836065573770492\n",
            "max accuracy in batch 88.46153846153845\n",
            "predicted expression\n",
            "[27, 61, 58, 38, 9, 62, 23, 61, 58, 4, 8, 62, 61, 58, 40, 61, 8, 62, 25, 58, 4, 8, 31, 25, 58, 3, 10, 31, 62, 0, 0, 0, 2]\n",
            "ground truth expression\n",
            "[27, 61, 50, 38, 12, 40, 61, 3, 62, 62, 23, 61, 50, 3, 9, 62, 61, 50, 40, 61, 8, 62, 25, 50, 4, 14, 31, 25, 50, 3, 13, 31, 62]\n",
            "current accuracy 9.090909090909092\n",
            "current ave accuracy 32.34422298124067\n",
            "min accuracy in batch 1.639344262295082\n",
            "max accuracy in batch 73.07692307692307\n",
            "predicted expression\n",
            "[27, 61, 58, 38, 8, 40, 61, 3, 62, 62, 23, 61, 4, 9, 34, 61, 58, 62, 36, 40, 61, 8, 62, 61, 58, 62, 62, 61, 36, 40, 61, 8, 62, 61, 58, 62, 3, 25, 9, 58, 34, 61, 58, 62, 3, 8, 31, 36, 40, 61, 9, 62, 61, 58, 62, 62, 2]\n",
            "ground truth expression\n",
            "[27, 61, 48, 38, 7, 40, 61, 3, 62, 62, 23, 61, 4, 15, 34, 61, 48, 62, 20, 40, 61, 8, 62, 61, 48, 62, 62, 61, 25, 7, 3, 13, 48, 20, 61, 48, 62, 31, 20, 40, 61, 14, 62, 61, 48, 62, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2]\n",
            "current accuracy 40.35087719298245\n",
            "current ave accuracy 32.083497355246415\n",
            "min accuracy in batch 4.761904761904762\n",
            "max accuracy in batch 73.33333333333333\n",
            "predicted expression\n",
            "[27, 61, 48, 38, 23, 61, 30, 62, 61, 10, 62, 62, 23, 61, 10, 36, 40, 61, 10, 62, 61, 48, 62, 3, 4, 10, 36, 40, 61, 10, 62, 61, 48, 62, 62, 61, 9, 62, 0, 0, 0, 0, 0, 0, 2]\n",
            "ground truth expression\n",
            "[27, 61, 60, 38, 23, 61, 30, 62, 61, 16, 62, 40, 61, 4, 62, 62, 23, 61, 34, 40, 61, 9, 62, 61, 60, 62, 25, 12, 60, 3, 25, 4, 16, 30, 31, 40, 61, 10, 62, 31, 62, 61, 4, 16, 62]\n",
            "current accuracy 26.666666666666668\n",
            "current ave accuracy 31.797816220193365\n",
            "min accuracy in batch 10.256410256410255\n",
            "max accuracy in batch 83.33333333333334\n",
            "predicted expression\n",
            "[27, 61, 58, 38, 9, 62, 23, 61, 34, 61, 58, 62, 3, 4, 10, 34, 61, 58, 62, 62, 61, 58, 40, 61, 11, 62, 62, 2]\n",
            "ground truth expression\n",
            "[27, 61, 44, 38, 9, 62, 23, 61, 10, 34, 40, 61, 15, 62, 61, 25, 13, 44, 31, 62, 62, 61, 44, 40, 61, 9, 62, 62]\n",
            "current accuracy 32.142857142857146\n",
            "current ave accuracy 31.411541368239348\n",
            "min accuracy in batch 8.571428571428571\n",
            "max accuracy in batch 80.0\n",
            "predicted expression\n",
            "[27, 61, 58, 38, 9, 62, 35, 61, 58, 62, 3, 35, 61, 58, 62, 2]\n",
            "ground truth expression\n",
            "[27, 61, 48, 38, 10, 62, 35, 61, 48, 4, 12, 40, 61, 7, 62, 62]\n",
            "current accuracy 50.0\n",
            "current ave accuracy 31.533227204853237\n",
            "min accuracy in batch 11.320754716981133\n",
            "max accuracy in batch 73.33333333333333\n",
            "predicted expression\n",
            "[27, 61, 54, 38, 10, 62, 23, 61, 13, 3, 4, 10, 34, 61, 25, 12, 54, 31, 62, 62, 61, 34, 61, 54, 62, 62, 2]\n",
            "ground truth expression\n",
            "[27, 61, 42, 38, 12, 62, 23, 61, 42, 3, 15, 40, 61, 9, 62, 3, 42, 3, 15, 4, 14, 16, 62, 61, 42, 0, 2]\n",
            "current accuracy 29.629629629629626\n",
            "current ave accuracy 31.392822074376358\n",
            "min accuracy in batch 2.2222222222222223\n",
            "max accuracy in batch 86.3013698630137\n",
            "predicted expression\n",
            "[27, 61, 58, 38, 8, 62, 23, 61, 35, 61, 58, 3, 9, 62, 3, 10, 62, 61, 58, 62, 0, 0, 0, 2]\n",
            "ground truth expression\n",
            "[27, 61, 48, 38, 10, 62, 23, 61, 35, 18, 10, 39, 61, 10, 3, 15, 48, 62, 4, 12, 62, 61, 48, 62]\n",
            "current accuracy 33.33333333333333\n",
            "current ave accuracy 31.221019660781153\n",
            "min accuracy in batch 9.836065573770492\n",
            "max accuracy in batch 50.0\n",
            "predicted expression\n",
            "[27, 61, 58, 38, 8, 62, 23, 61, 8, 3, 4, 10, 34, 61, 58, 62, 62, 61, 58, 36, 61, 58, 62, 62, 0, 2]\n",
            "ground truth expression\n",
            "[27, 61, 52, 38, 11, 62, 23, 61, 16, 3, 4, 11, 36, 61, 25, 10, 52, 31, 62, 62, 61, 36, 61, 52, 62, 62]\n",
            "current accuracy 38.46153846153847\n",
            "current ave accuracy 32.146797902916994\n",
            "min accuracy in batch 11.11111111111111\n",
            "max accuracy in batch 84.61538461538461\n",
            "predicted expression\n",
            "[27, 61, 58, 38, 9, 62, 23, 61, 34, 61, 25, 10, 58, 31, 62, 62, 61, 58, 62, 2]\n",
            "ground truth expression\n",
            "[27, 61, 42, 38, 10, 62, 23, 61, 22, 42, 40, 61, 16, 62, 62, 61, 42, 0, 0, 2]\n",
            "current accuracy 40.0\n",
            "current ave accuracy 32.76534748483459\n",
            "min accuracy in batch 15.217391304347828\n",
            "max accuracy in batch 82.05128205128204\n",
            "predicted expression\n",
            "[27, 61, 58, 38, 8, 40, 61, 3, 62, 62, 23, 61, 4, 10, 34, 61, 58, 62, 36, 40, 61, 8, 62, 61, 58, 62, 62, 61, 36, 40, 61, 8, 62, 61, 58, 62, 3, 25, 9, 58, 34, 61, 58, 62, 3, 8, 31, 36, 40, 61, 9, 62, 61, 58, 62, 62, 2]\n",
            "ground truth expression\n",
            "[27, 61, 53, 38, 9, 40, 61, 3, 62, 62, 23, 61, 4, 11, 22, 61, 53, 62, 20, 40, 61, 13, 62, 61, 53, 62, 62, 61, 25, 12, 3, 9, 53, 22, 61, 53, 62, 31, 36, 40, 61, 15, 62, 61, 53, 62, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2]\n",
            "current accuracy 36.84210526315789\n",
            "current ave accuracy 33.22490193790572\n",
            "min accuracy in batch 12.5\n",
            "max accuracy in batch 83.87096774193549\n",
            "predicted expression\n",
            "[27, 61, 48, 38, 23, 61, 30, 62, 61, 9, 62, 62, 23, 61, 20, 40, 61, 10, 62, 61, 48, 62, 3, 20, 40, 61, 10, 62, 61, 48, 62, 62, 61, 9, 62, 2]\n",
            "ground truth expression\n",
            "[27, 61, 54, 38, 12, 7, 12, 40, 61, 4, 62, 62, 8, 3, 25, 4, 7, 5, 14, 7, 13, 54, 31, 40, 61, 13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2]\n",
            "current accuracy 19.444444444444446\n",
            "current ave accuracy 32.95840306176079\n",
            "min accuracy in batch 9.75609756097561\n",
            "max accuracy in batch 58.82352941176471\n",
            "predicted expression\n",
            "[27, 61, 58, 38, 8, 40, 61, 3, 62, 62, 23, 61, 58, 4, 8, 62, 61, 58, 3, 58, 62, 2]\n",
            "ground truth expression\n",
            "[27, 61, 48, 38, 15, 40, 61, 3, 62, 62, 23, 61, 48, 4, 10, 62, 61, 48, 3, 16, 0, 2]\n",
            "current accuracy 68.18181818181817\n",
            "current ave accuracy 32.51951858051617\n",
            "min accuracy in batch 5.714285714285714\n",
            "max accuracy in batch 68.18181818181817\n",
            "predicted expression\n",
            "[17, 23, 61, 27, 61, 60, 38, 30, 6, 9, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 60, 62, 36, 61, 60, 62, 62, 61, 27, 61, 60, 38, 30, 6, 10, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 60, 62, 4, 9, 20, 40, 61, 9, 62, 61, 60, 62, 62, 2, 0, 0, 0, 0, 0, 0, 2]\n",
            "ground truth expression\n",
            "[17, 23, 61, 27, 61, 48, 38, 23, 61, 30, 62, 61, 13, 62, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 48, 62, 34, 61, 48, 62, 62, 61, 27, 61, 48, 38, 23, 61, 30, 62, 61, 9, 62, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 48, 62, 4, 9, 22, 40, 61, 10, 62, 61, 48, 62, 62]\n",
            "current accuracy 23.52941176470588\n",
            "current ave accuracy 32.249814259940734\n",
            "min accuracy in batch 4.477611940298507\n",
            "max accuracy in batch 75.47169811320755\n",
            "predicted expression\n",
            "[27, 61, 54, 38, 24, 62, 23, 61, 29, 41, 61, 8, 62, 61, 54, 62, 62, 61, 29, 41, 61, 8, 7, 62, 61, 13, 62, 62, 23, 61, 29, 41, 61, 8, 7, 62, 61, 10, 62, 62, 61, 29, 41, 61, 8, 7, 62, 61, 54, 62, 62, 2]\n",
            "ground truth expression\n",
            "[27, 61, 58, 38, 46, 62, 23, 61, 23, 61, 45, 62, 61, 45, 58, 62, 25, 28, 61, 58, 62, 3, 7, 31, 62, 61, 23, 61, 45, 62, 61, 45, 58, 62, 25, 58, 3, 4, 12, 46, 31, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2]\n",
            "current accuracy 17.307692307692307\n",
            "current ave accuracy 32.0097363554862\n",
            "min accuracy in batch 4.545454545454546\n",
            "max accuracy in batch 72.0\n",
            "predicted expression\n",
            "[27, 61, 58, 38, 9, 40, 61, 3, 62, 62, 34, 61, 58, 62, 3, 4, 9, 23, 61, 9, 62, 61, 58, 62, 2]\n",
            "ground truth expression\n",
            "[27, 61, 54, 38, 9, 40, 61, 3, 62, 62, 20, 61, 54, 62, 3, 4, 16, 23, 61, 16, 62, 61, 54, 0, 2]\n",
            "current accuracy 72.0\n",
            "current ave accuracy 32.34742906760704\n",
            "min accuracy in batch 7.8431372549019605\n",
            "max accuracy in batch 79.3103448275862\n",
            "predicted expression\n",
            "[27, 61, 60, 38, 30, 6, 10, 62, 23, 61, 9, 3, 4, 9, 36, 61, 60, 62, 62, 61, 10, 60, 3, 4, 10, 30, 62, 0, 0, 0, 0, 0, 0, 2]\n",
            "ground truth expression\n",
            "[27, 61, 60, 38, 11, 40, 61, 3, 62, 62, 23, 61, 28, 61, 60, 62, 3, 4, 14, 60, 3, 16, 62, 61, 28, 61, 60, 62, 25, 60, 4, 13, 31, 62]\n",
            "current accuracy 11.76470588235294\n",
            "current ave accuracy 32.38484262773557\n",
            "min accuracy in batch 0.0\n",
            "max accuracy in batch 69.23076923076923\n",
            "predicted expression\n",
            "[27, 61, 54, 38, 24, 62, 23, 61, 29, 41, 61, 8, 62, 61, 54, 62, 62, 61, 29, 41, 61, 8, 7, 62, 61, 13, 62, 62, 23, 61, 29, 41, 61, 8, 7, 62, 61, 10, 62, 62, 61, 29, 41, 61, 8, 7, 62, 61, 54, 62, 62, 2]\n",
            "ground truth expression\n",
            "[27, 61, 56, 38, 24, 62, 23, 61, 29, 41, 61, 13, 12, 62, 61, 56, 62, 62, 61, 29, 41, 61, 9, 9, 62, 61, 16, 62, 62, 23, 61, 29, 41, 61, 13, 13, 62, 61, 8, 62, 62, 61, 29, 41, 61, 8, 13, 62, 61, 56, 62, 62]\n",
            "current accuracy 26.923076923076923\n",
            "current ave accuracy 32.464873297681216\n",
            "min accuracy in batch 8.771929824561402\n",
            "max accuracy in batch 80.76923076923077\n",
            "predicted expression\n",
            "[27, 61, 57, 38, 9, 40, 61, 3, 62, 62, 23, 61, 10, 6, 57, 62, 61, 4, 10, 36, 61, 57, 62, 36, 61, 57, 62, 62, 2]\n",
            "ground truth expression\n",
            "[27, 61, 56, 38, 8, 40, 61, 3, 62, 62, 23, 61, 13, 62, 61, 9, 3, 28, 61, 56, 62, 3, 10, 0, 0, 0, 0, 0, 2]\n",
            "current accuracy 37.93103448275862\n",
            "current ave accuracy 32.641256619240124\n",
            "min accuracy in batch 10.416666666666668\n",
            "max accuracy in batch 78.26086956521739\n",
            "predicted expression\n",
            "[27, 61, 57, 38, 30, 6, 9, 62, 23, 61, 9, 34, 40, 61, 9, 62, 61, 57, 62, 3, 4, 10, 36, 40, 61, 9, 62, 61, 57, 62, 62, 61, 10, 62, 2]\n",
            "ground truth expression\n",
            "[27, 61, 55, 38, 30, 6, 9, 62, 36, 40, 61, 14, 62, 61, 55, 62, 3, 27, 61, 55, 38, 30, 6, 10, 62, 34, 40, 61, 11, 62, 61, 55, 0, 0, 2]\n",
            "current accuracy 34.285714285714285\n",
            "current ave accuracy 32.819316954452006\n",
            "min accuracy in batch 13.793103448275861\n",
            "max accuracy in batch 86.20689655172413\n",
            "predicted expression\n",
            "[27, 61, 57, 38, 30, 6, 9, 62, 23, 61, 9, 34, 40, 61, 9, 62, 61, 57, 62, 3, 4, 10, 36, 40, 61, 9, 62, 61, 57, 62, 62, 61, 10, 62, 2]\n",
            "ground truth expression\n",
            "[17, 27, 61, 43, 38, 30, 6, 9, 62, 36, 40, 61, 10, 62, 61, 43, 62, 3, 27, 61, 43, 38, 30, 6, 9, 62, 20, 40, 61, 14, 62, 61, 43, 0, 2]\n",
            "current accuracy 8.571428571428571\n",
            "current ave accuracy 32.954645883183325\n",
            "min accuracy in batch 7.017543859649122\n",
            "max accuracy in batch 73.33333333333333\n",
            "predicted expression\n",
            "[27, 61, 57, 38, 23, 61, 30, 62, 61, 9, 62, 62, 23, 61, 10, 34, 61, 57, 62, 3, 4, 10, 36, 61, 57, 62, 62, 61, 10, 57, 3, 4, 10, 23, 61, 30, 62, 61, 10, 62, 62, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2]\n",
            "ground truth expression\n",
            "[27, 61, 57, 38, 23, 61, 30, 62, 61, 13, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 57, 62, 25, 36, 61, 57, 62, 3, 4, 9, 34, 61, 57, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 57, 62, 25, 57, 3, 4, 11, 23, 61, 30, 62, 61, 14, 62, 31, 62]\n",
            "current accuracy 25.423728813559322\n",
            "current ave accuracy 32.95095310724278\n",
            "min accuracy in batch 13.513513513513514\n",
            "max accuracy in batch 84.61538461538461\n",
            "predicted expression\n",
            "[27, 61, 58, 38, 10, 40, 61, 3, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 58, 62, 28, 61, 58, 62, 62, 61, 23, 61, 45, 62, 61, 45, 58, 62, 36, 61, 58, 62, 62, 2]\n",
            "ground truth expression\n",
            "[27, 61, 59, 38, 16, 40, 61, 3, 62, 62, 23, 61, 23, 61, 16, 3, 13, 59, 62, 61, 59, 62, 62, 61, 23, 61, 59, 3, 59, 28, 61, 59, 62, 4, 9, 62, 61, 59, 62, 62]\n",
            "current accuracy 37.5\n",
            "current ave accuracy 32.90603669788541\n",
            "min accuracy in batch 11.475409836065573\n",
            "max accuracy in batch 72.0\n",
            "predicted expression\n",
            "[23, 61, 27, 61, 58, 38, 9, 62, 11, 9, 25, 4, 9, 34, 40, 61, 10, 62, 61, 25, 9, 58, 31, 62, 3, 36, 40, 61, 9, 62, 61, 25, 9, 58, 31, 62, 31, 62, 61, 9, 62, 2]\n",
            "ground truth expression\n",
            "[23, 61, 27, 61, 59, 38, 12, 62, 16, 10, 25, 4, 16, 20, 40, 61, 13, 62, 61, 25, 10, 59, 31, 62, 3, 20, 40, 61, 9, 62, 61, 25, 11, 59, 31, 62, 31, 62, 61, 10, 0, 2]\n",
            "current accuracy 66.66666666666666\n",
            "current ave accuracy 33.02992648893944\n",
            "min accuracy in batch 4.761904761904762\n",
            "max accuracy in batch 80.0\n",
            "predicted expression\n",
            "[27, 61, 58, 38, 24, 62, 23, 61, 23, 61, 29, 41, 61, 10, 62, 61, 58, 62, 62, 61, 29, 41, 61, 8, 7, 62, 61, 9, 62, 62, 62, 61, 23, 61, 29, 41, 61, 8, 7, 62, 61, 58, 62, 62, 61, 29, 41, 61, 8, 7, 62, 61, 9, 62, 62, 62, 2]\n",
            "ground truth expression\n",
            "[27, 61, 59, 38, 24, 62, 23, 61, 23, 61, 29, 41, 61, 12, 16, 62, 61, 59, 62, 62, 61, 29, 41, 61, 12, 10, 62, 61, 8, 62, 62, 62, 61, 23, 61, 29, 41, 61, 10, 9, 62, 61, 59, 62, 62, 61, 29, 41, 61, 8, 7, 62, 61, 9, 62, 62, 62]\n",
            "current accuracy 31.57894736842105\n",
            "current ave accuracy 33.0113487956274\n",
            "min accuracy in batch 11.627906976744185\n",
            "max accuracy in batch 79.24528301886792\n",
            "predicted expression\n",
            "[27, 61, 59, 38, 30, 6, 9, 62, 23, 61, 10, 20, 40, 61, 10, 62, 61, 59, 62, 3, 4, 10, 36, 40, 61, 9, 62, 61, 59, 62, 62, 61, 10, 62, 0, 0, 0, 0, 0, 0, 2]\n",
            "ground truth expression\n",
            "[27, 61, 53, 38, 30, 6, 13, 40, 61, 4, 62, 62, 23, 61, 34, 40, 61, 13, 62, 61, 53, 62, 25, 10, 53, 3, 25, 4, 9, 30, 31, 40, 61, 12, 62, 31, 62, 61, 4, 11, 62]\n",
            "current accuracy 19.51219512195122\n",
            "current ave accuracy 33.06635771300645\n",
            "min accuracy in batch 5.0\n",
            "max accuracy in batch 78.46153846153847\n",
            "predicted expression\n",
            "[27, 61, 47, 38, 4, 24, 62, 23, 61, 47, 62, 61, 47, 3, 10, 62, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2]\n",
            "ground truth expression\n",
            "[27, 61, 60, 38, 4, 24, 62, 23, 61, 10, 60, 40, 61, 8, 62, 62, 61, 8, 26, 60, 40, 61, 8, 62, 32, 62]\n",
            "current accuracy 34.61538461538461\n",
            "current ave accuracy 32.960975115580865\n",
            "min accuracy in batch 2.5\n",
            "max accuracy in batch 78.26086956521739\n",
            "predicted expression\n",
            "[27, 61, 59, 38, 4, 24, 62, 23, 61, 9, 62, 61, 59, 40, 61, 10, 62, 62, 2]\n",
            "ground truth expression\n",
            "[27, 61, 54, 38, 24, 62, 23, 61, 13, 62, 61, 16, 0, 0, 0, 0, 0, 0, 2]\n",
            "current accuracy 21.052631578947366\n",
            "current ave accuracy 33.122466383583095\n",
            "min accuracy in batch 8.955223880597014\n",
            "max accuracy in batch 82.1917808219178\n",
            "predicted expression\n",
            "[27, 61, 58, 38, 8, 62, 10, 34, 61, 58, 62, 2]\n",
            "ground truth expression\n",
            "[27, 61, 43, 38, 13, 62, 43, 20, 61, 43, 0, 2]\n",
            "current accuracy 50.0\n",
            "current ave accuracy 33.3259299337666\n",
            "min accuracy in batch 11.76470588235294\n",
            "max accuracy in batch 80.0\n",
            "predicted expression\n",
            "[46, 40, 61, 27, 61, 58, 38, 9, 40, 61, 3, 62, 62, 23, 61, 23, 61, 9, 62, 61, 58, 3, 14, 62, 62, 61, 36, 61, 58, 62, 62, 62, 2]\n",
            "ground truth expression\n",
            "[46, 40, 61, 27, 61, 56, 38, 9, 40, 61, 3, 62, 62, 23, 61, 23, 61, 9, 62, 61, 56, 3, 9, 62, 62, 61, 20, 61, 56, 62, 62, 0, 2]\n",
            "current accuracy 81.81818181818183\n",
            "current ave accuracy 33.43586710293449\n",
            "min accuracy in batch 6.382978723404255\n",
            "max accuracy in batch 81.81818181818183\n",
            "predicted expression\n",
            "[27, 61, 58, 38, 9, 62, 23, 61, 23, 61, 45, 62, 61, 45, 58, 62, 25, 46, 40, 61, 58, 62, 3, 4, 9, 20, 61, 58, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 58, 62, 25, 7, 58, 40, 61, 8, 62, 3, 9, 58, 40, 61, 8, 62, 3, 4, 10, 58, 4, 8, 31, 62, 2]\n",
            "ground truth expression\n",
            "[27, 61, 44, 38, 11, 40, 61, 3, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 44, 62, 25, 10, 3, 4, 12, 33, 40, 61, 10, 62, 61, 44, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 44, 62, 25, 34, 61, 44, 62, 3, 44, 20, 40, 61, 9, 62, 61, 44, 62, 31, 0, 0, 2]\n",
            "current accuracy 12.698412698412698\n",
            "current ave accuracy 33.24565507999437\n",
            "min accuracy in batch 12.698412698412698\n",
            "max accuracy in batch 72.22222222222221\n",
            "predicted expression\n",
            "[27, 61, 59, 38, 9, 40, 61, 3, 62, 62, 4, 23, 61, 23, 61, 45, 62, 61, 45, 59, 62, 34, 40, 61, 9, 62, 61, 59, 62, 62, 61, 23, 61, 45, 62, 61, 45, 59, 62, 59, 20, 61, 59, 62, 62, 2]\n",
            "ground truth expression\n",
            "[27, 61, 59, 38, 16, 40, 61, 3, 62, 62, 4, 9, 23, 61, 23, 61, 45, 62, 61, 45, 59, 62, 34, 40, 61, 16, 62, 61, 59, 62, 62, 61, 23, 61, 45, 62, 61, 45, 59, 62, 59, 36, 61, 59, 62, 62]\n",
            "current accuracy 26.08695652173913\n",
            "current ave accuracy 33.37706769708322\n",
            "min accuracy in batch 9.090909090909092\n",
            "max accuracy in batch 82.75862068965517\n",
            "predicted expression\n",
            "[27, 61, 58, 38, 9, 62, 23, 61, 58, 4, 8, 62, 61, 58, 40, 61, 10, 62, 25, 58, 4, 8, 31, 25, 58, 3, 10, 31, 62, 2]\n",
            "ground truth expression\n",
            "[27, 61, 60, 38, 14, 62, 23, 61, 60, 3, 9, 62, 61, 15, 3, 7, 36, 61, 60, 62, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2]\n",
            "current accuracy 30.0\n",
            "current ave accuracy 33.37433896887632\n",
            "min accuracy in batch 8.19672131147541\n",
            "max accuracy in batch 82.05128205128204\n",
            "predicted expression\n",
            "[27, 61, 58, 38, 4, 9, 62, 23, 61, 58, 3, 7, 3, 58, 3, 9, 40, 61, 9, 62, 62, 61, 58, 3, 10, 62, 0, 2]\n",
            "ground truth expression\n",
            "[27, 61, 56, 38, 30, 62, 23, 61, 20, 61, 56, 62, 3, 8, 62, 61, 56, 3, 25, 4, 10, 30, 31, 40, 61, 9, 62, 62]\n",
            "current accuracy 14.285714285714285\n",
            "current ave accuracy 33.30438060271883\n",
            "min accuracy in batch 9.090909090909092\n",
            "max accuracy in batch 79.48717948717949\n",
            "predicted expression\n",
            "[27, 61, 54, 38, 4, 8, 62, 23, 61, 23, 61, 45, 62, 61, 45, 54, 62, 25, 46, 40, 61, 54, 62, 3, 4, 10, 20, 61, 54, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 54, 62, 25, 7, 54, 40, 61, 8, 62, 3, 9, 54, 40, 61, 8, 62, 3, 4, 10, 54, 4, 8, 31, 62, 2]\n",
            "ground truth expression\n",
            "[27, 61, 56, 38, 30, 6, 15, 40, 61, 4, 62, 62, 23, 61, 34, 40, 61, 10, 62, 61, 56, 62, 62, 61, 23, 61, 4, 9, 62, 61, 15, 56, 3, 25, 4, 11, 30, 31, 40, 61, 16, 62, 62, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2]\n",
            "current accuracy 10.9375\n",
            "current ave accuracy 33.192604950872536\n",
            "min accuracy in batch 8.823529411764707\n",
            "max accuracy in batch 61.111111111111114\n",
            "predicted expression\n",
            "[27, 61, 59, 38, 24, 62, 23, 61, 8, 7, 59, 40, 61, 9, 62, 3, 59, 3, 10, 62, 61, 59, 40, 61, 8, 62, 62, 2]\n",
            "ground truth expression\n",
            "[27, 61, 59, 38, 24, 62, 23, 61, 16, 7, 8, 59, 40, 61, 8, 62, 62, 61, 46, 40, 61, 59, 62, 0, 0, 0, 0, 2]\n",
            "current accuracy 42.857142857142854\n",
            "current ave accuracy 33.016499890836606\n",
            "min accuracy in batch 6.25\n",
            "max accuracy in batch 63.1578947368421\n",
            "predicted expression\n",
            "[27, 61, 58, 38, 9, 40, 61, 3, 62, 62, 35, 61, 58, 25, 58, 4, 16, 31, 62, 0, 2]\n",
            "ground truth expression\n",
            "[27, 61, 58, 38, 23, 61, 30, 62, 61, 13, 62, 62, 35, 61, 34, 61, 58, 62, 62, 3, 16]\n",
            "current accuracy 23.809523809523807\n",
            "current ave accuracy 33.1304516526852\n",
            "min accuracy in batch 6.25\n",
            "max accuracy in batch 79.3103448275862\n",
            "predicted expression\n",
            "[27, 61, 57, 38, 24, 62, 23, 61, 4, 9, 25, 34, 61, 23, 61, 10, 62, 61, 57, 62, 62, 3, 4, 13, 23, 61, 9, 62, 61, 57, 62, 20, 61, 23, 61, 10, 62, 61, 57, 62, 62, 31, 62, 61, 4, 10, 57, 40, 61, 4, 9, 62, 62, 2]\n",
            "ground truth expression\n",
            "[27, 61, 55, 38, 24, 62, 23, 61, 23, 61, 45, 62, 61, 45, 55, 62, 25, 15, 3, 4, 10, 55, 20, 61, 9, 6, 55, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 55, 62, 55, 40, 61, 4, 10, 62, 0, 0, 0, 0, 0, 0, 0, 0, 2]\n",
            "current accuracy 20.37037037037037\n",
            "current ave accuracy 32.977747196455105\n",
            "min accuracy in batch 10.204081632653061\n",
            "max accuracy in batch 53.84615384615385\n",
            "predicted expression\n",
            "[27, 61, 57, 38, 13, 62, 23, 61, 34, 61, 25, 10, 57, 31, 62, 36, 61, 25, 9, 57, 31, 62, 23, 61, 10, 62, 61, 9, 62, 23, 61, 10, 62, 61, 57, 62, 62, 61, 34, 61, 25, 9, 57, 31, 62, 23, 61, 10, 62, 61, 10, 62, 23, 61, 10, 62, 61, 57, 62, 62, 2]\n",
            "ground truth expression\n",
            "[27, 61, 59, 38, 10, 62, 23, 61, 25, 8, 3, 4, 34, 61, 59, 62, 31, 25, 9, 3, 20, 61, 59, 62, 31, 62, 61, 14, 3, 7, 36, 61, 59, 62, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2]\n",
            "current accuracy 18.0327868852459\n",
            "current ave accuracy 32.96370786055494\n",
            "min accuracy in batch 5.660377358490567\n",
            "max accuracy in batch 78.84615384615384\n",
            "predicted expression\n",
            "[27, 61, 58, 38, 24, 62, 23, 61, 29, 41, 61, 8, 7, 62, 61, 58, 62, 62, 61, 29, 41, 61, 8, 7, 62, 61, 13, 62, 62, 23, 61, 29, 41, 61, 8, 7, 62, 61, 9, 62, 62, 61, 29, 41, 61, 8, 7, 62, 61, 58, 62, 62, 2]\n",
            "ground truth expression\n",
            "[27, 61, 49, 38, 24, 62, 23, 61, 29, 41, 61, 10, 10, 62, 61, 49, 62, 62, 61, 29, 41, 61, 9, 13, 62, 61, 7, 62, 62, 23, 61, 29, 41, 61, 10, 8, 62, 61, 10, 62, 62, 61, 29, 41, 61, 11, 15, 62, 61, 49, 62, 0, 2]\n",
            "current accuracy 73.58490566037736\n",
            "current ave accuracy 33.03254338260013\n",
            "min accuracy in batch 10.9375\n",
            "max accuracy in batch 77.58620689655173\n",
            "predicted expression\n",
            "[27, 61, 59, 38, 24, 62, 23, 61, 8, 7, 59, 40, 61, 9, 62, 4, 8, 62, 61, 8, 59, 40, 61, 8, 62, 3, 4, 10, 59, 40, 61, 8, 62, 62, 2]\n",
            "ground truth expression\n",
            "[27, 61, 59, 38, 4, 24, 62, 23, 61, 16, 14, 59, 40, 61, 14, 62, 62, 61, 16, 59, 40, 61, 13, 62, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2]\n",
            "current accuracy 14.285714285714285\n",
            "current ave accuracy 32.903820387527766\n",
            "min accuracy in batch 12.280701754385964\n",
            "max accuracy in batch 72.41379310344827\n",
            "predicted expression\n",
            "[23, 61, 27, 61, 58, 38, 8, 62, 23, 61, 45, 62, 61, 45, 58, 62, 8, 8, 34, 61, 25, 58, 31, 62, 36, 61, 25, 9, 58, 31, 62, 62, 61, 27, 61, 58, 38, 9, 62, 23, 61, 45, 62, 61, 45, 58, 62, 58, 62, 2]\n",
            "ground truth expression\n",
            "[23, 61, 27, 61, 42, 38, 7, 62, 11, 10, 36, 61, 25, 9, 42, 31, 62, 36, 61, 25, 13, 42, 31, 62, 62, 61, 27, 61, 42, 38, 16, 62, 12, 42, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2]\n",
            "current accuracy 22.0\n",
            "current ave accuracy 32.74089813264895\n",
            "min accuracy in batch 11.475409836065573\n",
            "max accuracy in batch 73.07692307692307\n",
            "predicted expression\n",
            "[17, 23, 61, 27, 61, 60, 38, 8, 62, 23, 61, 45, 62, 61, 45, 60, 62, 10, 8, 34, 61, 25, 60, 31, 62, 36, 61, 25, 60, 31, 62, 62, 61, 27, 61, 60, 38, 10, 62, 23, 61, 45, 62, 61, 45, 60, 62, 10, 60, 62, 2]\n",
            "ground truth expression\n",
            "[23, 61, 27, 61, 52, 38, 12, 62, 15, 36, 61, 25, 9, 52, 31, 62, 62, 61, 27, 61, 52, 38, 7, 62, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2]\n",
            "current accuracy 5.88235294117647\n",
            "current ave accuracy 32.814703808289316\n",
            "min accuracy in batch 5.88235294117647\n",
            "max accuracy in batch 80.0\n",
            "predicted expression\n",
            "[27, 61, 58, 38, 30, 6, 9, 62, 23, 61, 9, 36, 40, 61, 10, 62, 61, 58, 62, 3, 4, 9, 36, 40, 61, 9, 62, 61, 58, 62, 62, 61, 9, 62, 2]\n",
            "ground truth expression\n",
            "[27, 61, 57, 38, 30, 6, 11, 62, 23, 61, 16, 20, 40, 61, 15, 62, 61, 57, 62, 3, 4, 12, 20, 40, 61, 9, 62, 61, 57, 62, 62, 61, 13, 0, 2]\n",
            "current accuracy 68.57142857142857\n",
            "current ave accuracy 32.89090416048231\n",
            "min accuracy in batch 3.076923076923077\n",
            "max accuracy in batch 81.81818181818183\n",
            "predicted expression\n",
            "[27, 61, 59, 38, 9, 62, 23, 61, 59, 4, 8, 62, 61, 59, 4, 10, 40, 61, 9, 62, 62, 2]\n",
            "ground truth expression\n",
            "[27, 61, 59, 38, 11, 40, 61, 4, 62, 62, 23, 61, 59, 4, 11, 62, 61, 59, 3, 12, 0, 2]\n",
            "current accuracy 22.727272727272727\n",
            "current ave accuracy 32.81413457040097\n",
            "min accuracy in batch 9.836065573770492\n",
            "max accuracy in batch 82.75862068965517\n",
            "predicted expression\n",
            "[27, 61, 58, 38, 30, 6, 9, 62, 23, 61, 20, 61, 58, 62, 3, 4, 10, 22, 61, 58, 62, 62, 61, 58, 3, 4, 11, 30, 6, 9, 62, 2]\n",
            "ground truth expression\n",
            "[27, 61, 48, 38, 30, 6, 13, 40, 61, 4, 62, 62, 23, 61, 36, 61, 48, 62, 4, 16, 62, 61, 36, 61, 48, 62, 0, 0, 0, 0, 0, 2]\n",
            "current accuracy 21.875\n",
            "current ave accuracy 32.88913150581609\n",
            "min accuracy in batch 4.3478260869565215\n",
            "max accuracy in batch 76.66666666666667\n",
            "predicted expression\n",
            "[27, 61, 59, 38, 9, 40, 61, 3, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 59, 62, 28, 61, 59, 62, 62, 61, 23, 61, 45, 62, 61, 45, 59, 62, 36, 61, 59, 62, 62, 2]\n",
            "ground truth expression\n",
            "[27, 61, 51, 38, 8, 40, 61, 3, 62, 62, 23, 61, 25, 51, 4, 13, 31, 25, 51, 4, 14, 31, 62, 61, 51, 4, 12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2]\n",
            "current accuracy 27.500000000000004\n",
            "current ave accuracy 32.85066047812815\n",
            "min accuracy in batch 3.125\n",
            "max accuracy in batch 90.0\n",
            "predicted expression\n",
            "[27, 61, 58, 38, 23, 61, 30, 62, 61, 9, 62, 62, 23, 61, 36, 61, 58, 62, 3, 4, 10, 34, 61, 58, 62, 62, 61, 58, 3, 4, 9, 23, 61, 30, 62, 61, 10, 62, 62, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2]\n",
            "ground truth expression\n",
            "[27, 61, 54, 38, 23, 61, 30, 62, 61, 16, 62, 40, 61, 4, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 54, 62, 25, 22, 61, 54, 62, 4, 14, 31, 62, 61, 23, 61, 45, 62, 61, 45, 54, 62, 20, 61, 54, 62, 62]\n",
            "current accuracy 26.53061224489796\n",
            "current ave accuracy 33.03119141473529\n",
            "min accuracy in batch 11.11111111111111\n",
            "max accuracy in batch 84.61538461538461\n",
            "predicted expression\n",
            "[28, 61, 59, 62, 17, 23, 61, 27, 61, 57, 38, 23, 61, 30, 62, 61, 10, 62, 40, 61, 4, 62, 62, 36, 61, 57, 62, 62, 61, 27, 61, 57, 38, 23, 61, 30, 62, 61, 10, 62, 40, 61, 4, 62, 62, 4, 9, 20, 40, 61, 9, 62, 61, 57, 62, 62, 0, 0, 0, 0, 0, 0, 0, 2]\n",
            "ground truth expression\n",
            "[28, 61, 42, 62, 17, 23, 61, 27, 61, 56, 38, 30, 6, 13, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 56, 62, 36, 61, 56, 62, 62, 61, 27, 61, 56, 38, 30, 6, 10, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 56, 62, 4, 9, 20, 40, 61, 10, 62, 61, 56, 62, 62]\n",
            "current accuracy 32.8125\n",
            "current ave accuracy 33.07194153603051\n",
            "min accuracy in batch 6.521739130434782\n",
            "max accuracy in batch 81.13207547169812\n",
            "predicted expression\n",
            "[27, 61, 44, 38, 23, 61, 30, 62, 61, 10, 62, 62, 23, 61, 9, 20, 40, 61, 10, 62, 61, 44, 62, 3, 4, 10, 36, 40, 61, 10, 62, 61, 44, 62, 62, 61, 9, 62, 2]\n",
            "ground truth expression\n",
            "[27, 61, 52, 38, 23, 61, 30, 62, 61, 16, 62, 62, 23, 61, 9, 36, 40, 61, 10, 62, 61, 52, 62, 3, 10, 36, 40, 61, 10, 62, 61, 52, 62, 62, 61, 15, 0, 0, 2]\n",
            "current accuracy 56.41025641025641\n",
            "current ave accuracy 33.05084283529009\n",
            "min accuracy in batch 3.7735849056603774\n",
            "max accuracy in batch 80.82191780821918\n",
            "predicted expression\n",
            "[23, 61, 27, 61, 57, 38, 8, 62, 23, 61, 45, 62, 61, 45, 57, 62, 8, 8, 34, 61, 25, 57, 31, 62, 36, 61, 25, 9, 57, 31, 62, 62, 61, 27, 61, 57, 38, 10, 62, 23, 61, 45, 62, 61, 45, 57, 62, 57, 62, 2]\n",
            "ground truth expression\n",
            "[23, 61, 27, 61, 55, 38, 13, 62, 23, 61, 45, 62, 61, 45, 55, 62, 10, 20, 40, 61, 13, 62, 61, 25, 12, 55, 31, 62, 62, 61, 27, 61, 55, 38, 7, 62, 23, 61, 45, 62, 61, 45, 55, 62, 55, 40, 61, 9, 62, 62]\n",
            "current accuracy 34.0\n",
            "current ave accuracy 33.05245123829086\n",
            "min accuracy in batch 7.6923076923076925\n",
            "max accuracy in batch 82.1917808219178\n",
            "predicted expression\n",
            "[27, 61, 58, 38, 10, 40, 61, 3, 62, 62, 23, 61, 58, 4, 8, 62, 61, 58, 40, 61, 8, 62, 3, 4, 14, 58, 3, 8, 62, 2]\n",
            "ground truth expression\n",
            "[27, 61, 60, 38, 9, 40, 61, 3, 62, 62, 46, 40, 61, 23, 61, 28, 61, 60, 62, 62, 61, 15, 3, 28, 61, 60, 62, 62, 0, 2]\n",
            "current accuracy 36.666666666666664\n",
            "current ave accuracy 32.973018486137875\n",
            "min accuracy in batch 2.857142857142857\n",
            "max accuracy in batch 73.68421052631578\n",
            "predicted expression\n",
            "[27, 61, 57, 38, 8, 40, 61, 3, 62, 62, 23, 61, 4, 10, 34, 61, 57, 62, 36, 40, 61, 10, 62, 61, 57, 62, 62, 61, 36, 40, 61, 10, 62, 61, 57, 62, 3, 25, 10, 57, 36, 61, 57, 62, 3, 8, 31, 36, 40, 61, 10, 62, 61, 57, 62, 62, 2]\n",
            "ground truth expression\n",
            "[27, 61, 57, 38, 8, 40, 61, 3, 62, 62, 23, 61, 4, 14, 36, 61, 57, 62, 34, 40, 61, 16, 62, 61, 57, 62, 62, 61, 25, 9, 3, 14, 57, 34, 61, 57, 62, 31, 20, 40, 61, 8, 62, 61, 57, 62, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2]\n",
            "current accuracy 43.859649122807014\n",
            "current ave accuracy 33.02207227646118\n",
            "min accuracy in batch 12.121212121212121\n",
            "max accuracy in batch 76.92307692307693\n",
            "predicted expression\n",
            "[27, 61, 55, 38, 9, 62, 23, 61, 55, 3, 7, 62, 61, 55, 40, 61, 8, 62, 25, 55, 4, 8, 31, 25, 55, 3, 10, 31, 62, 2]\n",
            "ground truth expression\n",
            "[27, 61, 47, 38, 13, 62, 23, 61, 14, 47, 62, 61, 35, 61, 9, 47, 3, 15, 62, 4, 13, 0, 0, 0, 0, 0, 0, 0, 0, 2]\n",
            "current accuracy 23.333333333333332\n",
            "current ave accuracy 32.900225093075\n",
            "min accuracy in batch 9.090909090909092\n",
            "max accuracy in batch 82.1917808219178\n",
            "predicted expression\n",
            "[27, 61, 58, 38, 24, 62, 23, 61, 26, 58, 32, 62, 61, 9, 58, 3, 11, 62, 0, 0, 0, 0, 0, 0, 0, 2]\n",
            "ground truth expression\n",
            "[27, 61, 58, 38, 24, 62, 23, 61, 8, 16, 58, 40, 61, 10, 62, 62, 61, 10, 26, 58, 40, 61, 13, 62, 32, 62]\n",
            "current accuracy 34.61538461538461\n",
            "current ave accuracy 32.96945419478017\n",
            "min accuracy in batch 6.666666666666667\n",
            "max accuracy in batch 71.7948717948718\n",
            "predicted expression\n",
            "[27, 61, 57, 38, 13, 40, 61, 3, 62, 62, 34, 61, 57, 62, 23, 61, 9, 62, 61, 57, 62, 35, 61, 57, 25, 10, 3, 4, 9, 57, 31, 62, 2]\n",
            "ground truth expression\n",
            "[27, 61, 58, 38, 30, 6, 13, 62, 36, 40, 61, 11, 62, 61, 58, 62, 3, 27, 61, 58, 38, 30, 6, 13, 62, 22, 40, 61, 11, 62, 61, 58, 62]\n",
            "current accuracy 12.121212121212121\n",
            "current ave accuracy 33.00918211902475\n",
            "min accuracy in batch 8.16326530612245\n",
            "max accuracy in batch 82.75862068965517\n",
            "predicted expression\n",
            "[27, 61, 57, 38, 30, 6, 9, 40, 61, 4, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 57, 62, 25, 36, 61, 57, 62, 4, 9, 31, 62, 61, 23, 61, 45, 62, 61, 45, 57, 62, 36, 61, 57, 62, 62, 0, 0, 0, 0, 0, 2]\n",
            "ground truth expression\n",
            "[27, 61, 37, 38, 30, 6, 16, 62, 23, 61, 23, 61, 45, 62, 61, 45, 37, 62, 25, 36, 61, 37, 62, 3, 4, 12, 33, 61, 37, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 37, 62, 25, 37, 3, 4, 13, 30, 6, 11, 31, 62]\n",
            "current accuracy 11.76470588235294\n",
            "current ave accuracy 32.92987221090745\n",
            "min accuracy in batch 3.225806451612903\n",
            "max accuracy in batch 73.07692307692307\n",
            "predicted expression\n",
            "[27, 61, 58, 38, 8, 40, 61, 3, 62, 62, 23, 61, 4, 14, 34, 61, 58, 62, 62, 61, 8, 3, 58, 34, 61, 58, 62, 62, 0, 0, 2]\n",
            "ground truth expression\n",
            "[27, 61, 52, 38, 16, 62, 23, 61, 46, 40, 61, 52, 62, 3, 46, 40, 61, 4, 10, 52, 62, 4, 9, 62, 61, 52, 34, 61, 52, 62, 62]\n",
            "current accuracy 12.903225806451612\n",
            "current ave accuracy 32.8552839474781\n",
            "min accuracy in batch 0.0\n",
            "max accuracy in batch 66.66666666666666\n",
            "predicted expression\n",
            "[17, 27, 61, 57, 38, 23, 61, 30, 62, 61, 9, 62, 40, 61, 4, 62, 62, 36, 61, 57, 62, 3, 4, 10, 36, 61, 57, 62, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2]\n",
            "ground truth expression\n",
            "[17, 27, 61, 48, 38, 23, 61, 30, 62, 61, 16, 62, 62, 20, 40, 61, 9, 62, 61, 48, 62, 3, 27, 61, 48, 38, 23, 61, 30, 62, 61, 15, 62, 62, 22, 40, 61, 9, 62, 61, 48, 62]\n",
            "current accuracy 30.952380952380953\n",
            "current ave accuracy 32.87672581262916\n",
            "min accuracy in batch 5.263157894736842\n",
            "max accuracy in batch 80.82191780821918\n",
            "predicted expression\n",
            "[27, 61, 59, 38, 30, 6, 13, 62, 23, 61, 10, 20, 40, 61, 10, 62, 61, 59, 62, 3, 4, 10, 36, 40, 61, 9, 62, 61, 59, 62, 62, 61, 10, 62, 2]\n",
            "ground truth expression\n",
            "[27, 61, 51, 38, 30, 6, 14, 62, 23, 61, 10, 36, 40, 61, 15, 62, 61, 51, 62, 3, 13, 22, 40, 61, 15, 62, 61, 51, 62, 62, 61, 10, 0, 0, 2]\n",
            "current accuracy 48.57142857142857\n",
            "current ave accuracy 32.872857888111334\n",
            "min accuracy in batch 8.771929824561402\n",
            "max accuracy in batch 72.58064516129032\n",
            "predicted expression\n",
            "[27, 61, 59, 38, 9, 62, 23, 61, 23, 61, 8, 34, 61, 25, 10, 59, 31, 62, 62, 61, 10, 59, 62, 20, 61, 25, 10, 59, 31, 62, 62, 61, 23, 61, 9, 34, 61, 25, 10, 59, 31, 62, 62, 61, 10, 59, 62, 62, 2]\n",
            "ground truth expression\n",
            "[46, 40, 61, 27, 61, 59, 38, 9, 40, 61, 3, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 59, 62, 28, 61, 25, 11, 3, 59, 31, 62, 62, 61, 23, 61, 45, 62, 61, 45, 59, 62, 33, 61, 59, 62, 62, 0, 0, 2]\n",
            "current accuracy 20.408163265306122\n",
            "current ave accuracy 32.919568296290706\n",
            "min accuracy in batch 9.75609756097561\n",
            "max accuracy in batch 78.94736842105263\n",
            "predicted expression\n",
            "[23, 61, 27, 61, 48, 38, 8, 62, 23, 61, 45, 62, 61, 45, 48, 62, 8, 8, 34, 61, 25, 10, 48, 31, 62, 20, 61, 25, 9, 48, 31, 62, 62, 61, 27, 61, 48, 38, 10, 62, 23, 61, 45, 62, 61, 45, 48, 62, 48, 62, 2]\n",
            "ground truth expression\n",
            "[17, 23, 61, 27, 61, 47, 38, 13, 62, 8, 7, 34, 61, 25, 7, 31, 62, 33, 61, 25, 10, 47, 31, 62, 62, 61, 27, 61, 47, 38, 16, 62, 15, 47, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2]\n",
            "current accuracy 7.8431372549019605\n",
            "current ave accuracy 32.85465104397236\n",
            "min accuracy in batch 4.615384615384616\n",
            "max accuracy in batch 72.22222222222221\n",
            "predicted expression\n",
            "[27, 61, 57, 38, 23, 61, 30, 62, 61, 9, 62, 62, 20, 40, 61, 10, 62, 61, 57, 62, 3, 34, 40, 61, 9, 62, 61, 57, 62, 2]\n",
            "ground truth expression\n",
            "[27, 61, 57, 38, 23, 61, 30, 62, 61, 12, 62, 62, 33, 40, 61, 9, 62, 61, 57, 62, 3, 36, 40, 61, 15, 62, 61, 57, 0, 2]\n",
            "current accuracy 80.0\n",
            "current ave accuracy 32.900037541508325\n",
            "min accuracy in batch 12.222222222222221\n",
            "max accuracy in batch 83.33333333333334\n",
            "predicted expression\n",
            "[28, 61, 57, 62, 17, 23, 61, 27, 61, 57, 38, 30, 6, 9, 40, 61, 4, 62, 62, 36, 61, 57, 62, 62, 61, 27, 61, 57, 38, 30, 6, 11, 40, 61, 4, 62, 62, 4, 9, 20, 40, 61, 9, 62, 61, 57, 62, 62, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2]\n",
            "ground truth expression\n",
            "[28, 61, 57, 62, 17, 23, 61, 27, 61, 55, 38, 30, 6, 12, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 55, 62, 20, 61, 55, 62, 62, 61, 27, 61, 55, 38, 30, 6, 11, 40, 61, 4, 62, 62, 23, 61, 45, 62, 61, 45, 55, 62, 4, 9, 36, 40, 61, 9, 62, 61, 55, 62, 62]\n",
            "current accuracy 34.375\n",
            "current ave accuracy 32.84812499993253\n",
            "min accuracy in batch 13.114754098360656\n",
            "max accuracy in batch 77.08333333333334\n",
            "predicted expression\n",
            "[27, 61, 59, 38, 9, 62, 23, 61, 25, 59, 4, 8, 31, 25, 35, 61, 9, 59, 3, 9, 62, 3, 7, 31, 62, 61, 8, 7, 3, 4, 11, 59, 62, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2]\n",
            "ground truth expression\n",
            "[17, 27, 61, 47, 38, 23, 61, 30, 62, 61, 16, 62, 62, 23, 61, 25, 35, 61, 34, 61, 47, 62, 62, 4, 13, 31, 25, 35, 61, 34, 61, 47, 62, 62, 3, 10, 31, 62, 61, 35, 61, 34, 61, 47, 62, 62, 4, 13, 62]\n",
            "current accuracy 2.0408163265306123\n",
            "current ave accuracy 32.71606116561158\n",
            "min accuracy in batch 2.0408163265306123\n",
            "max accuracy in batch 57.49999999999999\n",
            "predicted expression\n",
            "[27, 61, 58, 38, 8, 62, 23, 61, 46, 40, 61, 58, 62, 3, 4, 9, 34, 61, 58, 62, 4, 8, 62, 61, 58, 40, 61, 10, 62, 3, 10, 58, 40, 61, 8, 62, 3, 8, 7, 58, 40, 61, 10, 62, 62, 0, 0, 0, 2]\n",
            "ground truth expression\n",
            "[27, 61, 58, 38, 8, 62, 23, 61, 46, 40, 61, 58, 62, 3, 4, 15, 34, 61, 58, 62, 3, 4, 8, 19, 7, 62, 61, 8, 58, 40, 61, 9, 62, 3, 13, 19, 10, 58, 40, 61, 9, 62, 3, 10, 16, 19, 12, 58, 62]\n",
            "current accuracy 40.816326530612244\n",
            "current ave accuracy 32.69348388987539\n",
            "min accuracy in batch 8.333333333333332\n",
            "max accuracy in batch 75.0\n",
            "predicted expression\n",
            "[27, 61, 57, 38, 9, 40, 61, 4, 62, 62, 23, 61, 57, 62, 61, 26, 57, 4, 9, 32, 62, 2]\n",
            "ground truth expression\n",
            "[27, 61, 49, 38, 4, 24, 62, 23, 61, 16, 62, 61, 49, 40, 61, 13, 10, 62, 0, 0, 0, 2]\n",
            "current accuracy 27.27272727272727\n",
            "current ave accuracy 32.67069590587297\n",
            "min accuracy in batch 11.11111111111111\n",
            "max accuracy in batch 91.11111111111111\n",
            "predicted expression\n",
            "[27, 61, 57, 38, 24, 62, 23, 61, 23, 61, 45, 62, 61, 45, 57, 62, 28, 61, 25, 10, 57, 3, 9, 31, 62, 62, 61, 23, 61, 45, 62, 61, 45, 57, 62, 25, 28, 61, 25, 13, 57, 3, 7, 31, 62, 3, 13, 31, 62, 0, 0, 0, 0, 0, 0, 0, 0, 2]\n",
            "ground truth expression\n",
            "[27, 61, 57, 38, 24, 62, 23, 61, 9, 3, 23, 61, 14, 62, 61, 57, 62, 62, 61, 23, 61, 35, 61, 57, 40, 61, 15, 62, 3, 57, 3, 15, 62, 3, 35, 61, 57, 40, 61, 9, 62, 3, 4, 9, 57, 62, 62, 61, 35, 61, 57, 40, 61, 10, 62, 62, 62, 62]\n",
            "current accuracy 15.517241379310345\n",
            "current ave accuracy 32.58839275531413\n",
            "min accuracy in batch 0.0\n",
            "max accuracy in batch 82.1917808219178\n",
            "predicted expression\n",
            "[17, 27, 61, 58, 38, 9, 40, 61, 3, 62, 62, 23, 61, 10, 62, 61, 58, 62, 3, 4, 10, 23, 61, 9, 62, 61, 46, 40, 61, 58, 3, 3, 62, 62, 2]\n",
            "ground truth expression\n",
            "[17, 27, 61, 51, 38, 8, 7, 62, 23, 61, 14, 62, 61, 25, 35, 18, 11, 39, 61, 58, 62, 3, 13, 31, 25, 35, 61, 58, 62, 3, 9, 31, 0, 0, 2]\n",
            "current accuracy 17.142857142857142\n",
            "current ave accuracy 32.63573790326382\n",
            "min accuracy in batch 13.333333333333334\n",
            "max accuracy in batch 87.87878787878788\n",
            "predicted expression\n",
            "[23, 61, 27, 61, 58, 38, 10, 62, 11, 9, 25, 4, 9, 34, 40, 61, 10, 62, 61, 25, 9, 58, 31, 62, 3, 36, 40, 61, 9, 62, 61, 25, 9, 58, 31, 62, 31, 62, 61, 9, 62, 2]\n",
            "ground truth expression\n",
            "[23, 61, 27, 61, 54, 38, 9, 62, 10, 14, 25, 9, 36, 40, 61, 11, 62, 61, 25, 9, 54, 31, 62, 3, 36, 40, 61, 15, 62, 61, 25, 10, 54, 31, 62, 31, 62, 61, 10, 0, 0, 2]\n",
            "current accuracy 19.047619047619047\n",
            "current ave accuracy 32.64266697308511\n",
            "min accuracy in batch 10.416666666666668\n",
            "max accuracy in batch 73.33333333333333\n",
            "predicted expression\n",
            "[27, 61, 59, 38, 24, 62, 23, 61, 59, 40, 61, 9, 62, 3, 4, 9, 28, 61, 23, 61, 10, 62, 61, 59, 62, 62, 62, 61, 10, 59, 40, 61, 9, 62, 3, 4, 10, 59, 62, 2]\n",
            "ground truth expression\n",
            "[27, 61, 59, 38, 24, 62, 23, 61, 12, 13, 28, 61, 59, 62, 62, 61, 35, 61, 58, 62, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2]\n",
            "current accuracy 25.0\n",
            "current ave accuracy 32.621860489436116\n",
            "min accuracy in batch 7.317073170731707\n",
            "max accuracy in batch 83.33333333333334\n",
            "predicted expression\n",
            "[27, 61, 54, 38, 23, 61, 30, 62, 61, 13, 62, 62, 23, 61, 34, 61, 54, 62, 3, 4, 10, 34, 61, 54, 62, 62, 61, 54, 3, 4, 10, 23, 61, 30, 62, 61, 10, 62, 62, 2]\n",
            "ground truth expression\n",
            "[27, 61, 58, 38, 15, 62, 23, 61, 12, 19, 9, 58, 34, 61, 25, 16, 58, 31, 62, 62, 61, 16, 58, 15, 20, 61, 25, 15, 58, 31, 62, 0, 0, 0, 0, 0, 0, 0, 0, 2]\n",
            "current accuracy 12.5\n",
            "current ave accuracy 32.58407280516571\n",
            "min accuracy in batch 11.11111111111111\n",
            "max accuracy in batch 73.68421052631578\n",
            "predicted expression\n",
            "[27, 61, 57, 38, 9, 62, 23, 61, 46, 40, 61, 57, 62, 3, 4, 10, 34, 61, 57, 62, 4, 8, 62, 61, 57, 40, 61, 10, 62, 3, 10, 57, 40, 61, 10, 62, 3, 10, 57, 40, 61, 10, 62, 62, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2]\n",
            "ground truth expression\n",
            "[27, 61, 48, 38, 16, 40, 61, 3, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 48, 62, 25, 8, 3, 4, 12, 34, 40, 61, 8, 62, 61, 48, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 48, 62, 25, 20, 61, 48, 62, 3, 48, 34, 40, 61, 8, 62, 61, 48, 62, 31, 62]\n",
            "current accuracy 11.475409836065573\n",
            "current ave accuracy 32.586800954408595\n",
            "min accuracy in batch 11.475409836065573\n",
            "max accuracy in batch 84.84848484848484\n",
            "predicted expression\n",
            "[27, 61, 59, 38, 4, 10, 40, 61, 3, 62, 62, 23, 61, 59, 40, 61, 9, 62, 3, 4, 10, 59, 3, 8, 62, 61, 59, 40, 61, 9, 62, 4, 9, 62, 2]\n",
            "ground truth expression\n",
            "[27, 61, 59, 38, 4, 10, 62, 23, 61, 14, 25, 59, 40, 61, 13, 62, 3, 4, 59, 3, 7, 31, 62, 61, 59, 3, 10, 0, 0, 0, 0, 0, 0, 0, 2]\n",
            "current accuracy 20.0\n",
            "current ave accuracy 32.656260286663326\n",
            "min accuracy in batch 12.5\n",
            "max accuracy in batch 80.0\n",
            "predicted expression\n",
            "[27, 61, 58, 38, 4, 9, 62, 23, 61, 58, 4, 8, 62, 61, 58, 40, 61, 16, 62, 3, 58, 3, 8, 62, 2]\n",
            "ground truth expression\n",
            "[27, 61, 58, 38, 15, 62, 23, 61, 58, 62, 61, 35, 61, 58, 40, 61, 9, 62, 3, 15, 62, 0, 0, 0, 2]\n",
            "current accuracy 20.0\n",
            "current ave accuracy 32.61099653322456\n",
            "min accuracy in batch 8.16326530612245\n",
            "max accuracy in batch 76.92307692307693\n",
            "predicted expression\n",
            "[27, 61, 57, 38, 4, 24, 62, 9, 57, 40, 61, 4, 8, 62, 3, 10, 57, 40, 61, 9, 62, 2]\n",
            "ground truth expression\n",
            "[27, 61, 58, 38, 4, 24, 62, 46, 40, 61, 58, 62, 33, 61, 58, 62, 3, 0, 0, 0, 0, 2]\n",
            "current accuracy 31.818181818181817\n",
            "current ave accuracy 32.61519453816501\n",
            "min accuracy in batch 12.280701754385964\n",
            "max accuracy in batch 80.0\n",
            "predicted expression\n",
            "[27, 61, 54, 38, 4, 24, 62, 26, 54, 4, 8, 32, 3, 54, 2]\n",
            "ground truth expression\n",
            "[27, 61, 55, 38, 4, 8, 62, 7, 55, 40, 61, 8, 62, 4, 10]\n",
            "current accuracy 33.33333333333333\n",
            "current ave accuracy 32.605113638804745\n",
            "min accuracy in batch 8.21917808219178\n",
            "max accuracy in batch 70.0\n",
            "predicted expression\n",
            "[27, 61, 58, 38, 9, 62, 23, 61, 10, 3, 4, 10, 34, 61, 25, 58, 31, 62, 62, 61, 58, 62, 2]\n",
            "ground truth expression\n",
            "[27, 61, 58, 38, 14, 62, 23, 61, 58, 25, 58, 3, 9, 16, 31, 62, 61, 58, 0, 0, 0, 0, 2]\n",
            "current accuracy 34.78260869565217\n",
            "current ave accuracy 32.562828754459574\n",
            "min accuracy in batch 6.0606060606060606\n",
            "max accuracy in batch 81.81818181818183\n",
            "predicted expression\n",
            "[27, 61, 54, 38, 9, 62, 23, 61, 34, 61, 25, 9, 54, 31, 62, 20, 61, 25, 9, 54, 31, 62, 23, 61, 9, 62, 61, 9, 62, 23, 61, 10, 62, 61, 54, 62, 62, 61, 36, 61, 25, 9, 54, 31, 62, 23, 61, 10, 62, 61, 10, 62, 23, 61, 10, 62, 61, 54, 62, 62, 2]\n",
            "ground truth expression\n",
            "[27, 61, 54, 38, 9, 62, 23, 61, 34, 61, 25, 13, 54, 31, 62, 62, 61, 54, 34, 61, 25, 13, 54, 31, 62, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2]\n",
            "current accuracy 26.229508196721312\n",
            "current ave accuracy 32.601914499233416\n",
            "min accuracy in batch 11.363636363636363\n",
            "max accuracy in batch 75.47169811320755\n",
            "predicted expression\n",
            "[27, 61, 57, 38, 24, 62, 23, 61, 23, 61, 45, 62, 61, 45, 57, 62, 28, 61, 25, 57, 3, 9, 31, 62, 62, 61, 23, 61, 45, 62, 61, 45, 57, 62, 25, 28, 61, 25, 13, 57, 3, 7, 31, 62, 3, 13, 31, 62, 2]\n",
            "ground truth expression\n",
            "[27, 61, 44, 38, 4, 24, 62, 23, 61, 8, 44, 40, 61, 9, 62, 3, 13, 62, 61, 35, 61, 12, 44, 40, 61, 14, 62, 3, 15, 44, 3, 8, 62, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2]\n",
            "current accuracy 10.204081632653061\n",
            "current ave accuracy 32.679111931268906\n",
            "min accuracy in batch 8.51063829787234\n",
            "max accuracy in batch 84.61538461538461\n",
            "predicted expression\n",
            "[27, 61, 57, 38, 23, 61, 30, 62, 61, 9, 62, 62, 20, 40, 61, 10, 62, 61, 57, 62, 3, 20, 40, 61, 9, 62, 61, 57, 62, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2]\n",
            "ground truth expression\n",
            "[27, 61, 57, 38, 23, 61, 30, 62, 61, 14, 62, 62, 33, 40, 61, 16, 62, 61, 57, 62, 3, 27, 61, 57, 38, 23, 61, 30, 62, 61, 15, 62, 62, 36, 40, 61, 9, 62, 61, 57, 62]\n",
            "current accuracy 48.78048780487805\n",
            "current ave accuracy 32.751357116550125\n",
            "min accuracy in batch 6.382978723404255\n",
            "max accuracy in batch 81.13207547169812\n",
            "predicted expression\n",
            "[27, 61, 57, 38, 30, 6, 9, 62, 23, 61, 9, 20, 40, 61, 10, 62, 61, 57, 62, 3, 4, 10, 36, 40, 61, 9, 62, 61, 57, 62, 62, 61, 10, 62, 0, 0, 0, 0, 2]\n",
            "ground truth expression\n",
            "[27, 61, 57, 38, 30, 6, 10, 40, 61, 4, 62, 62, 23, 61, 36, 40, 61, 15, 62, 61, 57, 62, 25, 9, 57, 3, 25, 9, 30, 31, 40, 61, 10, 62, 31, 62, 61, 11, 62]\n",
            "current accuracy 30.76923076923077\n",
            "current ave accuracy 32.74739279923637\n",
            "min accuracy in batch 0.0\n",
            "max accuracy in batch 89.04109589041096\n",
            "predicted expression\n",
            "[27, 61, 58, 38, 30, 6, 9, 40, 61, 4, 62, 62, 36, 61, 58, 62, 3, 4, 9, 36, 61, 58, 62, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2]\n",
            "ground truth expression\n",
            "[27, 61, 54, 38, 30, 6, 10, 62, 20, 40, 61, 11, 62, 61, 54, 62, 3, 27, 61, 54, 38, 30, 6, 14, 62, 36, 40, 61, 9, 62, 61, 54, 62]\n",
            "current accuracy 24.242424242424242\n",
            "current ave accuracy 32.68973462867787\n",
            "min accuracy in batch 3.225806451612903\n",
            "max accuracy in batch 69.23076923076923\n",
            "predicted expression\n",
            "[27, 61, 58, 38, 10, 40, 61, 3, 62, 62, 46, 40, 61, 28, 61, 25, 10, 3, 58, 40, 61, 36, 61, 58, 62, 62, 31, 62, 62, 2]\n",
            "ground truth expression\n",
            "[27, 61, 51, 38, 16, 40, 61, 3, 62, 62, 46, 40, 61, 22, 61, 51, 62, 28, 61, 25, 8, 3, 51, 31, 62, 0, 0, 0, 0, 2]\n",
            "current accuracy 46.666666666666664\n",
            "current ave accuracy 32.67803752030164\n",
            "min accuracy in batch 10.638297872340425\n",
            "max accuracy in batch 79.3103448275862\n",
            "predicted expression\n",
            "[27, 61, 57, 38, 30, 6, 9, 62, 20, 40, 61, 10, 62, 61, 57, 62, 3, 20, 40, 61, 9, 62, 61, 57, 62, 2]\n",
            "ground truth expression\n",
            "[27, 61, 49, 38, 30, 6, 10, 62, 20, 40, 61, 9, 62, 61, 49, 62, 3, 20, 40, 61, 15, 62, 61, 49, 0, 2]\n",
            "current accuracy 73.07692307692307\n",
            "current ave accuracy 32.679928820188586\n",
            "min accuracy in batch 5.319148936170213\n",
            "max accuracy in batch 76.92307692307693\n",
            "predicted expression\n",
            "[27, 61, 44, 38, 23, 61, 30, 62, 61, 9, 62, 62, 34, 40, 61, 9, 62, 61, 44, 62, 3, 20, 40, 61, 9, 62, 61, 44, 62, 2]\n",
            "ground truth expression\n",
            "[27, 61, 59, 38, 23, 61, 30, 62, 61, 12, 62, 62, 34, 40, 61, 12, 62, 61, 59, 62, 3, 20, 40, 61, 13, 62, 61, 59, 0, 2]\n",
            "current accuracy 76.66666666666667\n",
            "current ave accuracy 32.74084666324168\n",
            "min accuracy in batch 9.67741935483871\n",
            "max accuracy in batch 76.66666666666667\n",
            "predicted expression\n",
            "[27, 61, 54, 38, 9, 62, 9, 54, 40, 61, 8, 62, 3, 4, 9, 54, 40, 61, 8, 62, 3, 54, 3, 7, 2]\n",
            "ground truth expression\n",
            "[27, 61, 58, 38, 11, 62, 4, 9, 25, 10, 58, 4, 13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2]\n",
            "current accuracy 20.0\n",
            "current ave accuracy 32.78539241297546\n",
            "min accuracy in batch 8.571428571428571\n",
            "max accuracy in batch 78.57142857142857\n",
            "predicted expression\n",
            "[27, 61, 44, 38, 23, 61, 30, 62, 61, 10, 62, 62, 23, 61, 9, 20, 40, 61, 10, 62, 61, 44, 62, 3, 4, 10, 36, 40, 61, 10, 62, 61, 44, 62, 62, 61, 9, 62, 2]\n",
            "ground truth expression\n",
            "[27, 61, 48, 38, 30, 6, 9, 62, 34, 40, 61, 11, 62, 61, 48, 62, 3, 27, 61, 48, 38, 30, 6, 9, 62, 33, 40, 61, 9, 62, 61, 48, 0, 0, 0, 0, 0, 0, 2]\n",
            "current accuracy 15.384615384615385\n",
            "current ave accuracy 32.78225861659457\n",
            "min accuracy in batch 12.121212121212121\n",
            "max accuracy in batch 83.33333333333334\n",
            "predicted expression\n",
            "[27, 61, 57, 38, 24, 62, 23, 61, 23, 61, 29, 41, 61, 10, 62, 61, 57, 62, 62, 61, 29, 41, 61, 8, 7, 62, 61, 10, 62, 62, 62, 61, 23, 61, 29, 41, 61, 8, 7, 62, 61, 57, 62, 62, 61, 29, 41, 61, 8, 7, 62, 61, 10, 62, 62, 62, 2]\n",
            "ground truth expression\n",
            "[27, 61, 56, 38, 24, 62, 23, 61, 23, 61, 29, 41, 61, 12, 8, 62, 61, 56, 62, 62, 61, 29, 41, 61, 8, 7, 62, 61, 12, 62, 62, 62, 61, 23, 61, 29, 41, 61, 9, 8, 62, 61, 56, 62, 62, 61, 29, 41, 61, 16, 62, 61, 9, 62, 62, 0, 2]\n",
            "current accuracy 36.84210526315789\n",
            "current ave accuracy 32.76145058192207\n",
            "min accuracy in batch 5.263157894736842\n",
            "max accuracy in batch 79.48717948717949\n",
            "predicted expression\n",
            "[27, 61, 57, 38, 24, 62, 23, 61, 10, 62, 61, 57, 40, 61, 9, 62, 62, 23, 61, 10, 62, 61, 57, 62, 3, 13, 23, 61, 9, 62, 61, 57, 40, 61, 4, 9, 62, 62, 34, 61, 23, 61, 13, 62, 61, 57, 62, 62, 23, 61, 10, 62, 61, 57, 62, 3, 4, 10, 23, 61, 9, 62, 61, 9, 62, 31, 62, 2]\n",
            "ground truth expression\n",
            "[27, 61, 58, 38, 11, 62, 25, 15, 58, 3, 9, 23, 61, 16, 62, 61, 58, 4, 9, 62, 31, 13, 25, 58, 4, 10, 31, 25, 58, 3, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2]\n",
            "current accuracy 7.352941176470589\n",
            "current ave accuracy 32.69785013426504\n",
            "min accuracy in batch 4.545454545454546\n",
            "max accuracy in batch 64.70588235294117\n",
            "predicted expression\n",
            "[27, 61, 54, 38, 4, 8, 40, 61, 3, 62, 62, 23, 61, 54, 40, 61, 8, 62, 3, 4, 9, 54, 3, 8, 62, 61, 54, 40, 61, 9, 62, 4, 11, 62, 2]\n",
            "ground truth expression\n",
            "[27, 61, 37, 38, 10, 40, 61, 4, 62, 62, 23, 61, 37, 40, 61, 10, 62, 3, 4, 16, 37, 62, 61, 26, 37, 32, 0, 0, 0, 0, 0, 0, 0, 0, 2]\n",
            "current accuracy 14.285714285714285\n",
            "current ave accuracy 32.73613200276261\n",
            "min accuracy in batch 14.285714285714285\n",
            "max accuracy in batch 73.07692307692307\n",
            "predicted expression\n",
            "[27, 61, 48, 38, 9, 62, 23, 61, 23, 61, 45, 62, 61, 45, 48, 62, 25, 46, 40, 61, 48, 62, 3, 4, 9, 20, 61, 48, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 48, 62, 25, 48, 40, 61, 8, 62, 3, 9, 48, 40, 61, 14, 62, 3, 4, 10, 48, 31, 62, 2]\n",
            "ground truth expression\n",
            "[27, 61, 55, 38, 23, 61, 30, 62, 61, 15, 62, 62, 23, 61, 23, 61, 45, 62, 61, 45, 55, 62, 25, 36, 61, 55, 62, 3, 4, 12, 34, 61, 55, 62, 31, 62, 61, 23, 61, 45, 62, 61, 45, 55, 62, 25, 55, 3, 4, 13, 23, 61, 30, 62, 61, 15, 62, 31, 0, 2]\n",
            "current accuracy 16.666666666666664\n",
            "current ave accuracy 32.73107628776435\n",
            "min accuracy in batch 8.695652173913043\n",
            "max accuracy in batch 90.41095890410958\n",
            "predicted expression\n",
            "[27, 61, 57, 38, 9, 62, 23, 61, 34, 61, 25, 57, 31, 62, 62, 61, 36, 61, 57, 62, 62, 0, 0, 2]\n",
            "ground truth expression\n",
            "[27, 61, 58, 38, 15, 62, 23, 61, 34, 61, 25, 58, 31, 62, 62, 61, 58, 20, 61, 25, 58, 31, 62, 62]\n",
            "current accuracy 54.166666666666664\n",
            "current ave accuracy 32.76623409043644\n",
            "min accuracy in batch 0.0\n",
            "max accuracy in batch 90.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.count_nonzero(accs>10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OEYL-CDJvZ7",
        "outputId": "8983673e-3e79-45b2-ee7d-ae543c34b07d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1868\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fh4uMMMKU7dh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w1hvNyvWCJed"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "fsEcdJEKXEA0",
        "clVU1p2OavXJ",
        "2qJfqyA2N54K",
        "6sHTHQObIAEV"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}